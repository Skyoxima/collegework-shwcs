{
  "Sem_IV-DAOA": {
    "DP_Coinchange": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid initializer(int noofcoins, int sum, int soln_matrix[][sum + 1]) //\n{\n  int i, j;\n\n  for (i = 0; i <= noofcoins; i++)\n  {\n    for (j = 0; j <= sum; j++)\n    {\n      soln_matrix[i][j] = 0;\n    }\n  }\n}\n\nvoid printer(int noofcoins, int sum, int matrix[][sum + 1]) //\n{\n  int i, j;\n\n  for (i = 0; i <= noofcoins; i++)\n  {\n    for (j = 0; j <= sum; j++)\n      printf(\"SM[%d][%d]: \\033[1m\\033[38;5;225m%d \\033[0m\", i, j, matrix[i][j]);\n    printf(\"\\n\");\n  }\n}\n\nint *coinchange(int noofcoins, int sum, int soln_matrix[][sum + 1], int *coins)\n{\n  int i = 1, j = 1, k;\n  static int *selected_coins;\n  selected_coins = (int *)malloc((sum) * sizeof(int));\n\n  for (j = 1; j <= sum; j++) //\n  {\n    for (i = 1; i <= noofcoins; i++) //\n    {\n      if (i == 1 && j < coins[i])\n        soln_matrix[i][j] = 999; //\n\n      else if (j < coins[i])\n        soln_matrix[i][j] = soln_matrix[i - 1][j];\n\n      else if (i == 1 || i == j)\n        soln_matrix[i][j] = 1 + soln_matrix[1][j - coins[i]];\n\n      else\n      {\n        if (soln_matrix[i - 1][j] < (1 + soln_matrix[i][j - coins[i]]))\n          soln_matrix[i][j] = soln_matrix[i - 1][j];\n        else\n          soln_matrix[i][j] = 1 + soln_matrix[i][j - coins[i]];\n      }\n    }\n  }\n\n  i = noofcoins;\n  j = sum;\n  k = 0;\n  selected_coins[k] = 0;\n  while (j > 0)\n  {\n    if (soln_matrix[i][j] == soln_matrix[i - 1][j])\n      i--;\n    else\n    {\n      selected_coins[k] = coins[i];\n      k++;\n      j -= coins[i];\n    }\n  }\n\n  selected_coins[k] = -1;\n  return selected_coins;\n}\n\nvoid main()\n{\n  int noofcoins = 0, i, j, k, sum;\n  int *coins;\n  int *selected_coins;\n  system(\"cls\");\n\n  printf(\"Enter the number of coins available: \");\n  scanf(\"%d\", &noofcoins);\n  coins = (int *)malloc((noofcoins) * sizeof(int));\n\n  printf(\"\\n\");\n  coins[0] = 0;\n  for (i = 1; i <= noofcoins; i++)\n  {\n    printf(\"Enter Coin %d: \", i);\n    scanf(\"%d\", &coins[i]);\n  }\n\n  printf(\"\\nNow enter the amount sum to be achieved: \");\n  scanf(\"%d\", &sum);\n\n  int soln_matrix[noofcoins + 1][sum + 1]; //\n  initializer(noofcoins, sum, soln_matrix);\n\n  selected_coins = coinchange(noofcoins, sum, soln_matrix, coins);\n  printf(\"\\nWork Matrix: \\n\\n\");\n  printer(noofcoins, sum, soln_matrix);\n\n  printf(\"\\nSelected coins to pay the sum: \");\n  for (i = 0; selected_coins[i] != -1; i++)\n    printf(\"%d \", selected_coins[i]);\n  printf(\"\\n\\n\");\n}",
      "comments": {
        "4": "// not an n x n matrix therefore two parameters needed, soln_matrix[][total noofcolumns]",
        "17": "//! V. IMP.: check how the matrix size is passed",
        "35": "// j goes from 1 to 8",
        "37": "// i goes from 1 to 3, this is a column-wise traversal, [1,1] [2,1] [3,1]",
        "40": "// infinity",
        "100": "// +1 because >> for e.g: rows ~ 0, 1, 2, 3 and columns ~ 0, 1, 2, 3, 4, 5, 6, 7, 8"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/DP_Coinchange/DP_CC_OP_1.PNG",
        "OP_ss/Sem_IV-DAOA/DP_Coinchange/DP_CC_OP_2.PNG"
      ],
      "bgColors": {
        "DP_CC_OP_1.PNG": "#262626",
        "DP_CC_OP_2.PNG": "#262626"
      }
    },
    "DP_Longest_Common_Subsequence": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\nvoid printer(int n1, int n2, int matrix[][n2 + 1]) //\n{\n  int i, j;\n\n  for (i = 0; i <= n1; i++)\n  {\n    for (j = 0; j <= n2; j++)\n      printf(\"SM[%d][%d]: \\033[1m\\033[38;5;225m%d \\033[0m\", i, j, matrix[i][j]);\n    printf(\"\\n\");\n  }\n}\n\nvoid longest_common_subsequence(int n1, int n2, char X[n1], char Y[n2], int sol_mx[][n2 + 1], int LCS[n2])\n{\n  int i, j, temp1, temp2, s_index = n2;\n\n  for (i = 0; i < n2; i++)\n    LCS[i] = -1;\n\n  for (i = 1; i <= n1; i++)\n  {\n    for (j = 1; j <= n2; j++)\n    {\n      if (X[i - 1] == Y[j - 1]) //\n        sol_mx[i][j] = 1 + sol_mx[i - 1][j - 1];\n      else\n      {\n        temp1 = sol_mx[i - 1][j]; //\n        temp2 = sol_mx[i][j - 1]; //\n\n        if (temp1 > temp2)\n          sol_mx[i][j] = temp1;\n        else\n          sol_mx[i][j] = temp2;\n      }\n    }\n  }\n\n  //\n  i = n1;\n  j = n2;\n  while (i != 0)\n  {\n    if (X[i - 1] == Y[j - 1])\n    {\n      LCS[j - 1] = j - 1;\n      i--;\n      j--;\n    }\n\n    else\n    {\n      temp1 = sol_mx[i - 1][j];\n      temp2 = sol_mx[i][j - 1];\n\n      if (temp1 > temp2)\n        i--;\n      else\n        j--;\n    }\n  }\n}\n\nvoid main()\n{\n  system(\"cls\");\n\n  int i, j, k, n1, n2;\n\n  printf(\"\\nEnter the number of characters in String 1: \");\n  scanf(\"%d\", &n1);\n  char X[n1];\n  getchar();\n  printf(\"Enter String 1: \");\n  fgets(X, n1 + 1, stdin); //\n  getchar();\n\n  printf(\"\\nEnter the number of characters in String 2: \");\n  scanf(\"%d\", &n2);\n  char Y[n2];\n  int LCS[n2];\n  getchar();\n  printf(\"Enter String 2: \");\n  fgets(Y, n2 + 1, stdin);\n  getchar();\n\n  int soln_mx[n1 + 1][n2 + 1]; //\n  for (i = 0; i <= n1; i++)\n    for (j = 0; j <= n2; j++)\n      soln_mx[i][j] = 0;\n\n  longest_common_subsequence(n1, n2, X, Y, soln_mx, LCS);\n  printf(\"\\n\\n\\033[4m\\033[38;5;207mFinal Matrix:\\n\\033[0m\");\n  printer(n1, n2, soln_mx);\n\n  printf(\"\\n\\033[1m\\033[4m\\033[38;5;210mCharacters of the subsequence:\\033[0m \");\n  for (i = 0; i < n2; i++)\n    if (LCS[i] != -1)\n      printf(\"%c \", Y[LCS[i]]);\n}\n\n//\n//\n//\n//\n//\n",
      "comments": {
        "5": "//! check how the matrix size is passed",
        "28": "//* since the indexing starts from zero for the char arrays",
        "32": "// upper element",
        "33": "// left element",
        "43": "// solution, the actual subsequence.. backtracking usage is necessary incase of multiple answers (although this program will not give multiple answers)",
        "79": "// simple gets is risky, it doesn't check for bounds set and can cause an overflow, hence using fgets",
        "91": "// here you give the size of the matrix so that is why +1, 0 indexing is disregarded",
        "106": "//! Index Glossary",
        "107": "// X - 0 to n1 - 1",
        "108": "// Y - 0 to n2 - 1",
        "109": "// soln_mx 0 to n1 and 0 to n2",
        "110": "// LCS - 0 to n2 - 1, same as Y"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/DP_Longest_Common_Subsequence/DP_LCS_OP_1.PNG"
      ],
      "bgColors": {
        "DP_LCS_OP_1.PNG": "#202020"
      }
    },
    "DP_Matrix_Multiplication": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n//\n\nvoid initializer(int n, int matrix[][n]) //\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n  {\n    for (j = 0; j < n; j++)\n      if (j >= i)\n        matrix[i][j] = 0;\n      else\n        matrix[i][j] = -1;\n  }\n}\n\nvoid printer(int n, int matrix[][n])\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n  {\n    for (j = 0; j < n; j++)\n      if (j >= i)\n        printf(\"%d \", matrix[i][j]);\n      else\n        printf(\"  \");\n    printf(\"\\n\");\n  }\n}\n\nvoid print_parenthesis(int n, int matrix[][n], int i, int j)\n{\n  if (i == j)\n    printf(\" M%d \", i);\n  else\n  {\n    printf(\"(\");\n    print_parenthesis(n, matrix, i, matrix[i][j]);\n    print_parenthesis(n, matrix, matrix[i][j] + 1, j);\n    printf(\")\");\n  }\n}\n\nvoid main()\n{\n  int n = 0, i, j, k, min = 32767, temp, min_k, count, gap = 1; //\n  int *dims;                                                    //\n  system(\"cls\");\n\n  //\n  printf(\"Enter the number of matrices in the sequence: \");\n  scanf(\"%d\", &n);\n  dims = (int *)malloc((n + 1) * sizeof(int));\n  //\n\n  printf(\"\\n\");\n  for (i = 0; i <= n; i++)\n  {\n    printf(\"Enter P%d: \", i);\n    scanf(\"%d\", &dims[i]);\n  }\n\n  //\n  int substructure[n][n]; //\n  initializer(n, substructure);\n\n  //\n  int parenthesis[n][n];\n  initializer(n, parenthesis);\n\n  //\n  count = n - 1; //\n  while (count > 0)\n  {\n    for (i = 0, j = gap; j < n; i++, j++)\n    {\n      for (k = i; k < j; k++)\n      {\n        temp = substructure[i][k] + substructure[k + 1][j] + (dims[i] * dims[k + 1] * dims[j + 1]);\n        printf(\"\\ni = %d, j = %d, k = %d, %d\", i, j, k, temp); //\n        if (temp < min)                                        //\n        {\n          min = temp;\n          min_k = k;\n        }\n      }\n      substructure[i][j] = min;\n      parenthesis[i][j] = min_k;\n      printf(\"\\nFor cell [%d, %d], chosen value: \\033[0;32m %d units. \\033[0m\\n\", i, j, min);\n      min = 32767;\n    }\n    gap++;\n    count--;\n  }\n\n  printf(\"\\n\\nOptimal Substructure: \\n\");\n  printer(n, substructure);\n  printf(\"\\nTherefore the optimum cost for matrix chain multiplication is: \\033[1;32m %d units.\\033[0m\", substructure[0][n - 1]);\n\n  printf(\"\\n\\nParenthesization Matrix (index-based): \\n\");\n  printer(n, parenthesis);\n  printf(\"\\nTherefore, the optimal parenthesization (index-based) is: \\n\");\n\n  print_parenthesis(n, parenthesis, 0, n - 1);\n}\n",
      "comments": {
        "3": "// TBR - Towards Bottom Right (Diagonal Direction)",
        "5": "// C99 allows this, column size should be passed before the matrix",
        "49": "// setting min to effective inf., this will be resetted after each cell gets it's min",
        "50": "// gap is the difference between i and j for each diagonal",
        "53": "// take input, asking for number of matrices.",
        "57": "// UP: number of dimensions will be +1 of number of matrices needed",
        "66": "// substructure preparation",
        "67": "// C99 allows this",
        "70": "// parenthesization preparation",
        "74": "// optimization, indexing starts from zero hence a slight change in the formula",
        "75": "// number of TBR diagonals to be traversed",
        "83": "// clarification purpose",
        "84": "// of all values for all k, choosing the minimum one"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/DP_Matrix_Multiplication/DP_MCM_OP_1.png",
        "OP_ss/Sem_IV-DAOA/DP_Matrix_Multiplication/DP_MCM_OP_2.png",
        "OP_ss/Sem_IV-DAOA/DP_Matrix_Multiplication/DP_MCM_OP_3.png"
      ],
      "bgColors": {
        "DP_MCM_OP_1.png": "#181616",
        "DP_MCM_OP_2.png": "#181616",
        "DP_MCM_OP_3.png": "#181616"
      }
    },
    "Greedy_Coinchange": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n\nvoid main()\n{\n  int i, j, k = 0, noofcoins, temp, sum;\n  system(\"cls\");\n  printf(\"Enter the number of coins: \");\n  scanf(\"%d\", &noofcoins);\n  int *coins = (int *)malloc(noofcoins * sizeof(int));\n\n  printf(\"Enter the coins: (preferably descending order): \");\n  for (i = 0; i < noofcoins; i++)\n    scanf(\"%d\", &coins[i]);\n\n  for (i = 1; i < noofcoins; i++)\n    for (j = 0; j < noofcoins - i; j++)\n      if (coins[j + 1] > coins[j])\n      {\n        temp = coins[j + 1];\n        coins[j + 1] = coins[j];\n        coins[j] = temp;\n      }\n\n  printf(\"\\nEnter the Sum to be repaid: \");\n  scanf(\"%d\", &sum);\n\n  int *selected_coins = (int *)malloc(sum * sizeof(int));\n  while (sum > 0)\n  {\n    for (i = 0; i < noofcoins; i++)\n      if (coins[i] <= sum)\n      {\n        sum -= coins[i];\n        selected_coins[k++] = coins[i];\n        break;\n      }\n  }\n  printf(\"\\nSelected Coins: \");\n  for (i = 0; i < k; i++)\n    printf(\"%d \", selected_coins[i]);\n}",
      "comments": {},
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/Greedy_Coinchange/GCc_OP_1.png"
      ],
      "bgColors": {
        "GCc_OP_1.png": "#181616"
      }
    },
    "Greedy_Job_Scheduling": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct Job\n{\n  int jobno, deadline, profit;\n} Job;\n\nvoid main()\n{\n  int i, j, k, noofjobs, MDL = -1, INDL, total_profit = 0, isnc = 0;\n  Job temp;\n  printf(\"\\nEnter the number of jobs: \");\n  scanf(\"%d\", &noofjobs);\n  Job jobs[noofjobs];\n\n  printf(\"Enter the profits for each job: \");\n  for (i = 0; i < noofjobs; i++)\n    scanf(\"%d\", &jobs[i].profit);\n\n  printf(\"Enter the deadline for each job: \");\n  for (i = 0; i < noofjobs; i++)\n  {\n    scanf(\"%d\", &jobs[i].deadline);\n    if (jobs[i].deadline > MDL)\n      MDL = jobs[i].deadline;\n    jobs[i].jobno = i + 1;\n  }\n\n  for (i = 1; i < noofjobs; i++)\n    for (j = 0; j < noofjobs - i; j++)\n    {\n      if (jobs[j + 1].profit > jobs[j].profit)\n      {\n        temp = jobs[j + 1];\n        jobs[j + 1] = jobs[j];\n        jobs[j] = temp;\n      }\n    }\n\n  Job schedule[MDL];\n  Job not_completed[MDL];\n  for (i = 0; i < MDL; i++)\n    schedule[i].jobno = 0;\n\n  for (i = 0; i < noofjobs; i++)\n  {\n    INDL = jobs[i].deadline;\n    for (j = INDL - 1; j >= 0; j--)\n    {\n      if (schedule[j].jobno == 0)\n      {\n        schedule[j] = jobs[i];\n        total_profit += schedule[j].profit;\n        break;\n      }\n      if (j == 0)\n        not_completed[isnc++] = jobs[i];\n    }\n  }\n\n  printf(\"\\n\\nOptimal Job Sequence: \\n\");\n  for (i = 0; i < MDL; i++)\n    if (schedule[i].jobno != 0)\n      printf(\"J%d - Completed at %d\\n\", schedule[i].jobno, i + 1);\n\n  printf(\"Jobs not scheduled: \");\n  for (i = 0; i < isnc; i++)\n    printf(\"J%d \", not_completed[i].jobno);\n\n  printf(\"\\n\\nMaximum profit: \\033[1m\\033[38;5;223m%d units.\\033[0m\", total_profit);\n}",
      "comments": {},
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/Greedy_Job_Scheduling/GJS_OP_1.png",
        "OP_ss/Sem_IV-DAOA/Greedy_Job_Scheduling/GJS_OP_2.png"
      ],
      "bgColors": {
        "GJS_OP_1.png": "#181616",
        "GJS_OP_2.png": "#181616"
      }
    },
    "Knapsack_Problem": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n\ntypedef struct Item\n{\n  int item_no, value, weight;\n  float VW_ratio, fraction;\n} Item;\n\ntypedef struct Knapsack\n{\n  int max_capacity, curr_no_items;\n  float total_weight, curr_capacity, total_profit;\n  Item *included_item_list;\n} Sack;\n\nItem *take_items(int n)\n{\n  Item *item_list = (Item *)malloc(n * sizeof(Item));\n  int i, value, weight;\n  //\n  for (i = 0; i < n; i++)\n  {\n    printf(\"For Item %d, enter it's Profit(Vi) & Weight(Wi): \", i + 1);\n    scanf(\"%d, %d\", &value, &weight);\n    item_list[i].item_no = i + 1;\n    item_list[i].value = value;\n    item_list[i].weight = weight;\n    item_list[i].VW_ratio = (float)value / weight;\n    item_list[i].fraction = 1.0;\n  }\n\n  return item_list;\n}\n\nvoid sort_wrt_VW_ratio_descendingly(Item *item_list, int noofitems)\n{\n  int i, j;\n  Item temp;\n\n  for (i = 1; i < noofitems; i++)\n  {\n    for (j = 0; j < noofitems - i; j++)\n    {\n      if (item_list[j].VW_ratio < item_list[j + 1].VW_ratio)\n      {\n        temp = item_list[j];\n        item_list[j] = item_list[j + 1];\n        item_list[j + 1] = temp;\n      }\n    }\n  }\n}\n\nSack fill_sack(Item *item_list, int noofitems)\n{\n  int i, is_full = 0;\n  float fraction = 1.0;\n  Sack sack; //\n\n  printf(\"\\nEnter the Maximum Capacity of the Knapsack: \");\n  scanf(\"%d\", &sack.max_capacity);\n  sack.curr_capacity = sack.max_capacity;\n  sack.total_profit = 0.0;\n  sack.total_weight = 0.0;\n  sack.curr_no_items = 0;\n  sack.included_item_list = (Item *)calloc(noofitems, sizeof(Item));\n\n  for (i = 0; i < noofitems; i++)\n  {\n    if (is_full == 0)\n    {\n      if ((item_list[i].weight > sack.curr_capacity))\n      {\n        fraction = (float)(sack.max_capacity - sack.total_weight) / item_list[i].weight;\n        item_list[i].fraction = fraction;\n        is_full = 1;\n      }\n\n      sack.included_item_list[sack.curr_no_items] = item_list[i];\n      sack.curr_no_items++;\n      sack.curr_capacity -= item_list[i].weight * fraction; //\n      sack.total_profit += item_list[i].value * fraction;\n      sack.total_weight += item_list[i].weight * fraction; //\n    }\n  }\n  return sack;\n}\n\nvoid main()\n{\n  int n, i, j, k, value, weight;\n  Item *item_list = NULL;\n  Sack sack;\n  //\n  system(\"cls\");\n\n  printf(\"\\nEnter the number of items: \");\n  scanf(\"%d\", &n);\n\n  item_list = take_items(n);\n  //\n\n  printf(\"\\nInitial Table: \");\n  printf(\"\\nItem No.   Values   Weights       V/W\");\n  for (i = 0; i < n; i++)\n    printf(\"\\n  %d          %d         %d        %.2f\", item_list[i].item_no,\n           item_list[i].value,\n           item_list[i].weight,\n           item_list[i].VW_ratio);\n\n  sort_wrt_VW_ratio_descendingly(item_list, n);\n  printf(\"\\n\\nSorted Table (w.r.t V/W): \");\n  printf(\"\\nItem No.   Values   Weights       V/W\");\n  for (i = 0; i < n; i++)\n    printf(\"\\n  %d          %d         %d        %.2f\", item_list[i].item_no,\n           item_list[i].value,\n           item_list[i].weight,\n           item_list[i].VW_ratio);\n\n  sack = fill_sack(item_list, n);\n  printf(\"\\n\\nKnapsack Table (Items added to the knapsack): \");\n  printf(\"\\nItem No.     Values        Weights     Fractions\");\n  for (i = 0; i < sack.curr_no_items; i++)\n  {\n    if (sack.included_item_list[i].fraction != 1.0)\n      printf(\"\\033[1;31m\"); //\n\n    printf(\"\\n  %d          %.2f         %.2f        %.2f\", sack.included_item_list[i].item_no,\n           (float)sack.included_item_list[i].value * sack.included_item_list[i].fraction,\n           (float)sack.included_item_list[i].weight * sack.included_item_list[i].fraction,\n           sack.included_item_list[i].fraction);\n    printf(\"\\033[0m\");\n  }\n\n  printf(\"\\n\\nCurrent weight of the Knapsack: %.2f\\nProfit earned from the selected items: \\033[1;32m %.2f \\033[0m\\n\\n\", sack.total_weight, sack.total_profit);\n}",
      "comments": {
        "21": "// when you use the object (array) itself to traverse / fill the data in, use '.', if you use a pointer to that object, use ' -> '",
        "59": "// making a direct Knapsack object",
        "82": "// if the whole item is being added to the sack then multiplying the fraction (which would be 1.0) won't change anything, otherwise it will change the values as required",
        "84": "// should be equal to max_capacity ideally at the end of all iterations, can be less but not greater",
        "95": "// Item** test;  //if you really want to use '->' operator, pointer to a pointer(first index of a dynamically allocated array)",
        "102": "// test = item_list;",
        "127": "// ANSI escape sequence for formatted text, format (color) should only apply if the last item is not whole"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/Knapsack_Problem/KPS_OP_1.png"
      ],
      "bgColors": {
        "KPS_OP_1.png": "#262626"
      }
    },
    "Kruskals_Algorithm_w_Dynamic_Graph": {
      "lang": "c",
      "codeString": "//\n//\n//\n\n#include <stdio.h>\n#include <stdlib.h>\n#define MAX 30\n\ntypedef struct Graph_Edge\n{\n  int src, dest, weight; //\n} Edge;\n\ntypedef struct Graph_Node\n{\n  int data;                 //\n  int weight;               //\n  struct Graph_Node *link;  //\n  Edge indv_edge_list[MAX]; //\n  int no_of_edges;\n} Node;\n\n//\nEdge edge_list[3 * MAX];\nint total_edge_count = 0;\n\ntypedef struct Graph\n{\n  Node *head[MAX]; //\n} Graph;\n\nGraph *readGraph(int n) //\n{\n  int i, j, links, from, to, weight;\n  Graph *graph = (Graph *)malloc(sizeof(Graph));\n\n  for (i = 0; i < n; i++)\n  {\n    graph->head[i] = (Node *)malloc(sizeof(Node));\n    graph->head[i]->link = NULL;\n    graph->head[i]->data = i;\n    graph->head[i]->weight = 0; //\n\n    printf(\"\\nFor Node %d:\\n\", i);\n    printf(\"Enter the number of Edges: \");\n    scanf(\"%d\", &links);\n    graph->head[i]->no_of_edges = links;\n\n    for (j = 0; j < links; j++)\n    {\n      printf(\"Enter edge (format:- dest, weight): \");\n      scanf(\"%d, %d\", &to, &weight);\n\n      //\n      edge_list[total_edge_count].src = i;\n      edge_list[total_edge_count].dest = to;\n      edge_list[total_edge_count].weight = weight;\n      total_edge_count += 1;\n\n      //\n      graph->head[i]->indv_edge_list[j].src = i;\n      graph->head[i]->indv_edge_list[j].dest = to;\n      graph->head[i]->indv_edge_list[j].weight = weight;\n\n      Node *temp = (Node *)malloc(sizeof(Node));\n      temp->data = to;\n      temp->weight = weight; //\n      temp->link = NULL;\n\n      Node *current = graph->head[i]; //\n      while (current->link != NULL)\n        current = current->link;\n\n      current->link = temp;\n    }\n  }\n\n  return graph;\n}\n\nvoid adj_list(Graph *graph, int n)\n{\n  printf(\"Adjacency List:\\n\");\n  for (int i = 0; i < n; i++)\n  {\n    Node *p = graph->head[i];\n    for (p = graph->head[i]; p->link != NULL; p = p->link)\n    {\n      printf(\"%d (%d) --> \", p->data, p->weight);\n    }\n    printf(\"%d (%d) --> NULL\", p->data, p->weight);\n    printf(\"\\n\");\n  }\n}\n\nvoid print_edges_per_Node(Graph *graph, int n)\n{\n  int i, j;\n\n  for (i = 0; i < n; i++)\n  {\n    printf(\"\\nFor Node %d:\\n\", i);\n    for (j = 0; j < graph->head[i]->no_of_edges; j++)\n    {\n      printf(\"Source: %d, Destination: %d, Weight: %d\\n\",\n              graph->head[i]->indv_edge_list[j].src,\n              graph->head[i]->indv_edge_list[j].dest,\n              graph->head[i]->indv_edge_list[j].weight); //\n    }\n  }\n}\n\nvoid sort_edges_by_weight(Edge *total_edge_list)\n{\n  int i, j;\n  Edge temp;\n  for (i = 1; i < total_edge_count; i++)\n  {\n    for (j = 0; j < total_edge_count - i; j++)\n    {\n      if (total_edge_list[j].weight > total_edge_list[j + 1].weight)\n      {\n        temp = total_edge_list[j];\n        total_edge_list[j] = total_edge_list[j + 1];\n        total_edge_list[j + 1] = temp;\n      }\n    }\n  }\n}\n\nEdge *remove_repeats(Edge *total_edge_list, Edge *new_list)\n{\n  int i, j = 0, k = 0;\n\n  for (i = 0; i < total_edge_count; i++)\n  {\n    for (j = i + 1; j < total_edge_count; j++)\n    {\n      if ((total_edge_list[j].weight == total_edge_list[i].weight) && (total_edge_list[j].src == total_edge_list[i].dest && total_edge_list[j].dest == total_edge_list[i].src))\n      {\n        new_list[k] = total_edge_list[i];\n        k++;\n        break;\n      }\n    }\n  }\n  return new_list;\n}\n\nvoid update_parent(int *parents_array, Edge curr_edge, int noofnodes)\n{\n  int i;\n  for (i = 0; i < noofnodes; i++)\n    if (parents_array[i] == parents_array[curr_edge.dest])\n      parents_array[i] = parents_array[curr_edge.src];\n}\n\nvoid Kruskals(Edge *prcsd_edge_list, int noofnodes)\n{\n  Edge *MST = (Edge *)malloc((noofnodes - 1) * sizeof(Edge));\n  int *parents = (int *)malloc(((noofnodes) * sizeof(int)));\n  int i = 0, j, k = 0, min_cost = 0;\n\n  for (j = 0; j < noofnodes; j++)\n    parents[j] = j;\n\n  for (i = 0; i < total_edge_count / 2; i++)\n  {\n    if (k == noofnodes - 1)\n      break;\n\n    if (parents[prcsd_edge_list[i].src] != parents[prcsd_edge_list[i].dest])\n    {\n      MST[k] = prcsd_edge_list[i];\n      update_parent(parents, prcsd_edge_list[i], noofnodes);\n      k++;\n    }\n  }\n\n  printf(\"\\n\\nThe Minimum Spanning Tree: \");\n  for (j = 0; j < (noofnodes - 1); j++)\n  {\n    printf(\"\\n%d -> %d : %d\", MST[j].src, MST[j].dest, MST[j].weight);\n    min_cost += MST[j].weight;\n  }\n  printf(\"\\nCost of the Minimum Spanning Tree: %d units.\", min_cost);\n}\n\nvoid main()\n{\n  int i, j, noofnodes, count;\n  Graph *Main_Graph = NULL;\n  system(\"cls\");\n  Edge new_list[3 * MAX];\n\n  printf(\"Enter the number of Nodes required in the Graph: \");\n  scanf(\"%d\", &noofnodes);\n\n  Main_Graph = readGraph(noofnodes); //\n  printf(\"\\n\");\n\n  adj_list(Main_Graph, noofnodes); //\n  printf(\"\\n\\n\");\n\n  printf(\"\\nAll the Edges: \\n\");\n  for (i = 0; i < total_edge_count; i++)\n    printf(\"(%d, %d, %d) \", edge_list[i].src, edge_list[i].dest, edge_list[i].weight);\n\n  sort_edges_by_weight(edge_list); //\n  printf(\"\\nAll the Edges (Sorted by weights): \\n\");\n  for (i = 0; i < total_edge_count; i++)\n    printf(\"(%d, %d, %d) \", edge_list[i].src, edge_list[i].dest, edge_list[i].weight);\n\n  remove_repeats(edge_list, new_list); //\n  printf(\"\\nRepeats removed: \\n\");\n  for (i = 0; i < total_edge_count / 2; i++)\n    printf(\"(%d, %d, %d) \", new_list[i].src, new_list[i].dest, new_list[i].weight);\n\n  Kruskals(new_list, noofnodes);\n  system(\"pause\");\n}\n\n//\n//\n",
      "comments": {
        "1": "// Dynamic Graph Implementation (HN Sir method)",
        "2": "//  Here we first take in the number of nodes the graph will have.",
        "3": "//  Then we ask the edges it will make with others, along with respective weights of that edges.",
        "11": "// each edge has 3 values: source, destination and weight",
        "16": "// has the node/vertex Number",
        "17": "//! when the node is the destination, in the adjacency list the weight to get to it will be stored here",
        "18": "// address of the node the current node is connected to cause linked list",
        "19": "//?-- TRY THIS? --done",
        "23": "//! Global array for all the edges, had to keep it global cause readGraph is returning 'graph'",
        "29": "// array of Node type linked list",
        "32": "// taking in the number of nodes",
        "42": "//*each starting node's weight-to-get-to will be zero",
        "54": "//! this is essentially making a list of all the edges, global 'edge_list'",
        "60": "//! this is giving each node's edge_list a 'Edge' type data",
        "67": "// weight to get to this node",
        "70": "//*Node currently indexed by i in the head array of the Graph Structure",
        "108": "// for this one, 'source' can be removed...",
        "199": "//!",
        "202": "//!",
        "209": "//!",
        "214": "//!",
        "223": "// in the Node structure definition, I have written data and weight separately to write comments, no other reason",
        "224": "// What if each node has an array of Edges, just that it will only contain all the edges that node is the source of -- implemented"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/Kruskals_Algorithm_w_Dynamic_Graph/KDG_OP_1.png",
        "OP_ss/Sem_IV-DAOA/Kruskals_Algorithm_w_Dynamic_Graph/KDG_OP_2.png"
      ],
      "bgColors": {
        "KDG_OP_1.png": "#0c0c0c",
        "KDG_OP_2.png": "#0c0c0c"
      }
    },
    "MergeSort": {
      "lang": "py",
      "codeString": "#\nfrom numpy import floor\n\ndef mergesort(arr, lb, ub):\n\tif (lb < ub):  #\n\t\tmid = int(floor((lb + ub) / 2))\n\t\tmergesort(arr, lb, mid)\n\t\tmergesort(arr, mid + 1, ub)\n\t\taux_arr = merge(arr, lb, mid, ub)\n\ndef merge(arr, lb, mid, ub):\n\taux_arr = []  #\n\ti = lb\n\tj = mid + 1\n\n\twhile (i <= mid and j <= ub):\n\t\tif (arr[i] < arr[j]):\n\t\t\taux_arr.append(arr[i])\n\t\t\ti += 1\n\t\telse:\n\t\t\taux_arr.append(arr[j])\n\t\t\tj += 1\n\n\twhile (i <= mid):  #\n\t\taux_arr.append(arr[i])\n\t\ti += 1\n\n\twhile (j <= ub):\n\t\taux_arr.append(arr[j])\n\t\tj += 1\n\n\ti = lb\n\tj = 0\n\twhile (i <= ub):\n\t\t#\n\t\tarr[i] = aux_arr[j]\n\t\ti += 1\n\t\tj += 1\n\narray = [int(x) for x in input(\"Enter an array of numbers (Space separated): \").split()]\nmergesort(array, 0, len(array) - 1)\nprint(\"Merge-sorted Array: \", *array, sep=\" \")",
      "comments": {
        "1": "# Python program to implement Mergesorting on a given array",
        "5": "# similar to quicksorting, atleast 2 distinct array elements required",
        "12": "# auxiliary array to temporarily store sorted sub-arrays",
        "24": "# emptying sub-array if necessary",
        "35": "# main array being sorted using auxiliary array's content for each call of merge function"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/MergeSort/MS_OP_1.png"
      ],
      "bgColors": {
        "MS_OP_1.png": "#181616"
      }
    },
    "Minmax": {
      "lang": "py",
      "codeString": "def minmax(arr, lb, ub):\n  if (lb == ub):  #\n    return (arr[lb], arr[lb])\n  elif (ub - lb == 1):  #\n    if (arr[lb] < arr[ub]):\n      return (arr[lb], arr[ub])\n    else:\n      return (arr[ub], arr[lb])\n  else:  #\n    mid = (lb + ub) // 2\n    [l_sub_min, l_sub_max] = minmax(arr, lb, mid)\n    [r_sub_min, r_sub_max] = minmax(arr, mid + 1, ub)\n\n    #\n    if (l_sub_min < r_sub_min):\n      mini = l_sub_min\n    else:\n      mini = r_sub_min\n\n    if (l_sub_max < r_sub_max):\n      maxi = r_sub_max\n    else:\n      maxi = l_sub_max\n\n    return (mini, maxi)\n#\n\n\narray = [int(array_ele) for array_ele in input(\n  \"Enter the array elements\\n(Delimiter = space): \").split()]\n[mini, maxi] = minmax(array, 0, len(array) - 1)\nprint(\"\\nMaximum: {}\\nMinimum: {}\".format(maxi, mini))",
      "comments": {
        "2": "# strictly one array element in consideration",
        "4": "# strictly two array elements in consideration",
        "9": "# more than 2 elements sub-arrays",
        "14": "# For combinations, code reachable only when sub-array(s) at hand as 2 elements at the most",
        "26": "# * if block is the recursion ending statement group"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/Minmax/MM_OP_1.png"
      ],
      "bgColors": {
        "MM_OP_1.png": "#181616"
      }
    },
    "Prims_Algorithm_w_Dynamic_Graph": {
      "lang": "c",
      "codeString": "#include <stdio.h>\n#include <stdlib.h>\n#define MAX 20\n\ntypedef struct Graph_Edge\n{\n  int src, dest, weight;\n} Edge;\n\ntypedef struct Edges_array\n{\n  Edge *edge_list; //\n  int noofedges;\n} Edge_list;\n\ntypedef struct Graph_Node\n{\n  int data;\n  int weight;\n  struct Graph_Node *link;\n  Edge_list indv_edge_list;\n} Node;\n\ntypedef struct Graph\n{\n  Node *head[MAX]; //\n} Graph;\n\nGraph *readGraph(int n, Edge_list *all_edges) //\n{\n  int i, j, links, from, to, weight;\n  Graph *graph = (Graph *)malloc(sizeof(Graph));\n  all_edges->edge_list = (Edge *)malloc((n * (n - 1)) * sizeof(Edge)); //\n  all_edges->noofedges = 0;\n\n  for (i = 0; i < n; i++)\n  {\n    graph->head[i] = (Node *)malloc(sizeof(Node));\n    graph->head[i]->link = NULL;\n    graph->head[i]->data = i;\n    graph->head[i]->weight = 0;\n\n    printf(\"\\nFor Node %d:\\n\", i);\n    printf(\"Enter the number of Edges: \");\n    scanf(\"%d\", &links);\n    graph->head[i]->indv_edge_list.edge_list = (Edge *)malloc(links * sizeof(Edge));\n    graph->head[i]->indv_edge_list.noofedges = 0;\n\n    for (j = 0; j < links; j++)\n    {\n      printf(\"Enter edge (format:- dest, weight): \");\n      scanf(\"%d, %d\", &to, &weight);\n\n      //\n      graph->head[i]->indv_edge_list.edge_list[j].src = i;\n      graph->head[i]->indv_edge_list.edge_list[j].dest = to;\n      graph->head[i]->indv_edge_list.edge_list[j].weight = weight;\n      graph->head[i]->indv_edge_list.noofedges++;\n\n      Node *temp = (Node *)malloc(sizeof(Node));\n      temp->data = to;\n      temp->weight = weight;\n      temp->link = NULL;\n\n      Node *current = graph->head[i];\n      while (current->link != NULL)\n        current = current->link;\n\n      current->link = temp;\n\n      all_edges->edge_list[all_edges->noofedges].src = i;\n      all_edges->edge_list[all_edges->noofedges].dest = to;\n      all_edges->edge_list[all_edges->noofedges].weight = weight;\n      all_edges->noofedges++;\n    }\n  }\n\n  return graph;\n}\n\nvoid adj_list(Graph *graph, int n)\n{\n  printf(\"Adjacency List:\\n\");\n  for (int i = 0; i < n; i++)\n  {\n    Node *p = graph->head[i];\n    for (p = graph->head[i]; p->link != NULL; p = p->link)\n    {\n      printf(\"[%d] (%d) --> \", p->data, p->weight);\n    }\n    printf(\"[%d] (%d) --> NULL\", p->data, p->weight);\n    printf(\"\\n\");\n  }\n}\n\nEdge find_min_weight_edge(Edge_list obj1, int *included) //\n{\n  int i, s, d;\n  Edge min;\n  min.weight = 32767;\n\n  for (i = 0; i < obj1.noofedges; i++)\n  {\n    s = obj1.edge_list[i].src;\n    d = obj1.edge_list[i].dest;\n\n    if (!(included[s] == 1 && included[d] == 1))\n    {\n      if (min.weight > obj1.edge_list[i].weight)\n        min = obj1.edge_list[i];\n    }\n  }\n\n  return min;\n}\n\nEdge_list Prims(Graph *graph, int noofnodes, Edge_list all_edges)\n{\n  int i, j, k;\n  Edge min_edge;\n  Edge_list MST;\n  int *included = (int *)malloc(noofnodes * sizeof(int));\n\n  min_edge.weight = 32767; //\n  MST.edge_list = (Edge *)malloc((noofnodes - 1) * sizeof(Edge));\n  MST.noofedges = 0;\n\n  for (i = 0; i < noofnodes; i++) //\n    included[i] = 0;\n\n  min_edge = find_min_weight_edge(all_edges, included);\n  included[min_edge.src] = 1; //\n  min_edge.weight = 32767;\n\n  while (MST.noofedges != noofnodes - 1)\n  {\n    for (i = 0; i < noofnodes; i++)\n    {\n      if (included[i] == 1)\n        if (find_min_weight_edge(graph->head[i]->indv_edge_list, included).weight < min_edge.weight)\n          min_edge = find_min_weight_edge(graph->head[i]->indv_edge_list, included);\n    }\n\n    MST.edge_list[MST.noofedges] = min_edge;\n    included[min_edge.dest] = 1;\n    min_edge.weight = 32767;\n    MST.noofedges++;\n  }\n  return MST;\n}\n\nvoid main()\n{\n  int i, j, noofnodes, final_cost = 0;\n  Graph *Main_Graph = NULL;\n  Edge_list all_edges, MST;\n  Edge_list *p_all_edges = &all_edges; //\n  system(\"cls\");\n\n  printf(\"Enter the number of Nodes required in the Graph: \");\n  scanf(\"%d\", &noofnodes);\n\n  Main_Graph = readGraph(noofnodes, p_all_edges);\n  printf(\"\\n\");\n\n  adj_list(Main_Graph, noofnodes);\n  printf(\"\\n\");\n\n  printf(\"\\nAll the Edges: \\n\");\n  for (i = 0; i < all_edges.noofedges; i++)\n    printf(\"(%d, %d, %d) \", all_edges.edge_list[i].src, all_edges.edge_list[i].dest, all_edges.edge_list[i].weight);\n\n  MST = Prims(Main_Graph, noofnodes, all_edges);\n  printf(\"\\n\\nEdges included in the Minimum Spanning Tree:\");\n  for (i = 0; i < MST.noofedges; i++)\n  {\n    printf(\"\\n%d <-> %d : %d \", MST.edge_list[i].src, MST.edge_list[i].dest, MST.edge_list[i].weight);\n    final_cost += MST.edge_list[i].weight;\n  }\n  printf(\"\\n\\nCost of the Minimum Spanning Tree: \\033[1;32m%d units.\\033[0m\\n\", final_cost);\n  system(\"pause\");\n}",
      "comments": {
        "12": "// dynamic array of edges",
        "26": "// array of pointers of Node type linked list, pointers used cause malloc will be used to form a SLL",
        "29": "// taking in the number of nodes and a pointer to the object of Edge_list",
        "33": "// maximum possible total no. of edges for an directed (bidrected) graph having 'n' vertices",
        "54": "// a bit too lengthy haha",
        "96": "// returns minimum edge of a node",
        "124": "// set infinite (so that the first one is always considered minimum)",
        "128": "// for excluding already included node (in the MST) checking",
        "132": "// marking the first node (node which is the source of minimum weight among all the edges of the graph) as included.",
        "157": "// a pointer to the Edge_list object has to be made to pass it in the readGraph function and create the whole edgelist without having to return the Edge_list object as readGraph is returning a Graph* already"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/Prims_Algorithm_w_Dynamic_Graph/Prims_OP_1.png",
        "OP_ss/Sem_IV-DAOA/Prims_Algorithm_w_Dynamic_Graph/Prims_OP_2.png",
        "OP_ss/Sem_IV-DAOA/Prims_Algorithm_w_Dynamic_Graph/Prims_OP_Full.png"
      ],
      "bgColors": {
        "Prims_OP_1.png": "#0c0c0c",
        "Prims_OP_2.png": "#0c0c0c",
        "Prims_OP_Full.png": "#0c0c0c"
      }
    },
    "QuickSort": {
      "lang": "py",
      "codeString": "#\n#\n\ndef quicksort(arr, lb, ub):\n\tif (lb < ub):  #\n\t\tprev_pivot = partition(arr, lb, ub)\n\t\tquicksort(arr, lb, prev_pivot - 1)\n\t\tquicksort(arr, prev_pivot + 1, ub)\n\n\ndef partition(arr, lb, ub):\n\tstart = lb\n\tend = ub\n\t#\n\tpivot = arr[lb]\n\t#\n\n\twhile (start < end):\n\t\t#\n\t\twhile (start < (len(arr) - 1) and arr[start] <= pivot):\n\t\t\tstart += 1\n\n\t\twhile (arr[end] > pivot):\n\t\t\tend -= 1\n\n\t\tif (start < end):\n\t\t\tarr[end], arr[start] = arr[start], arr[end]\n\n\tif (arr.index(pivot) != end):  #\n\t\tarr[end], arr[lb] = arr[lb], arr[end]\n\n\treturn end  #\n\n\narray = []\nx = 0\nwhile (x != -1):\n\tx = int(input(\"Enter array element, (-1 to stop): \"))\n\tif (x != -1):\n\t\tarray.append(x)\n\nquicksort(array, 0, len(array) - 1)\n\nprint(\"\\nQuicksorted array:\", end=' ')\nfor i in array:\n\tprint(i, end=' ')",
      "comments": {
        "1": "# Python program for implementing Quicksorting on a given array (start element is the pivot) method",
        "2": "# lb ~ Lower bound, ub ~ Upper bound",
        "5": "# minimum 2 distinct elements",
        "14": "# pivot element will be the first element of the array / sub-array",
        "16": "# * start and end will change throughout the function but lb and ub will stay the same",
        "19": "# ! first condition to prevent 'out of bounds' index for the last pass",
        "29": "# to prevent self swapping, none 1 element sub-array case",
        "32": "# * end is the 'indexer' to the pivot element placed at it's sorted position"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-DAOA/QuickSort/QS_OP_1.png"
      ],
      "bgColors": {
        "QS_OP_1.png": "#181616"
      }
    }
  },
  "Sem_IV-SF": {
    "Bankers_Algorithm": {
      "lang": "py",
      "codeString": "from os import system\nfrom prettytable import PrettyTable\n\ndef take_input():\n  machine_instances = [int(i) for i in input(\"Enter the machine instances: \").split()]\n  noofprocesses = int(input(\"Enter the No. of processes: \"))\n  allocations = []\n  max_needs = []\n\n  for i in range(0, noofprocesses):\n    print(f\"\\nFor Process P{i + 1}: \")\n    temp = [int(x) for x in input(\"Enter Allocation instances: \").split()][:len(machine_instances)] #\n    allocations.append(temp)\n\n    temp = [int(x) for x in input(\"Enter Max Need instances: \").split()][:len(machine_instances)]\n    max_needs.append(temp)\n\n  return machine_instances, allocations, max_needs\n\ndef calculate_available_inst_1(machine_instances, allocations):\n  sumof_allocations = []\n  col_sum = 0\n  \n  for i in range(0, len(machine_instances)):\n    for j in range(0, len(allocations)):\n      col_sum += allocations[j][i]\n    sumof_allocations.append(col_sum)\n    col_sum = 0\n  \n  return ([k - l for k, l in zip(machine_instances, sumof_allocations)])\n\ndef calculate_remaining_needs(max_needs, allocations):\n  remaining_needs = []\n  \n  for i, j in zip(max_needs, allocations):\n    indv_remaining_needs = [k - l for k, l in zip(i, j)]\n    remaining_needs.append(indv_remaining_needs)\n  \n  return remaining_needs\n\ndef table_print(allocations, max_needs, remaining_needs):\n  noofprocesses = len(max_needs)\n  Table = PrettyTable([\"Process No\", \"Allocation\", \"Max\", \"Remaining\"])\n  \n  for i in range(noofprocesses):\n    allocations_str = \"\"\n    for c in allocations[i]:\n      allocations_str += (str(c) + \" \")\n    \n    max_needs_str = \"\"\n    for c in max_needs[i]:\n      max_needs_str += (str(c) + \" \")\n    \n    remaining_needs_str = \"\"\n    for c in remaining_needs[i]:\n      remaining_needs_str += (str(c) + \" \")\n    \n    Table.add_row([i + 1, allocations_str, max_needs_str, remaining_needs_str])\n  \n  return Table\n\ndef bankers_algorithm():\n  system(\"cls\")\n  machine_instances, allocations, max_needs = take_input()\n  remaining_needs = calculate_remaining_needs(max_needs, allocations)\n  available = []\n  available.append(calculate_available_inst_1(machine_instances, allocations))\n  noofprocesses = len(max_needs)\n  \n  Table = table_print(allocations, max_needs, remaining_needs)\n  print(\"\\033[1m\\033[4m\\033[38;5;177mGiven Information:\\033[0m\\n\")\n  print(Table)\n  print(\"Initial available resources: \", available[0])\n\n  i = 0\n  j = 0\n  deadlock = 0\n  scheduled = 0\n  prev_cycle_scheduled = 0\n  schd_list = []\n  is_completed = [False for i in allocations]\n\n  while(deadlock != 1 and (scheduled != noofprocesses)): #\n    if(is_completed[i] == False):\n      pa = allocations[i]\n      rn = remaining_needs[i]\n      av = available[j]\n      can_fulfill = True\n\n      for m, n in zip(rn, av):\n        if m > n:\n          can_fulfill = False\n      \n      if(can_fulfill == True):\n        available.append((lambda a, b: [k + l for k, l in zip(a, b)])(pa, av)) #\n        j += 1\n        is_completed[i] = True\n        scheduled += 1\n        schd_list.append(i + 1)\n\n    i += 1    \n    if(i == noofprocesses):  \n      if(prev_cycle_scheduled == scheduled):\n        deadlock = 1\n      else:\n        prev_cycle_scheduled = scheduled\n        i = 0\n  \n  if deadlock == 1:\n    print(\"\\n\\033[1m\\033[38;5;196mDeadlock Occurred! The system is in an unsafe state!\\033[0m\")\n  else:\n    print(\"\\n\\033[1m\\033[38;5;158mThe system is in a safe state!\\n\\033[38;5;225m\\033[4mSafe sequence:\\033[0m\")\n    for i in schd_list:\n      if i != schd_list[-1]:\n        print(\"P\" + str(i) + \"\\033[38;5;216m \u2b9e \\033[0m\", end = \"\")\n      else:\n        print(\"P\" + str(i))\n\nbankers_algorithm()",
      "comments": {
        "12": "#! slicing done to prevent overfilling",
        "83": "#* while it is not a deadlock and not all processes have been scheduled",
        "95": "#* returns a list which has the sum of individual elements of pa and av"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Bankers_Algorithm/BaA_OP_1.png",
        "OP_ss/Sem_IV-SF/Bankers_Algorithm/BaA_OP_2.png"
      ],
      "bgColors": {
        "BaA_OP_1.png": "#181616",
        "BaA_OP_2.png": "#181616"
      }
    },
    "Booths_Algorithm": {
      "lang": "py",
      "codeString": "from prettytable import PrettyTable\nfrom os import system\nsystem(\"cls\")\n\ndef take_input():\n  mcand = int(input(\"Enter the Multiplicand: \"))\n  mlier = int(input(\"Enter the Multiplier: \"))\n\n  return mcand, mlier\n\ndef to_binary(*dec_number):\n  bin_master_list = []\n\n  def mechanism(dec_number):\n    if (dec_number >= 1):\n      mechanism(dec_number // 2)\n      bin_num.append(dec_number % 2)\n\n  for i in dec_number:\n    bin_num = []\n    mechanism(i)\n    bin_master_list.append(bin_num)\n\n  return bin_master_list\n\ndef dynamic_bit_adjuster(list1, list2):\n  l1 = len(list1)\n  l2 = len(list2)\n\n  if (l1 != l2):\n    if (l1 > l2):\n      list1.insert(0, 0)\n      for i in range(l2, l1 + 1):\n        list2.insert(0, 0)\n\n    elif (l2 > l1):\n      list2.insert(0, 0)\n      for i in range(l1, l2 + 1):\n        list1.insert(0, 0)\n  else:\n    list1.insert(0, 0)\n    list2.insert(0, 0)\n\n\ndef ones_complement(binary_num_list):\n  for i in range(0, len(binary_num_list)):\n    if binary_num_list[i] == 0:\n      binary_num_list[i] = 1\n    else:\n      binary_num_list[i] = 0\n\ndef binary_add(list1, list2):\n  carry = 0\n\n  for i in range(len(list1) - 1, -1, -1):  #\n    if (carry == 0):\n      if (list1[i] == 0 and list2[i] == 0):\n        list1[i] = 0\n      elif (list1[i] == 0 and list2[i] == 1):\n        list1[i] = 1\n      elif (list1[i] == 1 and list2[i] == 0):\n        list1[i] = 1\n      elif (list1[i] == 1 and list2[i] == 1):\n        list1[i] = 0\n        carry = 1  #\n\n    elif (carry == 1):\n      if (list1[i] == 0 and list2[i] == 0):\n        list1[i] = 1\n        carry = 0\n\n      elif (list1[i] == 0 and list2[i] == 1):\n        list1[i] = 0\n        carry = 1\n\n      elif (list1[i] == 1 and list2[i] == 0):\n        list1[i] = 0\n        carry = 1\n\n      elif (list1[1] == 1 and list2[i] == 1):\n        list1[i] = 1\n        carry = 1  #\n\ndef twos_complement(list1):\n  one = [1]\n  for i in range(0, len(list1)-1):\n    one.insert(0, 0)\n\n  ones_complement(list1)\n  binary_add(list1, one)\n\ndef ar_right_shift(list1, list2):\n  temp_bit1 = list1[-1]\n  temp_bit2 = list2[-1]  #\n  temp_copy1 = list1.copy()\n  temp_copy2 = list2.copy()\n\n  for i in range(1, len(list1)):\n    list1[i] = temp_copy1[i - 1]\n    list2[i] = temp_copy2[i - 1]\n  list2[0] = temp_bit1\n\n  return temp_bit2\n\ndef list_to_string(list1):\n  string = \"\"\n  for i in list1:\n    string += str(i)\n\n  return string\n\ndef to_decimal(list1, list2, dec_mcand, dec_mlier):\n  list3 = list1 + list2\n  expo = 0\n  summation = 0\n\n  if ((dec_mcand < 0 and dec_mlier > 0) or (dec_mlier < 0 and dec_mcand > 0)):\n    twos_complement(list3)\n\n  for i in range(len(list3)-1, -1, -1):\n    if (list3[i] == 1):\n      summation += 2**(expo)\n    expo += 1\n\n  return summation\n\ndef Booths_Algorithm():\n  #\n  dec_mcand, dec_mlier = take_input()\n\n  #\n  if dec_mcand == 0 or dec_mlier == 0:\n    print(\"Final Answer\\n{} x {} = {}\".format(dec_mcand, dec_mlier, 0))\n    return 0\n\n  #\n  bin_nums = to_binary(abs(dec_mcand), abs(dec_mlier))\n  bin_mcand = bin_nums[0]\n  bin_mlier = bin_nums[1]\n\n  #\n  dynamic_bit_adjuster(bin_mcand, bin_mlier)\n\n  #\n  if (dec_mcand < 0):\n    twos_complement(bin_mcand)\n  if (dec_mlier < 0):\n    twos_complement(bin_mlier)\n\n  #\n  A = [0 for i in range(0, len(bin_mcand))]\n  Q = bin_mlier.copy()\n  M = bin_mcand.copy()\n  twos_complement(bin_mcand)  #\n  m_M = bin_mcand.copy()\n  Qm1 = 0  #\n  count = len(bin_mcand)\n  table = PrettyTable([\"A\", \"Q\", \"Q_-1\", \"Count\", \"Operation\"])\n  final_table = [[list_to_string(A), list_to_string(Q), Qm1, count, \"Start\"]]\n\n  while (count > 0):\n    if (Q[-1] == 1 and Qm1 == 0):\n      binary_add(A, m_M)\n      #\n      final_table.append(\n        [list_to_string(A), list_to_string(Q), Qm1, count, \"A = A - M\"])\n\n    elif (Q[-1] == 0 and Qm1 == 1):\n      binary_add(A, M)\n      final_table.append(\n        [list_to_string(A), list_to_string(Q), Qm1, count, \"A = A + M\"])\n\n    Qm1 = ar_right_shift(A, Q)\n    final_table.append([list_to_string(A), list_to_string(\n      Q), Qm1, count, \"Arithmetic Right Shift\"])\n    count -= 1\n\n  #\n  final_table.append(['', '', '', '', \"Finish\"])\n  table.add_rows(final_table)\n  print(table)\n\n  #\n  f_a = to_decimal(A, Q, dec_mcand, dec_mlier)\n  if ((dec_mcand < 0 and dec_mlier > 0) or (dec_mlier < 0 and dec_mcand > 0)):\n    print(\"\\nFinal Answer:\\n{} x {} = -{}\".format(dec_mcand, dec_mlier, f_a))\n  else:\n    print(\"\\nFinal Answer:\\n{} x {} = {}\".format(dec_mcand, dec_mlier, f_a))\n\n\nBooths_Algorithm()\n",
      "comments": {
        "55": "# reverse traversal",
        "65": "# ! Quite important",
        "82": "# ! Quite important",
        "94": "# last bits",
        "128": "# taking input",
        "131": "# check for input 0",
        "136": "# coversion from decimal to binary for both inputs",
        "141": "# adjusting bits for both multiplicand and multiplier",
        "144": "# taking twos-complement if negative",
        "150": "# preparation for the main algorithm",
        "154": "# this WILL change bin_mcand",
        "156": "# Q_minus_1 bit",
        "164": "# have to convert to string to mitigate reference assignment of modified list",
        "178": "# printing the Operations table",
        "183": "# printing the final answer"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Booths_Algorithm/BA_OP_1.png"
      ],
      "bgColors": {
        "BA_OP_1.png": "#181616"
      }
    },
    "Disk_Scheduling": {
      "lang": "py",
      "codeString": "import numpy as np\nfrom os import system\n\ndef take_input():\n  req_sequence = [int(i) for i in input(\"Enter the request sequence: \").split()]\n  initial_rest = int(input(\"Enter the initial resting of the head: \"))\n  seek_multiplier = int(input(\"Enter the cost for travelling a single track: \"))\n  total_nooftracks = int(input(\"Enter the total number of tracks available: \"))\n\n  return req_sequence, initial_rest, seek_multiplier, total_nooftracks\n\ndef final_ans(total_seek_time, disk_schedule, initial_rest, algo_name):\n  print(\"\\033[1m\\033[4m\\033[38;5;229m\" + str(algo_name) + \"\\033[0m\")\n  print(\"\\033[1m\\033[38;5;85mDisk Pointer Trace: \\033[0m\")\n  print(\"\\033[1m\\033[38;5;213m\"+ str(initial_rest) + \"\\033[0m -> \", end = \"\")\n  for i in disk_schedule:\n    if i != disk_schedule[-1]:\n      print(i, \"-> \", end = \"\")\n    else:\n      print(i)\n  \n  print(\"Total Seek Time: \\033[1m\\033[4m\\033[38;5;217m\"+ str(total_seek_time) + \"\\033[0m msecs\\n\\n\")\n\ndef fcfs_dschd(req_sequence, curr_rest, per_track_seek_cost, total_nooftracks = 200):\n  initial_rest = curr_rest\n  total_seek_time = 0\n  disk_schedule = []\n\n  for i in req_sequence:\n    disk_schedule.append(i)\n    total_seek_time += np.abs(i - curr_rest) * per_track_seek_cost\n    curr_rest = i \n\n  final_ans(total_seek_time, disk_schedule, initial_rest, \"First Come First Serve (FCFS)\")\n\ndef sstf_dschd(req_sequence, curr_rest, per_track_seek_cost, total_nooftracks = 200):\n  initial_rest = curr_rest\n  total_seek_time = 0\n  nooftracks = len(req_sequence)\n  min_cost = 9999\n  to_schd = -1\n  temp_cost = 0\n  disk_schedule = []\n\n  while len(disk_schedule) != nooftracks:\n    for i in req_sequence:\n      temp_cost = np.abs(i - curr_rest) * per_track_seek_cost\n      if temp_cost < min_cost:\n        min_cost = temp_cost\n        to_schd = i\n        \n    req_sequence.remove(to_schd)\n    total_seek_time += min_cost\n    min_cost = 9999\n    disk_schedule.append(to_schd)\n    curr_rest = to_schd\n\n  final_ans(total_seek_time, disk_schedule, initial_rest, \"Shortest Seek Time First (SSTF)\")\n\ndef scan_dschd(req_sequence, curr_rest, per_track_seek_cost, total_nooftracks = 200):\n  initial_rest = curr_rest\n  total_seek_time = 0\n  disk_schedule = []\n  \n  sorted_req_sequence = list(sorted(req_sequence))\n  left_tracks = [i for i in sorted_req_sequence if i < curr_rest]\n  right_tracks = [i for i in sorted_req_sequence if i > curr_rest]\n  \n  #\n  diff_1 = curr_rest - 0\n  diff_2 = (total_nooftracks - 1) - curr_rest\n  \n  if(diff_1 <= diff_2):\n    left_tracks.insert(0, 0)\n    for i in range(len(left_tracks) - 1, -1, -1): #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += (curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n    for i in range(0, len(right_tracks)):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += (right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n  \n  else:\n    right_tracks.append(total_nooftracks - 1)\n    for i in range(0, len(right_tracks)):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += (right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n\n    for i in range(len(left_tracks) - 1, -1, -1):   #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += (curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n  final_ans(total_seek_time, disk_schedule, initial_rest, \"SCAN\")\n\ndef cscan_dschd(req_sequence, curr_rest, per_track_seek_cost, total_nooftracks = 200):\n  initial_rest = curr_rest\n  total_seek_time = 0\n  disk_schedule = []\n  \n  sorted_req_sequence = list(sorted(req_sequence))\n  left_tracks = [i for i in sorted_req_sequence if i < curr_rest]\n  right_tracks = [i for i in sorted_req_sequence if i > curr_rest]\n  \n  #\n  diff_1 = curr_rest - 0\n  diff_2 = (total_nooftracks - 1) - curr_rest\n\n  if(diff_1 <= diff_2): #\n    left_tracks.insert(0, 0)\n    for i in range(len(left_tracks) - 1, -1, -1):           #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += np.abs(curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n    curr_rest = total_nooftracks - 1                       #\n    for i in range(len(right_tracks) - 1, -1, -1):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += np.abs(right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n  \n  else: #\n    right_tracks.append(total_nooftracks - 1)\n    for i in range(0, len(right_tracks)):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += np.abs(right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n    \n    curr_rest = 0                                       #\n    for i in range(0, len(left_tracks)):         #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += np.abs(curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n  final_ans(total_seek_time, disk_schedule, initial_rest, \"C-SCAN\")\n\ndef look_dschd(req_sequence, curr_rest, per_track_seek_cost, total_nooftracks = 200):\n  initial_rest = curr_rest\n  total_seek_time = 0\n  disk_schedule = []\n  \n  sorted_req_sequence = list(sorted(req_sequence))\n  left_tracks = [i for i in sorted_req_sequence if i < curr_rest]\n  right_tracks = [i for i in sorted_req_sequence if i > curr_rest]\n  \n  #\n  diff_1 = curr_rest - 0\n  diff_2 = (total_nooftracks - 1) - curr_rest\n  \n  if(diff_1 <= diff_2):\n    for i in range(len(left_tracks) - 1, -1, -1): #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += (curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n    for i in range(0, len(right_tracks)):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += (right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n  \n  else:\n    for i in range(0, len(right_tracks)):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += (right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n\n    for i in range(len(left_tracks) - 1, -1, -1):   #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += (curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n  final_ans(total_seek_time, disk_schedule, initial_rest, \"LOOK\")\n\ndef clook_dschd(req_sequence, curr_rest, per_track_seek_cost, total_nooftracks = 200):\n  initial_rest = curr_rest\n  total_seek_time = 0\n  disk_schedule = []\n  \n  sorted_req_sequence = list(sorted(req_sequence))\n  left_tracks = [i for i in sorted_req_sequence if i < curr_rest]\n  right_tracks = [i for i in sorted_req_sequence if i > curr_rest]\n  \n  #\n  diff_1 = curr_rest - 0\n  diff_2 = (total_nooftracks - 1) - curr_rest\n\n  if(diff_1 <= diff_2): #\n    for i in range(len(left_tracks) - 1, -1, -1):           #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += np.abs(curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n    curr_rest = right_tracks[-1]               #\n    for i in range(len(right_tracks) - 1, -1, -1):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += np.abs(right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n\n  else: #\n    for i in range(0, len(right_tracks)):         #\n      disk_schedule.append(right_tracks[i])\n      total_seek_time += np.abs(right_tracks[i] - curr_rest) * per_track_seek_cost\n      curr_rest = right_tracks[i]\n    \n    curr_rest = left_tracks[0]                  #\n    for i in range(0, len(left_tracks)):   #\n      disk_schedule.append(left_tracks[i])\n      total_seek_time += np.abs(curr_rest - left_tracks[i]) * per_track_seek_cost\n      curr_rest = left_tracks[i]\n\n  final_ans(total_seek_time, disk_schedule, initial_rest, \"C-LOOK\")\n\ndef caller():\n  system(\"cls\")\n  req_sequence, initial_rest, seek_multiplier, total_nooftracks = take_input()\n  backup_req_sequence = list(req_sequence)\n  print(\"\\n\\033[1m\\033[38;5;183mThis program chooses the direction of scheduling by determining the nearest end from the initial resting and going towards the nearer one.\\nAlso, in C-SCAN and C-LOOK, this program is not counting the end-to-end track change.\\n\\033[0m\")\n  algorithms = {\"1\": fcfs_dschd, \"2\": sstf_dschd, \"3\": scan_dschd, \"4\": cscan_dschd, \"5\": look_dschd, \"6\":clook_dschd}\n  for i in algorithms:\n      algorithms[i](req_sequence, initial_rest, seek_multiplier, total_nooftracks)\n      req_sequence = list(backup_req_sequence)\n\ncaller()",
      "comments": {
        "69": "#* to choose side, nearest end is chosen",
        "75": "#? reverse traversing the left tracks first",
        "80": "#? then go for the right tracks ascendingly",
        "87": "#* go for the right tracks first ascendingly",
        "92": "#* then go for the left tracks descendingly",
        "108": "#* to choose side, nearest end is chosen",
        "112": "#! left side",
        "114": "#? reverse traversing the left tracks first",
        "119": "#! Do not penalize for ends-change step",
        "120": "#? then go for the right tracks also reverse",
        "125": "#! right side",
        "127": "#* go for the right tracks first ascendingly",
        "132": "#! Do not penalize for ends-change step",
        "133": "#* then go for the left tracks also ascendingly",
        "149": "#* to choose side, nearest end is chosen",
        "154": "#? reverse traversing the left tracks first",
        "159": "#? then go for the right tracks ascendingly",
        "165": "#* go for the right tracks first ascendingly",
        "170": "#* then go for the left tracks descendingly",
        "186": "#* to choose side, nearest end is chosen",
        "190": "#! left side",
        "191": "#? reverse traversing the left tracks first",
        "196": "#! Do not penalize (or penalize less (alpha)) for ends-change step, also end is not the last track but the last requested track",
        "197": "#? then go for the right tracks also reverse",
        "202": "#! right side",
        "203": "#* go for the right tracks first ascendingly",
        "208": "#!",
        "209": "#* then go for the left tracks also ascendingly"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Disk_Scheduling/DS_OP_1.png",
        "OP_ss/Sem_IV-SF/Disk_Scheduling/DS_OP_2.png"
      ],
      "bgColors": {
        "DS_OP_1.png": "#181616",
        "DS_OP_2.png": "#181616"
      }
    },
    "Fixed_Memory_Placement(Static)": {
      "lang": "py",
      "codeString": "from os import system\ndef take_input():\n  memory = [[int(i), 0, 0, False] for i in input(\"Enter memory block sizes: \").split()]\n  processes = [[int(i), False] for i in input(\"Enter processes' sizes: \").split()]\n\n  return memory, processes\n\ndef print_memory(memory, processes):\n  print(\"============================ Main Memory =============================\\nBlock No.\\tBlock Size\\tFilled Process\\tInternal Fragmentation\")\n  for block in memory:\n    if(block[3] == True):\n      print(\"  {}\\t        \\033[1;32m   {}\\t\\t   {}\\t\\t    {}\\033[0m\".format((memory.index(block) + 1), block[0], block[1], block[2]))\n    elif(block[3] == -1 or block[3] == False):\n      print(\"  {}\\t        \\033[1;31m   {}\\t\\t   {}\\t\\t    {}\\033[0m\".format((memory.index(block) + 1), block[0], block[1], block[2]))\n\n  print(\"Total Internal Fragmentation (Memory Loss) incurred: \\033[1;31m\", sum(i[2] for i in memory), \"kB\\033[0m\")\n\n  print(\"Unassigned processes: \", end = \" \")\n  unassigned = [i for i in processes if i[1] == False]\n  for i in unassigned:\n    print(str(i[0]) + \" kB\", end = \" \")\n\ndef reset(memory, processes):\n  for block in memory:\n    block[1] = 0\n    block[2] = 0\n    block[3] = False\n\n  for process in processes:\n    process[1] = False\n\ndef first_fit(memory, processes):\n  for process in processes:\n    for block in memory:\n      if block[0] >= process[0] and block[3] == False:\n        block[1] = process[0]                   #\n        block[2] = block[0] - process[0]        #\n        block[3] = True                         #\n        process[1] = True\n        break\n  print(\"\\033[1;34m After applying First-Fit\\033[0m\")\n  print_memory(memory, processes)\n\ndef best_fit(memory, processes):\n  wastages = []\n\n  for process in processes:\n    for block in memory:\n      if block[0] >= process[0] and block[3] == False:\n        wastages.append(block[0] - process[0])\n\n    if len(wastages) != 0:    \n      least_waste = min(wastages)\n      for block in memory:\n        if block[0] - process[0] == least_waste:\n          block[1] = process[0]              \n          block[2] = block[0] - process[0]        \n          block[3] = True                       \n          process[1] = True\n          break\n\n    wastages = []\n  print(\"\\033[1;34m After applying Best-Fit\\033[0m\")\n  print_memory(memory, processes)\n\ndef worst_fit(memory, processes):\n  wastages = []\n\n  for process in processes:\n    for block in memory:\n      if block[0] >= process[0] and block[3] == False:\n        wastages.append(block[0] - process[0])\n\n    if len(wastages) != 0:    \n      max_waste = max(wastages)\n      for block in memory:\n        if block[0] - process[0] == max_waste:\n          block[1] = process[0]              \n          block[2] = block[0] - process[0]        \n          block[3] = True                       \n          process[1] = True\n          break\n\n    wastages = []    \n  print(\"\\033[1;34m After applying Worst-Fit\\033[0m\")\n  print_memory(memory, processes)\n\ndef switch_case(memory, processes):\n  fit_choices = {\"1\": first_fit, \"2\": best_fit, \"3\": worst_fit}\n  choice = input(\"\\n1. First-Fit\\n2. Best-Fit\\n3. Worst-Fit: \")\n  fit_choices[choice](memory, processes)\n\ndef fit_again(memory, processes):\n  choice = int(input(\"\\n\\nTry another Fit?\\n(0. No, 1. Yes): \"))\n  if choice == 1:\n    choice2 = int(input(\"With new processes?\\n(0. No, 1. Yes): \"))\n    if choice2 == 1:\n      caller()\n    else:\n      reset(memory, processes)\n      switch_case(memory, processes)\n      fit_again(memory, processes)\n\ndef caller():\n  system(\"cls\")\n  memory, processes = take_input()\n  switch_case(memory, processes)\n  fit_again(memory, processes) \n\ncaller()",
      "comments": {
        "36": "#actually what is filled in the block",
        "37": "#what is the wastage",
        "38": "#status_check = True, this block cannot be used again?"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Fixed_Memory_Placement(Static)/FMP_BF_OP_1.png",
        "OP_ss/Sem_IV-SF/Fixed_Memory_Placement(Static)/FMP_FF_OP_1.png",
        "OP_ss/Sem_IV-SF/Fixed_Memory_Placement(Static)/FMP_WF_OP_1.png"
      ],
      "bgColors": {
        "FMP_BF_OP_1.png": "#181616",
        "FMP_FF_OP_1.png": "#181616",
        "FMP_WF_OP_1.png": "#181616"
      }
    },
    "Memory_Page_Replacement": {
      "lang": "py",
      "codeString": "from os import system\n\ndef take_input():\n  ref_string = [int(i) for i in input(\"Enter the Reference String: \").split()]\n  memory = [-1 for i in range(0, int(input(\"Enter the no. of frames in the memory: \")))]\n\n  return ref_string, memory\n\ndef fifo_page_rpmt(ref_string, memory):\n  faults = 0\n  hits = 0\n  to_place_index = 0\n  flag = 0\n  noofrefs = len(ref_string)\n  noofframes = len(memory)\n  print(\"\\n\")\n\n  for ref in ref_string:\n    for frame in memory:\n      if(frame == ref):\n        hits += 1\n        flag = 1\n    \n    if(flag == 0):\n      faults += 1\n      memory[to_place_index] = ref\n      to_place_index = (to_place_index + 1) % (noofframes)\n    flag = 0                    \n    print(\"| Reference: \\033[1m\\033[38;5;117m{}\\033[0m | Current Memory: {} | Fault count: \\033[1m\\033[38;5;196m{}\\033[0m | Hit count: \\033[1m\\033[38;5;156m{}\\033[0m\".format(ref, memory, faults, hits))\n  \n  print(\"\\n\\033[1m\\033[4m\\033[38;5;122mResults\\033[0m\")\n  print(f\"No. of Hits: \\033[38;5;156m{hits}\\033[0m\\nNo. of Faults(Miss): \\033[38;5;196m{faults}\\033[0m\\nHit Ratio: \\033[38;5;156m{hits}/{noofrefs}\\033[0m\\nFault(Miss) Ratio: \\033[38;5;196m{faults}/{noofrefs}\\033[0m\\n\")\n\ndef lru_page_rpmt(ref_string, memory):\n  faults = 0\n  hits = 0\n  to_place_index = 0\n  flag = 0\n  noofrefs = len(ref_string)\n  page_in_frame_age = [(i + 996) for i in range(len(memory)-1, -1, -1)]\n  print(\"\\n\")\n\n  for ref in ref_string:\n    for frame in memory:\n      if(frame == ref):\n        hits += 1\n        page_in_frame_age[memory.index(ref)] = 0        #\n        flag = 1\n\n    if(flag == 0):\n      faults += 1\n      to_place_index = page_in_frame_age.index(max(page_in_frame_age))\n      page_in_frame_age[to_place_index] = 0 \n      memory[to_place_index] = ref\n    flag = 0    \n    page_in_frame_age = list(map(lambda x: x + 1, page_in_frame_age)) #\n    print(\"| Reference: \\033[1m\\033[38;5;117m{}\\033[0m | Current Memory: {} | Fault count: \\033[1m\\033[38;5;196m{}\\033[0m | Hit count: \\033[1m\\033[38;5;156m{}\\033[0m\".format(ref, memory, faults, hits))\n\n  print(\"\\n\\033[1m\\033[4m\\033[38;5;122mResults\\033[0m\")\n  print(f\"No. of Hits: \\033[38;5;156m{hits}\\033[0m\\nNo. of Faults(Miss): \\033[38;5;196m{faults}\\033[0m\\nHit Ratio: \\033[38;5;156m{hits}/{noofrefs}\\033[0m\\nFault(Miss) Ratio: \\033[38;5;196m{faults}/{noofrefs}\\033[0m\\n\")\n\ndef optimal_page_rpmt(ref_string, memory):\n  faults = 0\n  hits = 0\n  to_place_index = 0\n  flag = 0\n  noofrefs = len(ref_string)\n  curr_pages_in_frames_future = [-1 for i in memory]\n  \n  def find_future_occurence():\n    for i in range(0, len(memory)):\n      try:\n        curr_pages_in_frames_future[i] = ref_string[curr_index:].index(memory[i])\n      except ValueError:                          #\n        curr_pages_in_frames_future[i] = 999\n  \n  curr_index = 0    #\n  for ref in ref_string:\n    for frame in memory:\n      if(frame == ref):\n        hits += 1\n        flag = 1\n\n    if(flag == 0):\n      faults += 1\n      find_future_occurence()\n      to_place_index = curr_pages_in_frames_future.index(max(curr_pages_in_frames_future))\n      memory[to_place_index] = ref\n    flag = 0\n    curr_index += 1\n    \n    print(\"| Reference: \\033[1m\\033[38;5;117m{}\\033[0m | Current Memory: {} | Fault count: \\033[1m\\033[38;5;196m{}\\033[0m | Hit count: \\033[1m\\033[38;5;156m{}\\033[0m\".format(ref, memory, faults, hits))\n\n  print(\"\\n\\033[1m\\033[4m\\033[38;5;122mResults\\033[0m\")\n  print(f\"No. of Hits: \\033[38;5;156m{hits}\\033[0m\\nNo. of Faults(Miss): \\033[38;5;196m{faults}\\033[0m\\nHit Ratio: \\033[38;5;156m{hits}/{noofrefs}\\033[0m\\nFault(Miss) Ratio: \\033[38;5;196m{faults}/{noofrefs}\\033[0m\\n\")\n\ndef caller():\n  system(\"cls\")\n  ref_string, memory = take_input()\n  algorithms = {1: fifo_page_rpmt, 2: lru_page_rpmt, 3: optimal_page_rpmt}\n  algorithms[int(input(\"Enter the algorithm to be used:\\n1. FIFO\\n2. LRU\\n3. Optimal: \"))](ref_string, memory) #\n\ncaller()",
      "comments": {
        "47": "#! resetting age, when hit",
        "56": "#! incrementing all pages in frame's age at the end of each iteration",
        "74": "#there is no future occurence of page in frame in memory[i], highest priority to replace",
        "77": "#simpler to control the for-in loop in this case",
        "101": "#! calling a value of the dictionary which is a function hence parameters are also passed here"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Memory_Page_Replacement/MPR_FIFO_OP_1.png",
        "OP_ss/Sem_IV-SF/Memory_Page_Replacement/MPR_LRU_OP_1.png",
        "OP_ss/Sem_IV-SF/Memory_Page_Replacement/MPR_Opt_OP_1.png"
      ],
      "bgColors": {
        "MPR_FIFO_OP_1.png": "#181616",
        "MPR_LRU_OP_1.png": "#181616",
        "MPR_Opt_OP_1.png": "#181616"
      }
    },
    "Non_Preemptive_Task_Scheduling": {
      "lang": "py",
      "codeString": "from os import system\nimport numpy as np\nimport pandas as pd\n\ndef take_input():\n  data = []\n  no_of_process = int(input(\"Enter the number of processes: \"))\n  if no_of_process <= 0:\n    print(\"Exiting...\")\n    exit()\n\n  for i in range(1, no_of_process + 1):\n    arr_time = int(\n      input(\"Enter the Arrival Time for Process {}: \".format(i)))\n    burst_time = int(\n      input(\"Enter the Burst Time for Process {}: \".format(i)))\n    priority = int(input(\"Enter the Priority for Process {}: \".format(i)))\n    temp_dict = {'Process No.': i, 'Arrival Time': arr_time,\n                  'Burst Time': burst_time, 'Priority': priority}\n    data.append(temp_dict)\n\n  schd_type = int(\n    input(\"Enter the type of Scheduling Algorithm:\\n1. FCFS\\n2. SJF\\nChoice: \"))\n\n  return data, schd_type\n\ndef sort_df(data_frame, by_parameter):\n  sorted_df = data_frame.sort_values(by=by_parameter)\n  #\n  sorted_df.reset_index(inplace=True, drop=True)\n  return sorted_df\n\ndef sorted_process_list(sorted_df):\n  process_list = []\n\n  for i in range(0, len(sorted_df)):\n    process_list.append([sorted_df['Process No.'][i], sorted_df['Arrival Time']\n                          [i], sorted_df['Burst Time'][i], sorted_df['Priority'][i]])\n\n  return process_list\n\ndef redone_gantt_chart(sorted_schd_list, passed_time=0):\n  end_times = []\n  gantt_list = []\n  passed_time = 0\n\n  def redone_match_ATPT(curr_passed_time, next_arr_time):\n    if curr_passed_time < next_arr_time:\n      if curr_passed_time == 0:\n        gantt_list.extend([curr_passed_time, \"idle\", next_arr_time])\n      else:\n        gantt_list.extend(['idle', next_arr_time])\n      return next_arr_time\n    elif curr_passed_time == 0:\n      gantt_list.append(curr_passed_time)\n    return curr_passed_time\n\n  for i in sorted_schd_list:\n    passed_time = redone_match_ATPT(passed_time, i[1])\n    passed_time += i[2]\n    gantt_list.extend(['P' + str(i[0]), passed_time])\n    end_times.append(passed_time)\n\n  def print_gantt(gantt_list):\n    for i in gantt_list:\n        if i != gantt_list[-1]:\n          print(i, \"-> \", end=\"\")\n        else:\n          print(i)\n  print_gantt(gantt_list)\n\n  return end_times\n\ndef turnaround_time(sorted_df):\n  indv_TAT = []\n\n  for i in range(0, len(sorted_df)):\n    pFT = sorted_df[\"Finish Time\"][i]\n    aT = sorted_df[\"Arrival Time\"][i]\n    indv_TAT.append(pFT - aT)\n\n  avg_TAT = np.average(indv_TAT)\n  sorted_df[\"Turnaround Time\"] = indv_TAT\n  return avg_TAT, sorted_df\n\ndef waiting_time(sorted_df):\n  indv_WT = []  #\n\n  #\n  for i in range(0, len(sorted_df)):\n    TAT = sorted_df[\"Turnaround Time\"][i]\n    BT = sorted_df[\"Burst Time\"][i]\n    indv_WT.append(TAT - BT)\n\n  avg_WT = np.average(indv_WT)\n  sorted_df[\"Waiting Time\"] = indv_WT\n  return avg_WT, sorted_df\n\ndef fcfs(raw_df):\n  sorted_df = sort_df(raw_df, 'Arrival Time')\n  sorted_schd_list = sorted_process_list(sorted_df)\n\n  print(\"\\nGantt Chart:\")\n  per_process_end_time = redone_gantt_chart(sorted_schd_list)\n  sorted_df[\"Finish Time\"] = per_process_end_time\n\n  avg_turnaround_time, sorted_df = turnaround_time(sorted_df)\n  avg_wait_time, sorted_df = waiting_time(sorted_df)\n  pd.set_option('display.expand_frame_repr', False)\n  print(\"\\nSchedule Table:\\n\", sorted_df)\n  print(\"\\nAverage Waiting Time: {}\\nAverage Turnaround Time: {}\\n\".format(\n    avg_wait_time, avg_turnaround_time))\n\ndef sjf_check_special_cases(raw_df):\n  if (len(raw_df[\"Arrival Time\"].unique()) == 1):\n    return 0\n  elif (len(raw_df[\"Burst Time\"].unique()) == 1):\n    return 1\n  return -1\n\ndef slice_df(sorted_df, sort_factor, curr_passed_time):\n  sliced_df = sorted_df.loc[sorted_df[sort_factor] <= curr_passed_time]\n\n  if len(sliced_df) == 0:\n    sliced_df = sorted_df.loc[sorted_df[sort_factor] > curr_passed_time]\n    first_greater_AT = sliced_df[\"Arrival Time\"].iloc[0]\n    sliced_df = sorted_df.loc[sorted_df[sort_factor] == first_greater_AT]\n\n  sliced_sorted_BT_df = sort_df(sliced_df, \"Burst Time\")\n  to_schd = list(sliced_sorted_BT_df.iloc[0])\n  sorted_df = sorted_df.drop(\n    sorted_df[sorted_df[\"Process No.\"] == to_schd[0]].index)\n\n  return to_schd, to_schd[2], sorted_df\n\ndef sjf(raw_df):\n  case = sjf_check_special_cases(raw_df)\n  fin_sorted_schd_list = []\n  curr_passed_time = 0\n\n  if case == 1:  #\n    fcfs(raw_df)\n  elif case == 0:  #\n    sorted_df = sort_df(raw_df, 'Burst Time')\n    sorted_schd_list = sorted_process_list(sorted_df)\n\n    print(\"\\nGantt Chart:\")\n    per_process_end_time = redone_gantt_chart(sorted_schd_list)\n    sorted_df[\"Finish Time\"] = per_process_end_time\n\n    avg_turnaround_time, sorted_df = turnaround_time(sorted_df)\n    avg_wait_time, sorted_df = waiting_time(sorted_df)\n    pd.set_option('display.expand_frame_repr', False)\n    print(\"\\nSchedule Table:\\n\", sorted_df)\n    print(\"Average Waiting Time: {}\\nAverage Turnaround Time: {}\".format(\n        avg_wait_time, avg_turnaround_time))\n  else:\n    initial_sorted_df = sort_df(raw_df, 'Arrival Time')\n    mod_sorted_df = initial_sorted_df.copy()\n    curr_passed_time = initial_sorted_df[\"Arrival Time\"][0]\n\n    for i in range(0, len(initial_sorted_df)):\n        temp_catcher, prev_burst, mod_sorted_df = slice_df(\n            mod_sorted_df, \"Arrival Time\", curr_passed_time)\n        curr_passed_time += prev_burst\n        fin_sorted_schd_list.append(temp_catcher)\n\n    process_order = [j[0] for j in fin_sorted_schd_list]\n    new_sorted_df = pd.DataFrame()\n    for i in range(0, len(process_order)):\n        new_sorted_df = pd.concat(\n            [new_sorted_df, initial_sorted_df[initial_sorted_df[\"Process No.\"] == process_order[i]]], ignore_index=True)\n\n    print(\"\\nGantt Chart:\")\n    per_process_end_time = redone_gantt_chart(fin_sorted_schd_list)\n    new_sorted_df[\"Finish Time\"] = per_process_end_time\n\n    avg_turnaround_time, new_sorted_df = turnaround_time(new_sorted_df)\n    avg_wait_time, new_sorted_df = waiting_time(new_sorted_df)\n    pd.set_option('display.expand_frame_repr', False)\n    print(\"\\nSchedule Table:\\n\", new_sorted_df)\n    print(\"\\nAverage Waiting Time: {}\\nAverage Turnaround Time: {}\\n\".format(\n        avg_wait_time, avg_turnaround_time))\n\ndef caller():\n  system(\"cls\")\n  data, schd_type = take_input()\n  data_frame = pd.DataFrame(data)\n  print(\"\\nRaw DataFrame:\\n\", data_frame)\n  if schd_type == 1:\n    fcfs(data_frame)\n  elif schd_type == 2:\n    sjf(data_frame)\n  else:\n    print(\"Invalid Choice!\")\n\ncaller()",
      "comments": {
        "29": "# ! necessary, otherwise process list function would give unsorted list since for-in loop goes by index",
        "87": "# in FCFS, the waiting time of the first process will be always 0",
        "89": "#! using formula WT = TAT - BT",
        "141": "# All burst times equal",
        "143": "# All arrival times equal"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Non_Preemptive_Task_Scheduling/NPTS_OP_FCFS_1.png",
        "OP_ss/Sem_IV-SF/Non_Preemptive_Task_Scheduling/NPTS_OP_FCFS_2.png",
        "OP_ss/Sem_IV-SF/Non_Preemptive_Task_Scheduling/NPTS_OP_SJF_1.png",
        "OP_ss/Sem_IV-SF/Non_Preemptive_Task_Scheduling/NPTS_OP_SJF_2.png"
      ],
      "bgColors": {
        "NPTS_OP_FCFS_1.png": "#181616",
        "NPTS_OP_FCFS_2.png": "#181616",
        "NPTS_OP_SJF_1.png": "#181616",
        "NPTS_OP_SJF_2.png": "#181616"
      }
    },
    "Non_Restoring_Division": {
      "lang": "py",
      "codeString": "from prettytable import PrettyTable\n\ndef take_input():\n  dvnd = int(input(\"Enter the Dividend: \"))\n  dvsr = int(input(\"Enter the Divisor: \"))\n\n  return dvnd, dvsr\n\ndef to_binary(*dec_number):\n  bin_master_list = []\n  def mechanism(dec_number):\n    if(dec_number >= 1):\n      mechanism(dec_number // 2)\n      bin_num.append(dec_number % 2)\n\n  for i in dec_number:\n    bin_num = []\n    mechanism(i)\n    bin_master_list.append(bin_num)\n\n  return bin_master_list\n\ndef static_bit_adjuster(bin_dvnd, bin_dvsr):\n  l1 = len(bin_dvnd)\n  l2 = len(bin_dvsr)\n\n  for i in range(l2, l1 + 1):\n    bin_dvsr.insert(0, 0)\n\ndef ones_complement(binary_num_list):\n  for i in range(0, len(binary_num_list)):\n    if binary_num_list[i] == 0:\n      binary_num_list[i] = 1\n    else:\n      binary_num_list[i] = 0\n\ndef binary_add(list1, list2):\n  carry = 0\n\n  for i in range(len(list1) - 1, -1, -1): #\n    if(carry == 0):\n      if(list1[i] == 0 and list2[i] == 0):\n        list1[i] = 0\n      elif(list1[i] == 0 and list2[i] == 1):\n        list1[i] = 1\n      elif(list1[i] == 1 and list2[i] == 0):\n        list1[i] = 1\n      elif(list1[i] == 1 and list2[i] == 1):\n        list1[i] = 0\n        carry = 1   #\n\n    elif(carry == 1):\n      if(list1[i] == 0 and list2[i] == 0):\n        list1[i] = 1\n        carry = 0\n\n      elif(list1[i] == 0 and list2[i] == 1):\n        list1[i] = 0\n        carry = 1\n\n      elif(list1[i] == 1 and list2[i] == 0):\n        list1[i] = 0\n        carry = 1\n\n      elif(list1[1] == 1 and list2[i] == 1):\n        list1[i] = 1\n        carry = 1 #\n\ndef twos_complement(list1):\n  one = [1]\n  for i in range(0, len(list1)-1):\n    one.insert(0, 0)\n  \n  ones_complement(list1)\n  binary_add(list1, one)\n\n#\ndef ar_left_shift(list1, list2):\n  l1 = len(list1)\n  l2 = len(list2)\n  temp1 = list1.copy()\n  temp2 = list2.copy()\n\n  temp_bit = list2[0]\n  for i in range(l2 - 2, -1, -1):\n    list2[i] = temp2[i + 1]\n  \n  list2[-1] = None\n  list1[-1] = temp_bit\n  for i in range(l1 - 2, -1, -1):\n    list1[i] = temp1[i + 1]\n\ndef list_to_string(list1):\n  string = \"\"\n  for i in list1:\n    if i == None:\n      string += '_'\n    else:\n      string += str(i)\n  \n  return string\n\ndef to_decimal(Q, A):\n  expo = 0\n  dec_quotient = 0\n  dec_remainder = 0\n\n  for i in range(len(Q) - 1, -1, -1):\n    if Q[i] == 1:\n      dec_quotient += 2**expo\n    expo += 1\n\n  expo = 0\n  for i in range(len(A) - 1, -1, -1):\n    if A[i] == 1:\n      dec_remainder += 2**expo\n    expo += 1\n\n  return dec_quotient, dec_remainder\n\ndef non_restoring_division():\n  #\n  dvnd, dvsr = take_input()\n\n  #\n  if dvsr == 0:\n    print(\"{} / {} is undefined! Cannot divide by Zero!\".format(dvnd, dvsr))\n    return \n  if dvnd == 0:\n    print(\"{} / {} = {}\".format(dvnd, dvsr, 0))\n    return\n  \n  #\n  binaries = to_binary(dvnd, dvsr)\n  bin_dvnd = binaries[0] ; bin_dvsr = binaries[1]\n\n  #\n  static_bit_adjuster(bin_dvnd, bin_dvsr)\n\n  #\n  Q = bin_dvnd.copy()\n  M = bin_dvsr.copy()\n  A = [0 for i in range(0, len(M))]\n  count = len(Q)\n  twos_complement(M)\n  minus_M = M.copy()\n  twos_complement(M)\n\n  #\n  table = PrettyTable([\"A\", \"Q\", \"M\", \"Count\", \"Operation\"])\n  final_table = [[list_to_string(A), list_to_string(Q), list_to_string(M), count, \"Start\"]]\n\n  #\n  while count > 0:\n    ar_left_shift(A, Q)\n    final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"Arithmetic Left Shift\"])\n\n    if A[0] == 1:\n      binary_add(A, M)\n      final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"A = A + M\"])\n    elif A[0] == 0:\n      binary_add(A, minus_M)\n      final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"A = A - M\"])\n    \n    #\n    if A[0] == 1:\n      Q[-1] = 0\n    elif A[0] == 0:\n      Q[-1] = 1\n    final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"Q_0 = A[MSB]'\"])\n    count -= 1\n  \n  if A[0] == 1:\n    binary_add(A, M)\n    final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"A = A + M\"])\n\n  final_table.append(['', '', '', '', \"Finish\"])\n  table.add_rows(final_table)\n  print(table)\n\n  #\n  res = to_decimal(Q, A)\n  print(\"For {} / {}:\\nQuotient = {} ; Remainder = {}\".format(dvnd, dvsr, res[0], res[1]))\n\nnon_restoring_division()",
      "comments": {
        "40": "#reverse traversal",
        "50": "#! Quite important",
        "67": "#! Quite important",
        "77": "#here in RD, lists (A and Q) will not have equal lengths, therfore 2 separate for loops",
        "122": "#*taking user input",
        "125": "#*preconditions",
        "133": "#*preparing binary number list from decimal input",
        "137": "#*Bit adjustments",
        "140": "#*main algorithm preparations",
        "149": "#*table preparation",
        "153": "#*steps of the algorithm",
        "165": "#* Q[LSB] = A[MSB]'",
        "181": "#getting final answer in decimal"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Non_Restoring_Division/NRD_OP_1.png"
      ],
      "bgColors": {
        "NRD_OP_1.png": "#181616"
      }
    },
    "Preemptive_Task_Scheduling": {
      "lang": "py",
      "codeString": "import numpy as np\nimport pandas as pd\nfrom os import system\nimport copy\n\n\ndef take_input():\n  data = []\n  no_of_process = int(input(\"Enter the number of processes: \"))\n\n  for i in range(1, no_of_process + 1):\n    arr_time = int(\n      input(\"Enter the Arrival Time for Process {}: \".format(i)))\n    burst_time = int(\n      input(\"Enter the Burst Time for Process {}: \".format(i)))\n    temp_dict = {'Process No.': i, 'Arrival Time': arr_time,\n                  'Initial Burst Time': burst_time, 'Remaining Time': burst_time}\n    data.append(temp_dict)\n\n  schd_type = int(\n    input(\"Enter the Preemptive scheduler: \\n1. SRTF\\n2. Round-Robin: \"))\n  if (schd_type == 2):\n    time_quantum = int(input(\"Enter the Time Quantum: \"))\n    return data, schd_type, time_quantum\n\n  return data, schd_type, 1\n\n\ndef sort_df(data_frame, by_parameter):\n  sorted_df = data_frame.sort_values(by=by_parameter)\n  sorted_df.reset_index(inplace=True, drop=True)\n\n  return sorted_df\n\n\ndef df_slicer(data_frame, sort_factor, cond_rhs, condition):\n  if condition == \"LESS_THAN_EQUAL\":\n    slice_df = data_frame.loc[data_frame[sort_factor] <= cond_rhs]\n  elif condition == \"GREATER_THAN\":\n    slice_df = data_frame.loc[data_frame[sort_factor] > cond_rhs]\n\n  return slice_df\n\n\ndef redone_gantt_chart(sorted_schd_list, passed_time=0):\n  gantt_list = []\n  passed_time = 0\n  end_times = dict()\n\n  def redone_match_ATPT(curr_passed_time, next_arr_time):\n    if curr_passed_time < next_arr_time:\n      if curr_passed_time == 0:\n        gantt_list.extend([curr_passed_time,\n                            \"\\033[38;5;225midle\", next_arr_time])\n      else:\n        gantt_list.extend(['\\033[38;5;225midle', next_arr_time])\n      return next_arr_time\n\n    elif curr_passed_time == 0:\n      gantt_list.append(curr_passed_time)\n    return curr_passed_time\n\n  for i in sorted_schd_list:\n    passed_time = redone_match_ATPT(passed_time, i[1])\n    passed_time += i[2]\n    gantt_list.extend(['\\033[38;5;225m' + 'P' + str(i[0]), passed_time])\n    end_times.update({i[0]: passed_time})\n  #\n\n  def print_gantt(gantt_list):\n    for i in gantt_list:\n        if i != gantt_list[-1]:\n          print(i, \"\\033[1;90m-> \\033[0m\", end=\"\")\n        else:\n          print(i, end=\"\")\n  print(\"\\033[4m\\033[38;5;225mGantt Chart\\033[0m\")\n  print_gantt(gantt_list)\n\n  return end_times\n\ndef turnaround_time(sorted_df):\n  indv_TAT = []\n\n  for i in range(0, len(sorted_df)):\n    pFT = sorted_df[\"Finish Time\"][i]\n    aT = sorted_df[\"Arrival Time\"][i]\n    indv_TAT.append(pFT - aT)\n\n  avg_TAT = np.average(indv_TAT)\n  sorted_df[\"Turnaround Time\"] = indv_TAT\n  return avg_TAT\n\ndef waiting_time(sorted_df):\n  indv_WT = []  #\n\n  #\n  #\n  for i in range(0, len(sorted_df)):\n    TAT = sorted_df[\"Turnaround Time\"][i]\n    BT = sorted_df[\"Initial Burst Time\"][i]\n    indv_WT.append(TAT - BT)\n\n  avg_WT = np.average(indv_WT)\n  sorted_df[\"Waiting Time\"] = indv_WT\n  return avg_WT\n\n\ndef SRTF(raw_df):\n  AT_sorted_full_df = sort_df(raw_df, \"Arrival Time\")\n  backup = AT_sorted_full_df.copy()\n\n  curr_passed_time = 0\n  per_process_passed_time = 0\n  fully_scheduled = 0\n  schdlist = []\n  noofprocess = raw_df.shape[0]\n  previously_running_proc_no = -1\n\n  while (fully_scheduled != noofprocess):\n    AT_sliced_df = df_slicer(\n      AT_sorted_full_df, \"Arrival Time\", curr_passed_time, \"LESS_THAN_EQUAL\")\n\n    if len(AT_sliced_df) == 0:\n      curr_passed_time += 1\n      continue\n\n    RT_sliced_df = sort_df(AT_sliced_df, \"Remaining Time\")\n    running_proc_no = RT_sliced_df[\"Process No.\"].iloc[0]\n\n    if (running_proc_no != previously_running_proc_no and previously_running_proc_no != -1 and\n      (len(AT_sorted_full_df.loc[AT_sorted_full_df[\"Process No.\"] == previously_running_proc_no]) != 0)):\n      to_schd = AT_sorted_full_df.loc[AT_sorted_full_df[\"Process No.\"] == previously_running_proc_no, [\n          \"Process No.\", \"Arrival Time\", \"Initial Burst Time\"]].values.tolist()[0]\n      to_schd[2] = per_process_passed_time\n      schdlist.append(to_schd)\n      per_process_passed_time = 0\n\n    previously_running_proc_no = running_proc_no\n\n    AT_sorted_full_df.loc[AT_sorted_full_df[\"Process No.\"]\n                            == running_proc_no, \"Remaining Time\"] -= 1\n    curr_passed_time += 1\n    per_process_passed_time += 1\n\n    if (int(AT_sorted_full_df.loc[AT_sorted_full_df[\"Process No.\"] == running_proc_no, \"Remaining Time\"]) == 0):\n      to_schd = AT_sorted_full_df.loc[AT_sorted_full_df[\"Process No.\"] == running_proc_no, [\n        \"Process No.\", \"Arrival Time\", \"Initial Burst Time\"]].values.tolist()[0]\n      to_schd[2] = per_process_passed_time\n      schdlist.append(to_schd)\n      fully_scheduled += 1\n      per_process_passed_time = 0\n      AT_sorted_full_df.drop(\n        AT_sorted_full_df.loc[AT_sorted_full_df[\"Process No.\"] == running_proc_no].index, inplace=True)\n\n  end_times = redone_gantt_chart(schdlist)\n  new_df = backup\n  new_df[\"Remaining Time\"], new_df[\"Finish Time\"] = [0 for i in range(len(new_df))], [0 for i in range(len(new_df))]\n\n  for i in end_times.keys():\n    for j in range(0, len(new_df)):\n      if (int(new_df.loc[j, \"Process No.\"]) == i):\n        new_df.loc[j, \"Finish Time\"] = end_times[i]\n\n  avg_turnaround_time = turnaround_time(new_df)\n  avg_waiting_time = waiting_time(new_df)\n  print(\"\\n\\n\", new_df)\n  print(\"\\nAverage Waiting Time: \\033[1m\\033[4m\\033[38;5;50m{}\\033[0m\\nAverage Turnaround Time: \\033[1m\\033[4m\\033[38;5;50m{}\\033[0m\".format(\n    avg_waiting_time, avg_turnaround_time))\n\n\ndef round_robin(raw_df, quantum=3):\n  AT_sorted_full_df = sort_df(raw_df, \"Arrival Time\")\n  backup = AT_sorted_full_df.copy()\n\n  curr_passed_time = AT_sorted_full_df.loc[0, \"Arrival Time\"]\n  per_process_passed_time = 0\n  fully_scheduled = 0\n  schdlist = []\n  noofprocess = raw_df.shape[0]\n  is_preempted = {key: 0 for key in [i for i in range(0, noofprocess)]}\n  i_flag = 0\n  backup_i = -999\n  i = 0\n\n  while (fully_scheduled != noofprocess):\n    if i == noofprocess:\n      i = 0\n\n    if (i != 0 and i_flag == 1):\n      i -= 1\n      i_flag = 0\n\n    if (AT_sorted_full_df[\"Arrival Time\"].iloc[i] > curr_passed_time):\n      #\n      backup_i = copy.deepcopy(i)\n      for k in range(0, i):\n        if (AT_sorted_full_df[\"Remaining Time\"].iloc[k] > 0 and is_preempted[k] >= 1):\n          i = k\n          break\n\n      if (backup_i == i):\n        curr_passed_time += 1\n        backup_i = -999\n        i += 1\n        i_flag = 1\n        continue\n\n    for j in range(0, quantum):\n      if (is_preempted[i] != -1):\n        AT_sorted_full_df.iloc[i, 3] -= 1\n        curr_passed_time += 1\n        per_process_passed_time += 1\n\n        if (int(AT_sorted_full_df.iloc[i, 3]) == 0):\n          to_schd = AT_sorted_full_df.iloc[i, [\n              0, 1, 2]].values.tolist()\n          to_schd[2] = per_process_passed_time\n          schdlist.append(to_schd)\n          fully_scheduled += 1\n          per_process_passed_time = 0\n          is_preempted[i] = -1\n          break\n\n        elif (per_process_passed_time == quantum):\n          to_schd = AT_sorted_full_df.iloc[i, [\n              0, 1, 2]].values.tolist()\n          to_schd[2] = per_process_passed_time\n          schdlist.append(to_schd)\n          is_preempted[i] += 1\n          per_process_passed_time = 0\n    i += 1\n\n  end_times = redone_gantt_chart(schdlist)\n  new_df = backup\n  new_df[\"Remaining Time\"], new_df[\"Finish Time\"] = [\n      0 for i in range(len(new_df))], [0 for i in range(len(new_df))]\n\n  for i in end_times.keys():\n    for j in range(0, len(new_df)):\n      if (int(new_df.loc[j, \"Process No.\"]) == i):\n        new_df.loc[j, \"Finish Time\"] = end_times[i]\n\n  avg_turnaround_time = turnaround_time(new_df)\n  avg_waiting_time = waiting_time(new_df)\n  print(\"\\n\\n\", new_df)\n  print(\"\\nAverage Waiting Time: \\033[1m\\033[4m\\033[38;5;50m{}\\033[0m\\nAverage Turnaround Time: \\033[1m\\033[4m\\033[38;5;50m{}\\033[0m\".format(\n      avg_waiting_time, avg_turnaround_time))\n\n\ndef caller():\n  system(\"cls\")\n  data, schd_type, time_quantum = take_input()\n  data_frame = pd.DataFrame(data)\n  print(\"\\nRaw DataFrame:\\n\", data_frame, \"\\n\")\n  if schd_type == 1:\n    SRTF(data_frame)\n  elif schd_type == 2:\n    round_robin(data_frame, time_quantum)\n  else:\n    print(\"Invalid Choice!\")\n\ncaller()",
      "comments": {
        "68": "# print(gantt_list)",
        "94": "# in FCFS, the waiting time of the first process will be always 0",
        "96": "#! using formula WT = TAT - BT",
        "97": "# (alternatively, formula can be WT = FTprev - ATcurr)",
        "194": "# check the queue first"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Preemptive_Task_Scheduling/PTS_RR_OP_1.png",
        "OP_ss/Sem_IV-SF/Preemptive_Task_Scheduling/PTS_RR_OP_2.png",
        "OP_ss/Sem_IV-SF/Preemptive_Task_Scheduling/PTS_SRTF_OP_1.png",
        "OP_ss/Sem_IV-SF/Preemptive_Task_Scheduling/PTS_SRTF_OP_2.png"
      ],
      "bgColors": {
        "PTS_RR_OP_1.png": "#181616",
        "PTS_RR_OP_2.png": "#181616",
        "PTS_SRTF_OP_1.png": "#181616",
        "PTS_SRTF_OP_2.png": "#181616"
      }
    },
    "Restoring_Division": {
      "lang": "py",
      "codeString": "from prettytable import PrettyTable\n\ndef take_input():\n  dvnd = int(input(\"Enter the Dividend: \"))\n  dvsr = int(input(\"Enter the Divisor: \"))\n\n  return dvnd, dvsr\n\ndef to_binary(*dec_number):\n  bin_master_list = []\n  def mechanism(dec_number):\n    if(dec_number >= 1):\n      mechanism(dec_number // 2)\n      bin_num.append(dec_number % 2)\n\n  for i in dec_number:\n    bin_num = []\n    mechanism(i)\n    bin_master_list.append(bin_num)\n\n  return bin_master_list\n\ndef static_bit_adjuster(bin_dvnd, bin_dvsr):\n  l1 = len(bin_dvnd)\n  l2 = len(bin_dvsr)\n\n  for i in range(l2, l1 + 1):\n    bin_dvsr.insert(0, 0)\n\ndef ones_complement(binary_num_list):\n  for i in range(0, len(binary_num_list)):\n    if binary_num_list[i] == 0:\n      binary_num_list[i] = 1\n    else:\n      binary_num_list[i] = 0\n\ndef binary_add(list1, list2):\n  carry = 0\n\n  for i in range(len(list1) - 1, -1, -1): #\n    if(carry == 0):\n      if(list1[i] == 0 and list2[i] == 0):\n        list1[i] = 0\n      elif(list1[i] == 0 and list2[i] == 1):\n        list1[i] = 1\n      elif(list1[i] == 1 and list2[i] == 0):\n        list1[i] = 1\n      elif(list1[i] == 1 and list2[i] == 1):\n        list1[i] = 0\n        carry = 1   #\n\n    elif(carry == 1):\n      if(list1[i] == 0 and list2[i] == 0):\n        list1[i] = 1\n        carry = 0\n\n      elif(list1[i] == 0 and list2[i] == 1):\n        list1[i] = 0\n        carry = 1\n\n      elif(list1[i] == 1 and list2[i] == 0):\n        list1[i] = 0\n        carry = 1\n\n      elif(list1[1] == 1 and list2[i] == 1):\n        list1[i] = 1\n        carry = 1 #\n\ndef twos_complement(list1):\n  one = [1]\n  for i in range(0, len(list1)-1):\n    one.insert(0, 0)\n  \n  ones_complement(list1)\n  binary_add(list1, one)\n\n#\ndef ar_left_shift(list1, list2):\n  l1 = len(list1)\n  l2 = len(list2)\n  temp1 = list1.copy()\n  temp2 = list2.copy()\n\n  temp_bit = list2[0]\n  for i in range(l2 - 2, -1, -1):\n    list2[i] = temp2[i + 1]\n  \n  list2[-1] = None\n  list1[-1] = temp_bit\n  for i in range(l1 - 2, -1, -1):\n    list1[i] = temp1[i + 1]\n\ndef list_to_string(list1):\n  string = \"\"\n  for i in list1:\n    if i == None:\n      string += '_'\n    else:\n      string += str(i)\n  \n  return string\n\ndef to_decimal(Q, A):\n  expo = 0\n  dec_quotient = 0\n  dec_remainder = 0\n\n  for i in range(len(Q) - 1, -1, -1):\n    if Q[i] == 1:\n      dec_quotient += 2**expo\n    expo += 1\n\n  expo = 0\n  for i in range(len(A) - 1, -1, -1):\n    if A[i] == 1:\n      dec_remainder += 2**expo\n    expo += 1\n\n  return dec_quotient, dec_remainder\n\ndef restoring_division():\n  #\n  dvnd, dvsr = take_input()\n\n  #\n  if dvsr == 0:\n    print(\"{} / {} is undefined! Cannot divide by Zero!\".format(dvnd, dvsr))\n    return \n  if dvnd == 0:\n    print(\"{} / {} = {}\".format(dvnd, dvsr, 0))\n    return \n\n  #\n  binaries = to_binary(dvnd, dvsr)\n  bin_dvnd = binaries[0] ; bin_dvsr = binaries[1]\n\n  #\n  static_bit_adjuster(bin_dvnd, bin_dvsr)\n\n  #\n  Q = bin_dvnd.copy()\n  M = bin_dvsr.copy()\n  A = [0 for i in range(0, len(M))]\n  count = len(Q)\n  twos_complement(M)\n  minus_M = M.copy()\n  twos_complement(M)\n\n  #\n  table = PrettyTable([\"A\", \"Q\", \"M\", \"Count\", \"Operation\"])\n  final_table = [[list_to_string(A), list_to_string(Q), list_to_string(M), count, \"Start\"]]\n\n  #\n  while count > 0:\n    ar_left_shift(A, Q)\n    final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"Arithmetic Left Shift\"])\n    binary_add(A, minus_M)\n    final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"A = A - M\"])\n\n    if A[0] == 1:\n      Q[-1] = 0\n      final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"MSB[A] = 1, Q_0 = 0\"])\n      binary_add(A, M) #\n      final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"(Restore A), A = A + M\"])\n    elif A[0] == 0:\n      Q[-1] = 1\n      final_table.append([list_to_string(A), list_to_string(Q), list_to_string(M), count, \"MSB[A] = 0, Q_0 = 1\"])\n\n    count -= 1\n\n  final_table.append(['', '', '', '', \"Finish\"])\n  table.add_rows(final_table)\n  print(table)\n\n  #\n  res = to_decimal(Q, A)\n  print(\"For {} / {}:\\nQuotient = {} ; Remainder = {}\".format(dvnd, dvsr, res[0], res[1]))\n\nrestoring_division()",
      "comments": {
        "40": "#reverse traversal",
        "50": "#! Quite important",
        "67": "#! Quite important",
        "77": "#here in RD, lists (A and Q) will not have equal lengths, therfore 2 separate for loops",
        "122": "#*taking user input",
        "125": "#*preconditions",
        "133": "#*preparing binary number list from decimal input",
        "137": "#*Bit adjustments",
        "140": "#*main algorithm preparations",
        "149": "#*table preparation",
        "153": "#*steps of the algorithm",
        "163": "#! Restoration of A",
        "175": "#getting final answer in decimal"
      },
      "outputSrcs": [
        "OP_ss/Sem_IV-SF/Restoring_Division/RD_OP_1.png"
      ],
      "bgColors": {
        "RD_OP_1.png": "#181616"
      }
    }
  },
  "Sem_V-IS": {
    "Caesar_Cipher_95": {
      "lang": "py",
      "codeString": "#\n\ndef caesar_encrypt(plain_text: str, key: int):\n  cipher_text = \"\"\n  for i in plain_text:\n    cipher_text += chr(((ord(i) + key - 32) % 95) + 32)\n  return cipher_text\n\ndef caesar_decrypt(cipher_text: str, key: int):\n  plain_text = \"\"\n  for i in cipher_text:\n    plain_text += chr(((ord(i) - key - 32) % 95) + 32)\n  return plain_text\n\ndef caesar_cipher():\n  plain_text = input(\"Enter the plain text: \")\n  key = int(input(\"Enter the key (shift, preferably 0 < key < 95): \"))\n  cipher_text = caesar_encrypt(plain_text, key)\n  print(\"Encrypted Text: \", cipher_text)\n  plain_text = caesar_decrypt(cipher_text, key)\n  print(\"Decrypted Text: \", plain_text)\n\ncaesar_cipher()",
      "comments": {
        "1": "#~ A simple python program to implement caesar cipher encryption and decryption using 95 valid (keyboard type-able) characters"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Caesar_Cipher_95/CC95_OP_1.png",
        "OP_ss/Sem_V-IS/Caesar_Cipher_95/CC95_OP_2.png"
      ],
      "bgColors": {
        "CC95_OP_1.png": "#181616",
        "CC95_OP_2.png": "#181616"
      }
    },
    "Columnar_Transposition": {
      "lang": "py",
      "codeString": "\n#\n\n#\ndef ctp_encryption(plain_text: str, key: str):\n  keylen, ptlen = len(key), len(plain_text)\n  cipher_text = \"\"\n  enc_mx = [list(plain_text[i: i + keylen]) for i in range(0, ptlen - keylen + 1, keylen)]      #\n\n  keylist = list(key)\n  sorted_keylist = sorted(list(key))\n  included_indx = []\n\n  #\n  for i in range(len(sorted_keylist)):\n    for j in range(len(keylist)):\n      if sorted_keylist[i] == keylist[j] and j not in included_indx:           #\n        for row in range(len(enc_mx)):\n          cipher_text += enc_mx[row][j]\n        included_indx.append(j)\n        break\n\n  return cipher_text\n\n#\ndef ctp_decryption(cipher_text: str, key: str):\n  plain_text = \"\"\n  keylen, ctlen = len(key), len(cipher_text)\n  dec_mx = [[0 for i in range(keylen)] for j in range(int(ctlen / keylen))]\n  ct_curr_indx = 0\n  \n  keylist, sorted_keylist = list(key), sorted(list(key))      #\n  included_indx = []\n\n  for i in range(len(sorted_keylist)):\n    for j in range(len(keylist)):\n      if sorted_keylist[i] == keylist[j] and j not in included_indx:           \n        for row in range(len(dec_mx)):\n          dec_mx[row][j] = cipher_text[ct_curr_indx]\n          ct_curr_indx += 1\n        included_indx.append(j)\n        break\n\n  for _ in range(len(dec_mx)):\n    plain_text += \"\".join(dec_mx.pop(0))\n\n  return plain_text\n\ndef columnar_tp():\n  print(\"Columnar Transposition\")\n  plain_text = input(\"Enter the plain text (preferably ALL CAPS, no SPACE): \").upper().replace(\" \", \"\")\n  key = input(\"Enter the key (preferably shorter than the Plaintext or it will be sliced): \")[:len(plain_text)].upper().replace(\" \", \"\")\n  keylen = len(key)\n  while True:\n    if len(plain_text) % keylen != 0:\n      plain_text += '_'\n    else:\n      break\n  cipher_text = ctp_encryption(plain_text, key)\n  print(\"Cipher Text: \", cipher_text)\n  plain_text = ctp_decryption(cipher_text, key)\n  print(\"Plain Text: \", plain_text)\n\ncolumnar_tp()",
      "comments": {
        "2": "#~ Python program to implement columnar transposition cipher",
        "4": "# Encryption -> Encryption_mx => PLaintext filled row-wise; According to the alphabetic order of the key's chars. pick columns in enc_mx and append those chars. in cipher_text",
        "8": "#~ +1 because endpoint is excluded but I want it included (NTS: Maybe do it the DES way)(Another NTS: Don't keep it as list of single strings, keep it as list of chars.)",
        "14": "# range used to not have to use 'index' function which inevitably returns index of first find   ",
        "17": "# if characters are equal and the index of the char. in the o.g keylist is not already used, use it as the column index for the enc_mx",
        "25": "# Decryption -> fill the columns with slices of cipher_text based on the same ascending-arrangement of the key",
        "32": "# I've not imported this from the encryption block to keep the essence of messaging between 2 users, receiver will have to process the key on their own"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Columnar_Transposition/CT_OP_1.png",
        "OP_ss/Sem_V-IS/Columnar_Transposition/CT_OP_2.png"
      ],
      "bgColors": {
        "CT_OP_1.png": "#181616",
        "CT_OP_2.png": "#181616"
      }
    },
    "DH_Key_Exchange": {
      "lang": "py",
      "codeString": "def DHKE():\n  g, p = 5, 23\n  a, b = 4, 3\n  Xa = (g ** a) % p\n  Xb = (g ** b) % p\n  SSA = (Xb ** a) % p\n  SSB = (Xa ** b) % p\n  if SSA == SSB:\n    print(\"Connection Established\")\n\nDHKE()",
      "comments": {},
      "outputSrcs": [],
      "bgColors": {}
    },
    "Double_Columnar_Transposition": {
      "lang": "py",
      "codeString": "#\n#\n\ndef text_padding(text, keylen):\n  while len(text) % keylen != 0:\n    text += '_'\n  return text\n\ndef key_orderer(key):\n  key_list = list(key)\n  sorted_key_list = list(sorted(key))\n  col_order = [] \n  for i in range(len(sorted_key_list)):\n    for j in range(len(key_list)):\n      if sorted_key_list[i] == key_list[j] and j not in col_order:\n        col_order.append(j)\n        break\n  return col_order\n\ndef columnar_tp_encryption(plain_text, key, other_key):\n  cipher_text = \"\"\n  keylen = len(key)\n  col_order = key_orderer(key)\n  if len(plain_text) % len(key) != 0:           #\n    plain_text = text_padding(plain_text, keylen)\n  ptlen = len(plain_text)                            #\n  enc_mx = [list(plain_text[i - keylen: i]) for i in range(keylen, ptlen + 1, keylen)]\n  \n  for col in col_order:\n    cipher_text += \"\".join([enc_mx[row][col] for row in range(len(enc_mx))])\n  return cipher_text, f\"{ptlen}\"\n\ndef columnar_tp_decryption(cipher_text, key):\n  plain_text = \"\"\n  keylen = len(key)\n  col_order = key_orderer(key)\n  ctlen = len(cipher_text)                    \n  dec_mx = [[0 for _ in range(keylen)] for _ in range(int(ctlen / keylen))]\n  ct_curr_indx = 0\n  \n  for col in col_order:\n    for row in range(len(dec_mx)):\n      dec_mx[row][col] = cipher_text[ct_curr_indx]\n      ct_curr_indx += 1\n\n  for _ in range(len(dec_mx)):\n    plain_text += \"\".join(dec_mx.pop(0))\n  \n  return plain_text\n\ndef double_columnar_encryption(plain_text: str, key1: str, key2: str):\n  intermediate_ct, intermediate_ptlen = columnar_tp_encryption(plain_text, key1, key2)\n  final_ct = columnar_tp_encryption(intermediate_ct, key2, key1)[0] + \"\u2265\" + intermediate_ptlen\n  return final_ct \n\ndef double_columnar_decryption(cipher_text, key1: str, key2: str):\n  intermediate_ptlen = int(cipher_text[cipher_text.index(\"\u2265\") + 1:])\n  cipher_text = cipher_text[:cipher_text.index(\"\u2265\")]\n  intermediate_pt = columnar_tp_decryption(cipher_text, key2)\n  intermediate_pt = intermediate_pt[:intermediate_ptlen]\n  final_pt = columnar_tp_decryption(intermediate_pt, key1)\n  return final_pt\n  \ndef double_columnar():\n  plain_text = input(\"Enter the plain text (preferably all caps, no space): \").upper().replace(\" \", \"\")\n  key1 = input(\"Enter the first key (preferably len(key) < len(plain_text)): \")[:len(plain_text)].upper().replace(\" \", \"\")\n  key2 = input(\"Enter the second key (preferably len(key) < len(plain_text)): \")[:len(plain_text)].upper().replace(\" \", \"\")\n  print(\"\\033[38;5;149mEntered Text:\", plain_text, \"\\033[0m\")\n\n  cipher_text = double_columnar_encryption(plain_text, key1, key2)\n  print(\"\\033[38;5;197mCipher Text:\", cipher_text, \"\\033[0m\")\n  plain_text = double_columnar_decryption(cipher_text, key1, key2)\n  print(\"\\n\\033[38;5;205mDeciphered Text:\", plain_text, \"\\033[0m\")\n\ndouble_columnar()",
      "comments": {
        "1": "#~ Implementing Double Columnar Transposition symmetric cryptography (See columnar_tp.py for explanation)",
        "2": "#!NTS at the end \u2193",
        "24": "# if padding required then only call the padding function ",
        "26": "# length of plaintext should always be taken after padding"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Double_Columnar_Transposition/DCT_OP_1.png",
        "OP_ss/Sem_V-IS/Double_Columnar_Transposition/DCT_OP_2.png"
      ],
      "bgColors": {
        "DCT_OP_1.png": "#181616",
        "DCT_OP_2.png": "#181616"
      }
    },
    "Electronic_Code_Book": {
      "lang": "py",
      "codeString": "#\n\ndef text_padder(text):\n  while len(text) % 16 != 0:\n    text += '_'\n  return text\n\ndef dec_to_binary(dec_num):\n  def mechanism(num):\n    if num >= 1:\n      mechanism(num // 2)\n      bin_list.append(num % 2)\n  bin_list = []\n  mechanism(dec_num)\n  return bin_list\n\n#\ndef ascii_list_binarizer(ascii_list):\n  binary_list = []\n  for num in ascii_list:\n    pad_to_8 = dec_to_binary(num)           #\n    while(len(pad_to_8) != 8):\n      pad_to_8.insert(0, 0)\n    binary_list.extend(pad_to_8)\n  return binary_list\n\n#\ndef list_XOR(list_a, list_b):\n  XORed = []\n  for x, y in zip(list_a, list_b):\n    XORed.append(x ^ y)     #\n  return XORed\n\ndef binary_to_ascii(eight_bits):\n  dec_number = 0\n  for i in range(len(eight_bits) - 1, -1, -1):\n    if eight_bits[i] == 1:\n      dec_number += 2 ** (len(eight_bits) - 1 - i)\n  return dec_number\n\ndef bin_list_asciirizer(bin_list):\n  ascii_list = []\n  for eight_indx in range(8, len(bin_list) + 1, 8):\n    ascii_list.append(binary_to_ascii(bin_list[eight_indx - 8: eight_indx]))\n  return ascii_list\n\ndef electronic_code_book_encryption(plain_text, key, shift):\n  #\n  pt_ascii_blocks = [list(map(lambda x: ord(x), list(plain_text[i - 16: i]))) for i in range(16, len(plain_text) + 1, 16)]       \n  #\n  pt_128_blocks = []\n  for block in pt_ascii_blocks:\n    pt_128_blocks.append(ascii_list_binarizer(block))\n\n  #\n  key_128 = ascii_list_binarizer(list(map(lambda x: ord(x), list(key))))\n\n  #\n  for i in range(shift):\n    for block in pt_128_blocks:\n      block.append(block.pop(0))  \n    \n  #\n  for b_indx in range(len(pt_128_blocks)):\n    pt_128_blocks.append(list_XOR(pt_128_blocks[b_indx], key_128))\n  pt_128_blocks = pt_128_blocks[len(pt_128_blocks) // 2:]               #\n\n  #\n  cipher_text = \"\"\n  for block in pt_128_blocks:\n    cipher_text += \"\".join(list(map(lambda x: chr(x), bin_list_asciirizer(block))))\n  return cipher_text\n\ndef electronic_code_book_decryption(cipher_text, key, shift):\n  #\n  key_128 = ascii_list_binarizer(list(map(lambda x: ord(x), list(key))))\n  ct_ascii_blocks = [list(map(lambda x: ord(x), list(cipher_text[i - 16: i]))) for i in range(16, len(cipher_text) + 1, 16)]\n  ct_128_blocks = []\n  for block in ct_ascii_blocks:\n    ct_128_blocks.append(ascii_list_binarizer(block))\n\n  #\n  for b_indx in range(len(ct_128_blocks)):\n    ct_128_blocks.append(list_XOR(ct_128_blocks[b_indx], key_128))\n  ct_128_blocks = ct_128_blocks[len(ct_128_blocks) // 2:]         \n  \n  #\n  for i in range(shift):\n    for block in ct_128_blocks:\n      block.insert(0, block.pop(-1))\n    \n  plain_text = \"\"\n  for block in ct_128_blocks:\n    plain_text += \"\".join(list(map(lambda x: chr(x), bin_list_asciirizer(block))))\n  return plain_text\n\ndef electronic_code_book():\n  plain_text = \"Dolore commodo nulla fugiat proident.Id sit dolore proident aliquip laboris aliqua fugiat ullamco cupidatat duis eiusmod occaecat nostrud cupidatat.\"\n  print(\"\\033[38;5;85mOriginal Plain Text:\", plain_text, \"\\033[0m\")\n  plain_text = text_padder(plain_text)\n  key = input(\"Enter the 16 character key string: \")[:16]\n  shift = int(input(\"Enter the shift amount 't': \"))\n  cipher_text = electronic_code_book_encryption(plain_text, key, shift)\n  print(\"\\033[38;5;197mCipher Text:\", cipher_text, \"\\033[0m\")\n  plain_text = electronic_code_book_decryption(cipher_text, key, shift)\n  print(\"\\033[38;5;209mDeciphered Text:\", plain_text, \"\\033[0m\")\n  \nelectronic_code_book()",
      "comments": {
        "1": "#~ Implementing Electronic Code Book Block Cipher technique (t-shifts)",
        "17": "# the -izer suffix just sounds funny to me so used it lol",
        "21": "# dec to bin only returns significant bits, have to pad for uniform 8 bit representation, 8 bits can represent till 255(included) and that's okay for 1 left shift of any english keyboard char ~(126) x 2 = 252 < 255",
        "27": "#* both list_a and list_b are lists of 128 bits",
        "31": "# shorthand for XOR in python is ^, don't confuse it with power!",
        "48": "# A list of lists containing 16 ascii values representing 16 chars. splits (blocks) of plain text",
        "50": "# list of lists containing 128 binary bits for 16 ascii values (1 ascii value -> 8 bits of binary digits, 16 x 8 = 128 bits)",
        "55": "# converting the 16 char. key string to 128 bits similarly",
        "58": "# circular left shift each block of pt_128 individually (that's what block cipher wants to achieve, separated encryption)",
        "63": "# XORing each 128 bits block with key's 128 bits",
        "66": "# the latter half of the main list is containing the actual XORed result",
        "68": "# forming the cipher_text in string format (which will be equal to the length of plain_text) from the blocks of bits",
        "75": "# getting the required setup of blocks of 128 bits (same as plain_text)",
        "82": "# Since XOR was the last thing done when encrypting, it will be the first thing done when decrypting (also XOR because XORing an XOR brings us back to the starting bits)",
        "87": "# now the XOR'ed bits are to be circular right shifted, i.e the reverse direction"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Electronic_Code_Book/ECB_OP_1.png"
      ],
      "bgColors": {
        "ECB_OP_1.png": "#181616"
      }
    },
    "Hill_Cipher_3x3": {
      "lang": "py",
      "codeString": "#\nimport numpy as np\nimport math\nfrom typing import List\n\ndef dynamic_list_slicer(list_, slice_size):\n  return [list_[i - slice_size: i] for i in range(slice_size, len(list_) + 1, slice_size)]\n\ndef return_reqd_matrices(text, key, return_pt_matrices = True):\n  char_decimal_eqv = {chr(i): i - 65 for i in range(65, 91)}\n  key_mx = dynamic_list_slicer(list(map(lambda x: char_decimal_eqv[x], list(key))), 3)\n  if return_pt_matrices:\n    text_blocks = dynamic_list_slicer(list(map(lambda x: char_decimal_eqv[x], list(text))), 9)    #\n    text_cde_matrices = [[block[i - 3: i] for i in range(3, len(block) + 1, 3)] for block in text_blocks]\n    return text_cde_matrices, key_mx\n  else:\n    return key_mx\n  \ndef hill_cipher_encryption(plain_text, key):\n  decimal_char_eqv = {i - 65: chr(i) for i in range(65, 91)}\n  cipher_text = \"\"\n  \n  pt_matrices, key_mx = return_reqd_matrices(plain_text, key)\n  print(\"Key matrix: \", key_mx)\n  print(\"Plain Text Matrices: \", pt_matrices)\n  \n  encrypted_matrices = []\n  for pt_mx in pt_matrices:\n    enc_mx = (np.dot(key_mx, pt_mx) % 26).tolist()\n    encrypted_matrices.append(enc_mx)\n  \n  print(\"Encrypted Matrices: \", encrypted_matrices)\n  for ct_mx in encrypted_matrices:\n    cipher_text += \"\".join([decimal_char_eqv[col] for row in ct_mx for col in row])\n  return cipher_text\n\n#\ndef extended_euclidean_algorithm(b, a = 26):\n  exe_table = {'x': [1, 0], 'y': [0, 1], 'r': [a, b], 'q': [-1]} \n  #\n  while exe_table['r'][-1] != 1:                                         \n    exe_table['q'].append(math.floor(exe_table['r'][-2] / exe_table['r'][-1]))  \n    exe_table['x'].append(exe_table['x'][-2] - exe_table['x'][-1] * exe_table['q'][-1])    \n    exe_table['y'].append(exe_table['y'][-2] - exe_table['y'][-1] * exe_table['q'][-1])\n    exe_table['r'].append(exe_table['r'][-2] % exe_table['r'][-1])\n    #\n  return (exe_table['y'][-1]) % a         #\n\ndef find_key_adj_mx(key_mx):\n  indices = [(i, j) for i in range(3) for j in range(3)]\n  cofactor_key_mx = [[0 for i in range(len(key_mx))] for j in range(len(key_mx))]\n  for i in range(len(cofactor_key_mx)):\n    for j in range(len(cofactor_key_mx)):\n      #\n      minor_mx = dynamic_list_slicer([key_mx[inx[0]][inx[1]] for inx in indices if inx[0] != i and inx[1] != j], 2)     #\n      #\n      cofactor_key_mx[i][j] = ((-1) ** (i + j)) * round(np.linalg.det(minor_mx))\n  adj_key_mx = (np.transpose(np.array(cofactor_key_mx)) % 26).tolist()\n  return adj_key_mx\n\ndef hill_cipher_decryption(cipher_text, key):\n  decimal_char_eqv = {i - 65: chr(i) for i in range(65, 91)}\n  plain_text = \"\"\n  ct_matrices, key_mx = return_reqd_matrices(cipher_text, key)\n  print(\"Key matrix: \", key_mx)\n  print(\"Cipher Text Matrices: \", ct_matrices)\n\n  #\n  #\n  det_key_mx = round(np.linalg.det(np.array(key_mx))) % 26\n  print(\"Determinant of Key Matrix: \", det_key_mx)\n  #\n  inverted_det = extended_euclidean_algorithm(det_key_mx)\n  print(\"Inverted Key Matrix Determinant: \", inverted_det)\n  \n  #\n  adj_key_mx = find_key_adj_mx(key_mx)\n  print(\"Adjoint Key Matrix: \", adj_key_mx)\n  \n  #\n  inv_key_mx = ((np.array(adj_key_mx) * inverted_det) % 26).tolist()\n  print(\"Inverse Key Matrix: \", inv_key_mx)\n\n  decrypted_matrices = []\n  for ct_mx in ct_matrices:\n    decrypted_matrices.append((np.dot(inv_key_mx, ct_mx) % 26).tolist())\n  \n  for dct_mx in decrypted_matrices:\n    plain_text += \"\".join([decimal_char_eqv[col] for row in dct_mx for col in row])\n  \n  return plain_text\n\ndef suggest_valid_keys(key_mx: list):\n  decimal_char_eqv = {i - 65: chr(i) for i in range(65, 91)} \n  for row_i in range(len(key_mx)):\n    for col_i in range(len(key_mx)):\n      og_value = key_mx[row_i][col_i]\n      for i in range(26):\n        key_mx[row_i][col_i] = (key_mx[row_i][col_i] + i) % 26\n        #\n        if math.gcd(round(np.linalg.det(key_mx)) % 26, 26) == 1:\n          #\n          print(\"\".join([decimal_char_eqv[j] for i in key_mx for j in i]))\n      key_mx[row_i][col_i] = og_value\n\n#\ndef validate_key(plain_text, key):\n  key_mx = return_reqd_matrices(plain_text, key, False)\n  det_key_mx = round(np.linalg.det(np.array(key_mx))) % 26\n  #\n  if det_key_mx == 0 or math.gcd(26, det_key_mx) != 1:\n    while det_key_mx == 0 or math.gcd(26, det_key_mx) != 1:\n      suggest_valid_keys(key_mx)\n      key = input(\"Key was invalid, please use one of the suggested keys based on your key(if no suggestions, try another random key): \")[:9].upper().replace(\" \", \"\")\n      key_mx = return_reqd_matrices(plain_text, key, False)\n      det_key_mx = round(np.linalg.det(np.array(key_mx))) % 26\n  \n  return key\n\ndef hill_cipher():\n  plain_text = input(\"Enter the plain text (uppercase English Alphabets only): \").upper().replace(\" \", \"\")\n  while len(plain_text) % 9 != 0:\n    plain_text += 'X'\n  key = input(\"Enter the 9-letter key: \")[:9].upper().replace(\" \", \"\")\n  while len(key) != 9:\n    key += 'X'\n  \n  key = validate_key(plain_text, key)\n  \n  cipher_text = hill_cipher_encryption(plain_text, key)\n  print(\"\\033[38;2;240;10;10mCipher Text: \", cipher_text, \"\\033[0m\")\n  plain_text = hill_cipher_decryption(cipher_text, key)\n  print(\"\\033[38;2;10;240;10mDeciphered Text: \", plain_text, \"\\033[0m\")\n\nhill_cipher()",
      "comments": {
        "1": "#~ A simple Python program to implement Hill Cipher (Encryption and Decryption)",
        "13": "# each block is of len = 9, 3 x 3 matrices will be formed for each block",
        "37": "# !for a multiplicative inverse to exist, the terms a and b must be co-prime... and in range 2-26 here",
        "40": "# print(exe_table)        ",
        "46": "# print(exe_table, end=\"\\n\\n\")",
        "47": "# taking care of additive inverse if applicable",
        "54": "# print(i, j, key_mx[i][j], end = \"  \")",
        "55": "# follows the exact logic in finding minor matrix manually",
        "56": "# print(minor_mx)",
        "68": "#! Finding key_inv_mx (base 26)",
        "69": "#~ Finding Determinant of key matrix, cannot have a singular matrix i.e det = 0 cause those are not invertible",
        "72": "#~ Modulo multiplicative inverse of the det (base 26)",
        "76": "#~ getting the adjoint matrix",
        "80": "#~ getting the inverse key matrix by inv_key_mx = adj_key_mx / det(key_mx)",
        "100": "# print(*key_mx)",
        "102": "# print(round(np.linalg.det(key_mx)) % 26, \"\".join([decimal_char_eqv[j] for i in key_mx for j in i]))",
        "106": "# passing plain_text just so I can call the return_reqd_matrices function",
        "110": "# print(det_key_mx)"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Hill_Cipher_3x3/HC_OP_1.png"
      ],
      "bgColors": {
        "HC_OP_1.png": "#181616"
      }
    },
    "Playfair_Cipher": {
      "lang": "py",
      "codeString": "#\nfrom itertools import permutations\n\ndef process_pt(text: str):\n  pairs, idx = [], 2\n  while idx <= len(text) + 1:\n    pair = text[idx - 2: idx]\n    if len(pair) == 1:                          #\n      text += 'X' if text[-1] != 'X' else 'Y'\n      continue      \n    if pair[0] == pair[1] or (pair[0] == \"I\" and pair[1] == \"J\") or (pair[0] == \"J\" and pair[1] == \"I\"):        #\n      text = text[:idx - 1] + \"X\" + text[idx - 1:]\n      continue\n    pairs.append(pair)      \n    idx += 2\n  return pairs\n\ndef unique_chars(text: str):\n  unique = []\n  for c in text:\n    if c not in unique:\n      unique.append(c)\n  return unique\n\ndef make_enc_mx(key: str):\n  enc_mx = []\n  enc_mx.extend(unique_chars(key))\n  for i in range(65, 91):\n    if chr(i) not in enc_mx:\n      enc_mx.append(chr(i))\n\n  #\n  enc_mx.pop(enc_mx.index('J'))\n  return [enc_mx[i - 5: i] for i in range(5, len(enc_mx) + 1, 5)]     #\n\ndef give_rc_inx(mx, char):\n  char = 'I' if char == 'J' else char\n  for row in range(len(mx)):\n    for col in range(len(mx[row])):\n      if mx[row][col] == char:\n        return row, col\n  return -1, -1\n\ndef playfair_encryption(plain_text: str, key: str):\n  cipher_text = \"\"\n  enc_mx = make_enc_mx(key)\n  #\n  pt_ch_pairs = process_pt(plain_text)\n  for pair in pt_ch_pairs:\n    r1, c1 = give_rc_inx(enc_mx, pair[0])\n    r2, c2 = give_rc_inx(enc_mx, pair[1])\n    #\n    if r1 == r2:\n      cipher_text += (enc_mx[r1][(c1 + 1) % 5] + enc_mx[r2][(c2 + 1) % 5])\n    elif c1 == c2:\n      cipher_text += (enc_mx[(r1 + 1) % 5][c1] + enc_mx[(r2 + 1) % 5][c2])\n    else:\n      cipher_text += (enc_mx[r1][c2] + enc_mx[r2][c1])\n  return cipher_text\n\n#\ndef all_pt_perms(plain_text: str):\n  pt_perms = []\n  i_idx_psns = [i for i in range(len(plain_text)) if plain_text[i] == \"I\"]\n  ij_perms = []\n  for itr in range(len(i_idx_psns) + 1):    #\n    ij_perms.extend(list(permutations(i_idx_psns, itr)))\n  \n  for perm in ij_perms:\n    pt_list = list(plain_text)\n    for idx in perm:\n      pt_list[idx] = 'J'\n    pt_perms.append(\"\".join(pt_list))\n  return list(set(pt_perms))\n\ndef playfair_decryption(cipher_text: str, key: str):\n  plain_text = \"\"\n  enc_mx = make_enc_mx(key)\n  ct_ch_pairs = process_pt(cipher_text)\n  \n  for pair in ct_ch_pairs:\n    r1, c1 = give_rc_inx(enc_mx, pair[0])\n    r2, c2 = give_rc_inx(enc_mx, pair[1])\n    if r1 == r2:\n      plain_text += (enc_mx[r1][(c1 - 1) % 5] + enc_mx[r2][(c2 - 1) % 5])\n    elif c1 == c2:\n      plain_text += (enc_mx[(r1 - 1) % 5][c1] + enc_mx[(r2 - 1) % 5][c2])\n    else:\n      plain_text += (enc_mx[r1][c2] + enc_mx[r2][c1])\n  \n  pt_perms = all_pt_perms(plain_text)\n  return pt_perms\n\ndef playfair():\n  plain_text = input(\"Enter the message: \").upper().replace(\" \", \"\")\n  key = input(\"Enter the key (preferably len(key) < len(plain_text): \")[:len(plain_text)].upper().replace(\" \", \"\")\n  cipher_text = playfair_encryption(plain_text, key)\n  print(\"Cipher Text:\\033[38;5;197m\", cipher_text,\"\\033[0m\\n\")\n  all_pt = playfair_decryption(cipher_text, key)\n  for i in range(len(all_pt)):\n    print(f\"\\033[38;2;{255 if i % 2 != 0 else 0};{255 if i % 2 == 0 else 75};{220 if i % 2 == 0 else 130}m{i}: {all_pt[i]}\")\n  print(\"\\033[0m\")\nplayfair()",
      "comments": {
        "1": "#~ Implementing playfair cipher for uppercase English alphabets",
        "8": "# safeguarding from index out of range errors at the last pair",
        "11": "# Have to especially consider consequent IJ occurences ",
        "32": "#! This variation of playfair cipher always treats Js as Is",
        "34": "# converted to 2D",
        "47": "# print(*enc_mx, sep=\"\\n\")",
        "52": "# print(f\"{pair}: {r1, c1}, {r2, c2}\")",
        "61": "#! Showing all possible texts to the receiver if the decrypted text contains 'I' (maybe reduces security levels but I feel it enhances receiver's exp)",
        "66": "# counts from 0 till all Is i.e no change to all Is as well as all Is changed to J"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Playfair_Cipher/PC_OP_1.png",
        "OP_ss/Sem_V-IS/Playfair_Cipher/PC_OP_2.png"
      ],
      "bgColors": {
        "PC_OP_1.png": "#181616",
        "PC_OP_2.png": "#181616"
      }
    },
    "Simplified_DES": {
      "lang": "py",
      "codeString": "#\n\nfrom copy import deepcopy\ndef dec_to_binary(dec_num):\n  def mechanism(num):\n    if num >= 1:\n      mechanism(num // 2)\n      bin_list.append(num % 2)\n  bin_list = []\n  mechanism(dec_num)\n  return bin_list\n\ndef ascii_list_binarizer(ascii_list):\n  binary_list = []\n  for num in ascii_list:\n    bin_num = dec_to_binary(num)\n    while len(bin_num) != 8:        #\n      bin_num.insert(0, 0)\n    binary_list.extend(bin_num)\n  return binary_list\n\ndef dynamic_list_pooler(list_, pool_size):\n  pooled_list = []\n  for i in range(pool_size, len(list_) + 1, pool_size):\n    pooled_list.append(list_[i-pool_size: i])\n  return pooled_list\n\ndef bin_to_decimal(eight_bits):\n  dec_number = 0\n  for i in range(len(eight_bits) - 1, -1, -1):\n    if eight_bits[i] == 1:\n      dec_number += 2 ** (len(eight_bits) - 1 - i)\n  return dec_number\n\ndef bin_list_asciirizer(bin_list, poolrange = 8):\n  ascii_list = []\n  for block_inx in range(poolrange, len(bin_list) + 1, poolrange):\n    ascii_list.append(bin_to_decimal(bin_list[block_inx-poolrange: block_inx]))\n  return ascii_list\n\ndef expansion_permutation(RPT):\n  RPT_8_4 = dynamic_list_pooler(RPT, 4)\n  RPT_8_6 = []\n  for i in range(len(RPT_8_4)):\n    RPT_8_6.append(deepcopy(RPT_8_4[i]))\n    RPT_8_6[-1].insert(0, RPT_8_4[(i - 1) % 8][-1])\n    RPT_8_6[-1].append(RPT_8_4[(i + 1) % 8][0])\n  \n  #\n  RPT_48 = []\n  [(RPT_48.extend(i)) for i in RPT_8_6]\n  return RPT_48\n\ndef s_box_substitution(RPT_48, s_box):\n  RPT_8_6 = dynamic_list_pooler(RPT_48, 6)\n  RPT_8_4 = []\n  for block in RPT_8_6:\n    RPT_8_4.append(dec_to_binary(s_box[bin_to_decimal([block[0], block[-1]])][bin_to_decimal(block[1:5])]))\n    while len(RPT_8_4[-1]) != 4:    #\n      RPT_8_4[-1].insert(0, 0)\n  \n  RPT_32 = []\n  [RPT_32.extend(i) for i in RPT_8_4]\n  return RPT_32\n\ndef function_block(RPT_32, key_48, s_box):\n  #\n  RPT_48 = expansion_permutation(RPT_32)\n  \n  #\n  for i in range(len(RPT_48)):\n    RPT_48[i] = RPT_48[i] ^ key_48[i]\n\n  #\n  RPT_32 = s_box_substitution(RPT_48, s_box)  \n  return RPT_32\n\ndef simplified_DES_encryption(pt_64, keys_48, s_box, noofrounds = 2):\n  cipher_text = \"\"\n  curr_round = 1\n  LPT, RPT = pt_64[:32], pt_64[32:]\n  while curr_round <= noofrounds:\n    #\n    pRPT = function_block(RPT, keys_48[curr_round - 1], s_box[curr_round - 1])\n    xRPT = [x ^ y for x, y in zip(LPT, pRPT)]\n    LPT = RPT\n    RPT = xRPT\n    curr_round += 1\n  #\n  ct_64 = RPT + LPT\n  cipher_text = \"\".join(list(map(lambda x: chr(x), bin_list_asciirizer(ct_64))))\n  return cipher_text, ct_64\n\ndef simplified_DES():\n  s_box_1 = [[14,\t4, 13, 1,\t2, 15, 11, 8, 3, 10, 6, 12, 5, 9, 0, 7], \n  [0, 15, 7, 4, 14, 2, 13, 1, 10, 6, 12, 11, 9, 5, 3, 8], \n  [4, 1, 14, 8, 13, 6, 2, 11, 15, 12, 9, 7, 3, 10, 5, 0], \n  [15, 12, 8, 2, 4, 9, 1, 7, 5, 11, 3, 14, 10, 0, 6, 13]]\n\n  s_box_2 = [[15, 1, 8, 14, 6, 11, 3, 4, 9, 7, 2, 13, 12, 0, 5, 10],\n  [3, 13, 4, 7, 15, 2, 8, 14, 12, 0, 1, 10, 6, 9, 11, 5],\n  [0, 14, 7, 11, 10, 4, 13, 1, 5, 8, 12, 6, 9, 3, 2, 15],\n  [13, 8, 10, 1, 3, 15, 4, 2, 11, 6, 7, 12, 0, 5, 14, 9]]\n\n  s_box_3 = [[12, 1, 10, 15, 9,\t2, 6,\t8, 0, 13, 3, 4,\t14,\t7, 5, 11],\n\t[10, 15, 4,\t2, 7,\t12,\t9, 5,\t6, 1, 13,\t14,\t0, 11, 3,\t8],\n\t[9,\t14,\t15,\t5, 2,\t8, 12, 3,\t7, 0,\t4, 10, 1,\t13,\t11,\t6],\n\t[4,\t3, 2,\t12,\t9, 5,\t15,\t10,\t11,\t14,\t1, 7,\t6, 0,\t8, 13]]  \n\n  plain_text = input(\"Enter the 8 character text: \")[:8]\n  pt_64 = ascii_list_binarizer(list(map(lambda x: ord(x), list(plain_text))))\n  key_1 = input(\"Enter the first key: \")[:6]\n  key_1_48 = ascii_list_binarizer(list(map(lambda x: ord(x), list(key_1))))\n  key_2 = input(\"Enter the second key: \")[:6]\n  key_2_48 = ascii_list_binarizer(list(map(lambda x: ord(x), list(key_2))))\n  key_3_48 = ascii_list_binarizer(list(map(lambda x: ord(x), list(reversed(key_2)))))\n  print(\"A \\033[38;5;189mthird key\\033[0m has been derived internally from the keys entered.\")\n\n  cipher_text, ct_64 = simplified_DES_encryption(pt_64, keys_48 = (key_1_48, key_2_48, key_1_48), s_box = (s_box_1, s_box_2, s_box_3), noofrounds = 3)\n  print(\"\\033[38;5;119mCipher Text:\", cipher_text, \"\\033[0m\")\n  plain_text, pt_64 = simplified_DES_encryption(ct_64, keys_48 = (key_1_48, key_2_48, key_1_48), s_box = (s_box_3, s_box_2, s_box_1), noofrounds = 3)\n  print(\"\\033[38;5;197mDeciphered Text:\", plain_text, \"\\033[0m\")\n\nsimplified_DES()",
      "comments": {
        "1": "#~ Implementing a simplified version of Data Encryption Standard (DES) (64 bits (8 chars.) input)",
        "17": "# regulation -> compulsorily 8 bits to represent every number",
        "49": "# flattening",
        "59": "# regulation -> since there is gonna be numbers from 0 - 15 in any of the s_box cell, 4 bits compulsion enforced on binary repr. of these numbers to make 4 x 8 = 32 bits",
        "67": "#~ Expanded RPT which is a list(8 members) of lists(6 members) which total upto 48 bits (This will be the naming convention throughout the program for 2D lists)",
        "70": "#~ XOR with the key's 48 bits",
        "74": "#~ Reducing the 48 RPT bits to 32",
        "83": "# do the crisscross",
        "89": "# now do the final \"straight\" output"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Simplified_DES/SDES_OP_1.png"
      ],
      "bgColors": {
        "SDES_OP_1.png": "#181616"
      }
    },
    "Simplified_RSA_Algorithm": {
      "lang": "py",
      "codeString": "import math\n#\ndef make_closest_prime(number, *exclude):\n  i = 2\n  while i <= int(number / 2) + 1:\n    if number % i == 0:\n      number += 1\n      while number in exclude:\n        number += 1\n      i = 2\n    else:\n      i += 1\n  return number\n\ndef relatively_prime_finder(totient, *exclude):\n  for i in range(2, int(totient / 2) + 1):           #\n    if math.gcd(i, totient) == 1:\n      if i not in exclude:\n        return i\n\ndef extended_euclidean_algorithm(\u03a6n, e):\n  exe_table = {'x': [1, 0], 'y': [0, 1], 'r': [\u03a6n, e], 'q': [-1]}         #\n  \n  while exe_table['r'][-1] != 1:                                         #\n    exe_table['q'].append(int(exe_table['r'][-2] / exe_table['r'][-1]))  #\n    exe_table['x'].append(exe_table['x'][-2] - exe_table['x'][-1] * exe_table['q'][-1])   #\n    exe_table['y'].append(exe_table['y'][-2] - exe_table['y'][-1] * exe_table['q'][-1])\n    exe_table['r'].append(exe_table['r'][-2] % exe_table['r'][-1])\n\n  return (exe_table['y'][-1]) % \u03a6n         #\n\ndef RSA():\n  PT = int(input(\"Enter the number to be encrypted: \"))\n  print(\"Enter p and q which are public, mutually accepted numbers between the sender and the receiver\")\n  p = len(input(\"Enter the string p, (length should be > 10): \"))\n  if p < 10:\n    raise ValueError(\"Cannot have number lesser than 10 for 'p'\")\n  while True:\n    q = len(input(\"Enter the passphrase q, (length should be > 10 \\033[1mand not as same as p\\033[0m): \"))\n    if q < 10:\n      raise ValueError(\"Cannot have number lesser than 10 for 'q'\")\n    elif q == p:\n      print(\"Length of q cannot be p!\")\n    else:    \n      break\n  p = make_closest_prime(p)\n  q = make_closest_prime(q, p)\n\n  print(f\"p = {p}, q = {q}\")\n  n = p * q\n  \u03a6n = (p - 1) * (q - 1)\n  print(f\"n = {n}, \u03a6n = {\u03a6n}\")\n  e = relatively_prime_finder(\u03a6n, p, q)\n  print(f\"e = {e}\")\n  d = extended_euclidean_algorithm(\u03a6n, e)\n  print(\"d = \", d)\n\n  PT %= n\n  print(\"Plain Text: \", PT)\n  CT = (PT ** e) % n \n  print(\"Cipher Text: \", CT)\n\n  PT = (CT ** d) % n \n  print(\"Plain Text: \", PT)\n\nRSA()",
      "comments": {
        "2": "#TODO - Rectify make_prime, add conditions for 0 and 1 length p and q ",
        "16": "# since e has to be less than totient ",
        "22": "# initial conditions for every extended Euclidean algorithm table",
        "24": "# The stopping condition in r column whose corr. y is our 'd'  -> (This was a doubt too, why is the answer of y considered as d and what does the value of x signify)",
        "25": "# for this column, the current value (one which is just getting appended) is always the division of the pre-previous and previous",
        "26": "# for both 'x' and 'y' columns, the current value comes out from the formula xi = xi-2 - xi-1*qi-1 ",
        "30": "# taking care of additive inverse if applicable"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Simplified_RSA_Algorithm/SRSA_OP_1.png"
      ],
      "bgColors": {
        "SRSA_OP_1.png": "#181616"
      }
    },
    "Vigenere_Cipher_26": {
      "lang": "py",
      "codeString": "#\n#\n\n#\nvigenere_table = [[chr((i + j - 65) % 26 + 65) for j in range(26)] for i in range(65, 91)]\n\"\"\"\nTable formation:\nAs Vigenere table is 26 caesar ciphers essentially, I used that logic to form the table (now, lol) row by row\n1. i goes from 65 - 90 i.e the ASCII values for A - Z. \n2. For each i, j goes 0 - 25, so, \n3. (i + j) goes 65 - 90 for i = 65 j = [0, 25]; 66 - 91 for i = 66 and j = [0, 25], and so on\n4. For e.g, when (i + j) = 91, (i + j - 65) = 26, (i + j - 65) % 26 = 0 and 0 + 65 would be 65 which is ASCII for A, hence implementing caesar cycle properly (same logic as done in the standalone caesar cipher but with 26 chars. instead of 95)\n\"\"\"\n#\n\ndef vigenere_encryption(plain_text, keyword):\n  cipher_text = \"\"\n  for i in range(len(plain_text)):                                                     #\n    cipher_text += vigenere_table[ord(keyword[i]) - 65][ord(plain_text[i]) - 65]       #\n  return cipher_text\n\ndef vigenere_decryption(cipher_text, keyword):\n  plain_text = \"\"\n  for i in range(len(cipher_text)):\n    plain_text += chr((vigenere_table[ord(keyword[i]) - 65].index(cipher_text[i])) + 65)      #\n  return plain_text\n  \ndef vigenere_cipher():\n  plain_text = input(\"Enter the plain text: \").upper()\n  keyword = input(\"Enter the keyword: \")[:len(plain_text)].upper()  #\n  while len(keyword) < len(plain_text):\n    keyword += keyword\n  keyword = keyword[:len(plain_text)]\n  #\n\n  cipher_text = vigenere_encryption(plain_text, keyword)\n  print(\"Encrypted Text: \", cipher_text)\n  \n  plain_text = vigenere_decryption(cipher_text, keyword)\n  print(\"Decrypted Text: \", plain_text)\n\nvigenere_cipher()",
      "comments": {
        "1": "#~ Implementing Vigenere Cipher for uppercase English alphabets",
        "2": "# https://pages.mtu.edu/~shene/NSF-4/Tutorial/VIG/Vig-Base.html",
        "4": "#* vigenere_table is a list of 26 lists, with each list having 26 chars. starting one step ahead successively",
        "14": "# alternatively, i think dictionary of dictionaries could've also been used",
        "18": "# range used so that 'i' can be commonly used for both keyword and pt",
        "19": "#* The cipher text characters are the characters at the intersection of keyword(X-axis)(rows) and plaintext(Y-axis)(columns), -65 for 65 -> 90 -->> 0 -> 25 for table indices",
        "25": "#* Plain text is the column index (converted to \u03b1\u00df) of the cipher_text char. in the keyword char.'s corresponding row",
        "30": "# precaution if the len(keyword) entered is > len(plain_text)",
        "34": "# print(keyword)"
      },
      "outputSrcs": [
        "OP_ss/Sem_V-IS/Vigenere_Cipher_26/VC_OP_1.png"
      ],
      "bgColors": {
        "VC_OP_1.png": "#181616"
      }
    }
  },
  "Sem_VI-IPCV": {
    "Basic_Operations": {
      "lang": "py",
      "codeString": "import cv2 as cv\nimport matplotlib.pyplot as plt\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nprint(img[200][0])\nprint(img.shape)\n\ncv.imshow(\"Oxalis\", img)\ncv.waitKey(0)\ncv.destroyAllWindows()\n\n #\n\n #\nrgb_img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nplt.imshow(rgb_img)\n\ngrayed = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\ncv.imshow(\"Gray Oxalis\", grayed)\ncv.waitKey(0)\ncv.destroyAllWindows()\nplt.imshow(cv.cvtColor(grayed, cv.COLOR_BGR2RGB)) #\n\ncropped_img = img[img.shape[0] // 2:, img.shape[1] // 2:]\ncv.imshow(\"Cropped Oxalis\", cropped_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\nprint(cropped_img.shape)\nplt.imshow(cv.cvtColor(cropped_img, cv.COLOR_BGR2RGB))\n\nimg2 = cv.imread(\"../Sample Images/Cat.jpg\")\nprint(img2.shape)\nadded_img = cv.add(img, img2)\ncv.imshow(\"Added Oxalis\", added_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\n\nfig = plt.figure(figsize=(15, 7))\ncolumns = 3\nfig.add_subplot(1, columns, 1)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.title(\"First Image\")\n\nfig.add_subplot(1, columns, 2)\nplt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\nplt.title(\"Second Image\")\n\nfig.add_subplot(1, columns, 3)\nplt.imshow(cv.cvtColor(added_img, cv.COLOR_BGR2RGB))\nplt.title(\"Added Image\")\n\nsubtracted_img_1 = cv.subtract(img, img2)\ncv.imshow(\"Subtracted (1-2) Oxalis\", subtracted_img_1)\ncv.waitKey(0)\ncv.destroyAllWindows()\nfig = plt.figure(figsize=(15, 7))\ncolumns = 3\nfig.add_subplot(1, columns, 1)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.title(\"First Image\")\n\nfig.add_subplot(1, columns, 2)\nplt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\nplt.title(\"Second Image\")\n\nfig.add_subplot(1, columns, 3)\nplt.imshow(cv.cvtColor(subtracted_img_1, cv.COLOR_BGR2RGB))\nplt.title(\"Subtracted Image\")\n\nsubtracted_img_2 = cv.subtract(img2, img)\ncv.imshow(\"Subtracted (2-1) Oxalis\", subtracted_img_2)\ncv.waitKey(0)\ncv.destroyAllWindows()\nfig = plt.figure(figsize=(15, 7))\ncolumns = 3\nfig.add_subplot(1, columns, 1)\nplt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\nplt.title(\"First Image\")\n\nfig.add_subplot(1, columns, 2)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.title(\"Second Image\")\n\nfig.add_subplot(1, columns, 3)\nplt.imshow(cv.cvtColor(subtracted_img_2, cv.COLOR_BGR2RGB))\nplt.title(\"Subtracted Image\")\n\nand_img = cv.bitwise_and(img, img2)\ncv.imshow(\"ANDed Oxalis\", and_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\nfig = plt.figure(figsize=(15, 7))\ncolumns = 3\nfig.add_subplot(1, columns, 1)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.title(\"First Image\")\n\nfig.add_subplot(1, columns, 2)\nplt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\nplt.title(\"Second Image\")\n\nfig.add_subplot(1, columns, 3)\nplt.imshow(cv.cvtColor(and_img, cv.COLOR_BGR2RGB))\nplt.title(\"ANDed Image\")\n\nor_img = cv.bitwise_or(img, img2)\ncv.imshow(\"ORed Oxalis\", or_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\nfig = plt.figure(figsize=(15, 7))\ncolumns = 3\nfig.add_subplot(1, columns, 1)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.title(\"First Image\")\n\nfig.add_subplot(1, columns, 2)\nplt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\nplt.title(\"Second Image\")\n\nfig.add_subplot(1, columns, 3)\nplt.imshow(cv.cvtColor(or_img, cv.COLOR_BGR2RGB))\nplt.title(\"ORed Image\")\n\nxor_img = cv.bitwise_xor(img, img2)\ncv.imshow(\"XORed Oxalis\", xor_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\nfig = plt.figure(figsize=(15, 7))\ncolumns = 3\nfig.add_subplot(1, columns, 1)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.title(\"First Image\")\n\nfig.add_subplot(1, columns, 2)\nplt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\nplt.title(\"Second Image\")\n\nfig.add_subplot(1, columns, 3)\nplt.imshow(cv.cvtColor(xor_img, cv.COLOR_BGR2RGB))\nplt.title(\"XORed Image\")\n\nnot_img = cv.bitwise_not(img)\ncv.imshow(\"NOT Oxalis\", not_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\nplt.imshow(cv.cvtColor(not_img, cv.COLOR_BGR2RGB))\nplt.title(\"NOTed Oxalis\")\n\nnot_img = cv.bitwise_not(img2)\ncv.imshow(\"NOT Cat\", not_img)\ncv.waitKey(0)\ncv.destroyAllWindows()\nplt.imshow(cv.cvtColor(not_img, cv.COLOR_BGR2RGB))\nplt.title(\"NOTed Cat\")",
      "comments": {
        "12": " plt.imshow(img)    misconversion",
        "14": " matplotlib takes in the array of 3 values (for a pixel) as RGB but cv2 forms those arrays of 3 vals while imreading as BGR so a conversion is needed",
        "22": " so while using matplotlib, convert the BGR to RGB everytime"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/1.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/2.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/3.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/4.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/5.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/6.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/7.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/8.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/9.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/10.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/11.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/12.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/13.png",
        "./OP_ss/Sem_VI-IPCV/Basic_Operations/14.png"
      ],
      "bgColors": {
        "1.png": "#111111",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#111111",
        "5.png": "#ffffff",
        "6.png": "#111111",
        "7.png": "#ffffff",
        "8.png": "#ffffff",
        "9.png": "#000000",
        "10.png": "#000000",
        "11.png": "#ffffff",
        "12.png": "#ffffff",
        "13.png": "#ffffff",
        "14.png": "#ffffff"
      },
      "markdown": []
    },
    "Edge_Detection": {
      "lang": "py",
      "codeString": "import numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nimgg = imgg[:1080, :1080]\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(25, 40))\n  fig.set_dpi(150)\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ndef convolute_image_33(img, mask):\n  mask = np.array(mask)\n  conv_img = [[0 for _ in range(img.shape[1])] for _ in range(img.shape[0])]\n  for x in range(1, img.shape[0] - 1):\n    for y in range(1, img.shape[1] - 1):\n      convoluted = img[x - 1: x + 2, y - 1: y + 2] * mask\n      val = sum(map(sum, convoluted))\n      if val > 0:\n        conv_img[x][y] = val if val <= 255 else 255\n      else:\n        conv_img[x][y] = 0\n  return np.array(conv_img)\n\nprewitts_x_mask = [[x - 1 for _ in range(3)] for x in range(3)]\nprint(\"Prewitts X-Gradient Mask\", end=\"\\n\")\nprint(*prewitts_x_mask, sep=\"\\n\")\nprewitts_y_mask = [[y - 1 for y in range(3)] for _ in range(3)]\nprint(\"\\nPrewitts Y-Gradient Mask\", end=\"\\n\")\nprint(*prewitts_y_mask, sep=\"\\n\")\n\nx_gradient_image = convolute_image_33(imgg, prewitts_x_mask)\ny_gradient_image = convolute_image_33(imgg, prewitts_y_mask)\nfinal_image = x_gradient_image + y_gradient_image\n\nmatplot_images(imgg, x_gradient_image, y_gradient_image, final_image, titles=[\"Original Grayscale Image\", \"X-image\", \"Y-image\", \"Image after Prewitts Filter\"])\n\nsobel_x_mask = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\nprint(\"Sobel X-Gradient Mask\", end= \"\\n\")\nprint(*sobel_x_mask, sep=\"\\n\")\nsobel_y_mask = np.array(sobel_x_mask).T.tolist() #\nprint(\"\\nSobel Y-Gradient Mask\", end= \"\\n\")\nprint(*sobel_y_mask, sep=\"\\n\")\n\nx_gradient_image = convolute_image_33(imgg, sobel_x_mask)\ny_gradient_image = convolute_image_33(imgg, sobel_y_mask)\n\nfinal_image = x_gradient_image + y_gradient_image\nmatplot_images(imgg, x_gradient_image, y_gradient_image, final_image, titles=[\"Original Grayscale Image\", \"X-image\", \"Y-image\", \"Image after Sobel Filter\"])",
      "comments": {
        "51": " transpose"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Edge_Detection/1.png",
        "./OP_ss/Sem_VI-IPCV/Edge_Detection/2.png",
        "./OP_ss/Sem_VI-IPCV/Edge_Detection/3.png",
        "./OP_ss/Sem_VI-IPCV/Edge_Detection/4.png",
        "./OP_ss/Sem_VI-IPCV/Edge_Detection/5.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#111111",
        "3.png": "#ffffff",
        "4.png": "#111111",
        "5.png": "#ffffff"
      },
      "markdown": []
    },
    "FD_Gaussian_Filters": {
      "lang": "py",
      "codeString": "import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\n #\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(12, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ndef freq_dom_gaussian_filter(img, filter_type='low', Do = 120):\n  noofrows, noofcols = img.shape\n\n #\n  dft_2d = np.fft.fft2(img)\n  \n #\n  shifted_2d_dft = np.fft.fftshift(dft_2d)\n  \n #\n  D_u_v = [[(np.sqrt((u - noofrows // 2) ** 2 + (v - noofcols // 2) ** 2)) for v in range(noofcols)] for u in range(noofrows)]\n  if filter_type == 'low': \n    H_u_v = [[np.e ** (-(D_u_v[u][v]) ** 2 / (Do ** 2)) for v in range(noofcols)] for u in range(noofrows)]\n  elif filter_type == 'high':\n    H_u_v = [[1 - (np.e ** (-(D_u_v[u][v]) ** 2 / (Do ** 2))) for v in range(noofcols)] for u in range(noofrows)]\n  else:\n    return\n    \n #\n  G_u_v = shifted_2d_dft * H_u_v\n  G_u_v = np.fft.ifftshift(G_u_v)\n\n #\n  reformed_img = np.real(np.fft.ifft2(G_u_v))\n  \n  return reformed_img\n\nglpf_filtered_img = freq_dom_gaussian_filter(imgg, 'low', 20)\n\nmatplot_images(imgg, glpf_filtered_img, titles=[\"Original Greyscale Image\", \"Gaussian LP image, Do = 20\"])\n\nglpf_filtered_img = freq_dom_gaussian_filter(imgg, 'low', 50)\n\nmatplot_images(imgg, glpf_filtered_img, titles=[\"Original Greyscale Image\", \"Gaussian LP image, Do = 50\"])\n\nglpf_filtered_img = freq_dom_gaussian_filter(imgg, 'low', 120)\n\nmatplot_images(imgg, glpf_filtered_img, titles=[\"Original Greyscale Image\", \"Gaussian LP image, Do = 120\"])\n\nghpf_filtered_img = freq_dom_gaussian_filter(imgg, 'high', 20)\n\nmatplot_images(imgg, ghpf_filtered_img, titles=[\"Original Greyscale Image\", \"Gaussian HP image, Do = 20\"])\n\nghpf_filtered_img = freq_dom_gaussian_filter(imgg, 'high', 50)\n\nmatplot_images(imgg, ghpf_filtered_img, titles=[\"Original Greyscale Image\", \"Gaussian HP image, Do = 50\"])\n\nghpf_filtered_img = freq_dom_gaussian_filter(imgg, 'high', 120)\n\nmatplot_images(imgg, ghpf_filtered_img, titles=[\"Original Greyscale Image\", \"Gaussian HP image, Do = 120\"])",
      "comments": {
        "11": " img.shape[0] is rows, img.shape[1] is columns",
        "25": " 1. Getting the 2D Discrete Fourier Transform",
        "28": " 2. Shifted 2D_DFT",
        "31": " 3. Forming the Ideal Low (or High) Pass Filter",
        "40": " 4. Multiplication and inverse shift",
        "44": " 5. Inverse 2D Discrete Fourier Transform"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/1.png",
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/2.png",
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/3.png",
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/4.png",
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/5.png",
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/6.png",
        "./OP_ss/Sem_VI-IPCV/FD_Gaussian_Filters/7.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#ffffff",
        "6.png": "#ffffff",
        "7.png": "#ffffff"
      },
      "markdown": []
    },
    "FD_Ideal_Pass_Filters": {
      "lang": "py",
      "codeString": "import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\n #\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(12, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ndef freq_dom_ideal_pass_filter(img, filter_type='low', Do = 120):\n  noofrows, noofcols = img.shape\n\n #\n  dft_2d = np.fft.fft2(img)\n  \n #\n  shifted_2d_dft = np.fft.fftshift(dft_2d)\n  \n #\n  D_u_v = [[(np.sqrt((u - noofrows // 2) ** 2 + (v - noofcols // 2) ** 2)) for v in range(noofcols)] for u in range(noofrows)]\n  if filter_type == 'low': \n    H_u_v = [[1 if d <= Do else 0 for d in row] for row in D_u_v]\n  elif filter_type == 'high':\n    H_u_v = [[0 if d < Do else 1 for d in row] for row in D_u_v]\n  else:\n    return\n    \n #\n  G_u_v = shifted_2d_dft * H_u_v\n  G_u_v = np.fft.ifftshift(G_u_v)\n\n #\n  reformed_img = np.real(np.fft.ifft2(G_u_v))\n  \n  return reformed_img\n\nilpf_filtered_img = freq_dom_ideal_pass_filter(imgg, 'low', 20)\n\nmatplot_images(imgg, ilpf_filtered_img, titles=[\"Original Greyscale Image\", \"ILPF image, Do = 20\"])\n\nilpf_filtered_img = freq_dom_ideal_pass_filter(imgg, 'low', 50)\n\nmatplot_images(imgg, ilpf_filtered_img, titles=[\"Original Greyscale Image\", \"ILPF image, Do = 50\"])\n\nilpf_filtered_img = freq_dom_ideal_pass_filter(imgg, 'low', 120)\n\nmatplot_images(imgg, ilpf_filtered_img, titles=[\"Original Greyscale Image\", \"ILPF image, Do = 120\"])\n\nihpf_filtered_img = freq_dom_ideal_pass_filter(imgg, 'high', 20)\n\nmatplot_images(imgg, ihpf_filtered_img, titles=[\"Original Greyscale Image\", \"IHPF image, Do = 20\"])\n\nihpf_filtered_img = freq_dom_ideal_pass_filter(imgg, 'high', 50)\n\nmatplot_images(imgg, ihpf_filtered_img, titles=[\"Original Greyscale Image\", \"IHPF image, Do = 50\"])\n\nihpf_filtered_img = freq_dom_ideal_pass_filter(imgg, 'high', 120)\n\nmatplot_images(imgg, ihpf_filtered_img, titles=[\"Original Greyscale Image\", \"IHPF image, Do = 120\"])",
      "comments": {
        "11": " img.shape[0] is rows, img.shape[1] is columns",
        "25": " 1. Getting the 2D Discrete Fourier Transform",
        "28": " 2. Shifted 2D_DFT",
        "31": " 3. Forming the Ideal Low (or High) Pass Filter",
        "40": " 4. Multiplication and inverse shift",
        "44": " 5. Inverse 2D Discrete Fourier Transform"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/1.png",
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/2.png",
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/3.png",
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/4.png",
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/5.png",
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/6.png",
        "./OP_ss/Sem_VI-IPCV/FD_Ideal_Pass_Filters/7.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#ffffff",
        "6.png": "#ffffff",
        "7.png": "#ffffff"
      },
      "markdown": []
    },
    "Histogram_Equalization": {
      "lang": "py",
      "codeString": "import numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nimg = cv.imread(\"./Periwinkle.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nimgg = imgg[:1080, :1080]\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\nimgg2 = np.array([[1, 1, 3, 6, 4, 3, 1], [5, 6, 3, 4, 5, 5, 3], [3, 4, 3, 2, 4, 3, 5], [5, 5, 4, 1, 3, 2, 3], [1, 3, 4, 5, 6, 5, 4], [4, 6, 4, 1, 2, 2, 3], [2, 4, 6, 3, 2, 4, 5]])\nmax_px_val = 256 #\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(12, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ndef return_frequency(img, max = 256):\n #\n #\n  frequency = {i: 0 for i in range(max)}\n  for x in range(img.shape[0]):\n    for y in range(img.shape[1]):\n      frequency[img[x][y]] += 1\n      \n  return frequency\n\nfreq = return_frequency(imgg, max_px_val)\nplt.figure(figsize=(15, 7))\nplt.bar(list(freq.keys()), list(freq.values()))\nplt.show()\n\ndef histogram_equalization(img, max = 256):  \n #\n  freqs = return_frequency(img, max)\n\n #\n  calcs = { \"n\": [i for i in range(max)], \n            \"nk\": [v for k, v in freqs.items()], \n            \"pdf\": [0 for _ in range(max)], \n            \"cdf\": [0 for _ in range(max)],\n            \"(L-1) * cdf\": [max - 1 for _ in range(max)], \n            \"rounding\": [0 for _ in range(max)] }\n  \n  for i in range(len(calcs[\"nk\"])):\n #\n    calcs[\"pdf\"][i] = calcs[\"nk\"][i] / sum(calcs[\"nk\"])\n    \n #\n    if i > 0:\n      calcs[\"cdf\"][i] = calcs[\"cdf\"][i - 1] + calcs[\"pdf\"][i]\n    else:\n      calcs[\"cdf\"][i] = calcs[\"pdf\"][i]\n    \n #\n    calcs[\"(L-1) * cdf\"][i] = calcs[\"(L-1) * cdf\"][i] * calcs[\"cdf\"][i]\n #\n    calcs[\"rounding\"][i] = round(calcs[\"(L-1) * cdf\"][i])\n  \n #\n  equalized_img = [[0 for _ in range(img.shape[1])] for _ in range(img.shape[0])]\n  for i in range(img.shape[0]):\n    for j in range(img.shape[1]):\n      equalized_img[i][j] = calcs[\"rounding\"][img[i][j]]\n\n  return np.array(equalized_img)\n\nequalized = histogram_equalization(imgg, max_px_val)\n\nmatplot_images(imgg, equalized, titles=[\"Original GrayScale Image\", \"Image after Histogram Equalization\"])\n\nfreq = return_frequency(equalized, max_px_val)\nplt.figure(figsize=(15, 7))\nplt.bar(list(freq.keys()), list(freq.values()))\nplt.show()\n\nfreq = return_frequency(imgg2, 8)\nplt.figure(figsize=(15, 7))\nplt.bar(list(freq.keys()), list(freq.values()))\nplt.show()\n\nequalized = histogram_equalization(imgg2, 8)\nprint(equalized)\n\nmatplot_images(imgg2, equalized, titles=[\"Original GrayScale Image\", \"Image after Histogram Equalization\"])\n\nfreq = return_frequency(equalized, 8)\nplt.figure(figsize=(15, 7))\nplt.bar(list(freq.keys()), list(freq.values()))\nplt.show()",
      "comments": {
        "13": " should be in the order of 2  n",
        "25": " this time, initiate frequency for all pixels as 0 first, last time this only had existing gray levels with their corr. freq.",
        "26": " but this time the non-existing ones are also there with freq. 0",
        "40": " getting nk",
        "43": " the main calculations table, a dictionary with keys as the column labels and values as lists, i.e the columns with initial values",
        "52": " pdf",
        "55": " cdf",
        "61": " (L - 1)  CDF",
        "63": " Rounding",
        "66": " Forming the new image"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/1.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/2.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/3.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/4.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/5.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/6.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/7.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Equalization/8.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#ffffff",
        "6.png": "#111111",
        "7.png": "#ffffff",
        "8.png": "#ffffff"
      },
      "markdown": []
    },
    "Histogram_Stretching": {
      "lang": "py",
      "codeString": "import numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nimg = cv.imread(\"./Low Contrast.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nimgg = imgg[:1080, :1080]\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(12, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ndef show_hist(img):\n  count = {}\n  for x in range(img.shape[0]):\n    for y in range(img.shape[1]):\n      if (p := img[x][y]) in count.keys():\n        count[p] += 1\n      else:\n        count.update({p : 1})\n  plt.figure(figsize=(15, 7))\n  plt.bar(list(count.keys()), list(count.values()))\n  plt.show()\n\nshow_hist(imgg)\nrmax, rmin = max(map(max, imgg)), min(map(min, imgg))\nprint(f\"Maximum Pixel Value in Input: {rmax} Minimum Pixel Value in Input: {rmin}\")\n\ndef histogram_stretching(img, smax, smin, rmax, rmin):\n  stretched_img = [[0 for _ in range(img.shape[1])] for _ in range(img.shape[0])]\n  for x in range(img.shape[0]):\n    for y in range(img.shape[1]):\n      stretched_img[x][y] = int((((smax - smin) / (rmax - rmin)) * (img[x][y] - rmin)) + smin)\n      \n  return np.array(stretched_img)\n\nstretched = histogram_stretching(imgg, 255, 0, rmax, rmin)\nshow_hist(stretched)\nmatplot_images(imgg, stretched, titles=[\"Original GrayScale Image\", \"Image after Histogram Stretching\"])\n\nsmax, smin = max(map(max, stretched)), min(map(min, stretched))\nprint(f\"Minimum Pixel Value in Input: {rmin} Maximum Pixel Value in Input: {rmax}\")\nprint(f\"Minimum Pixel Value in Output: {smin} Maximum Pixel Value in Output: {smax}\")",
      "comments": {},
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Histogram_Stretching/1.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Stretching/2.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Stretching/3.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Stretching/4.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Stretching/5.png",
        "./OP_ss/Sem_VI-IPCV/Histogram_Stretching/6.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#111111",
        "4.png": "#ffffff",
        "5.png": "#ffffff",
        "6.png": "#111111"
      },
      "markdown": []
    },
    "Image_Enhancement-1": {
      "lang": "py",
      "codeString": "import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\n #\nimg_grayed = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n #\nplt.imshow(img_grayed, cmap=\"gray\")\n #\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(15, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n\ndef digital_negative(og_grayscale, show_plot: bool = False):\n  neg = [[255 - y for y in x] for x in og_grayscale]\n  if show_plot:\n    matplot_images(og_grayscale, neg, titles=[\"Original Grayscale Image\", \"Digitally Negative Grayscale Image\"])\n\ndigital_negative(img_grayed, True)\n\ndef thresholder(og_gs, th = 30, show_plot: bool = False):\n  thresholded = [[0 if y < th else 255 for y in x]for x in og_gs]\n  if show_plot:\n    matplot_images(og_gs, thresholded, titles=[\"Original Grayscale Image\", \"Thresholded Grayscale Image\"])\nthresholder(img_grayed, 128, True)\n\ndef gray_level_slicing(og_gs, lb, ub, show_plot: bool = False):\n  gl_sliced_no_bg = [[255 if lb <= y < ub  else 0 for y in x] for x in og_gs]\n  gl_sliced_w_bg = [[255 if lb < y <= ub else y for y in x] for x in og_gs]\n  if show_plot:\n    matplot_images(og_gs, gl_sliced_no_bg, gl_sliced_w_bg, titles=[\"Original Grayscale Image\", \"Gray Level Sliced Image w/o Background\", \"Gray Level Sliced Image w/ Background\"])\ngray_level_slicing(img_grayed, 30, 60, True)",
      "comments": {
        "6": " print(\"Original image data (read using cv2 i.e BGR), 1st row, first 5 pixels\\n\", img[0][:5])",
        "8": " print(\"Grayed image, 1st row, first 5 pixels\\n\", img_grayed[0][:5])",
        "10": " cmap is important otherwise matplotlib is using green hues for the singular values we are getting after converting to grayscale"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-1/1.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-1/2.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-1/3.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-1/4.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#000000",
        "4.png": "#ffffff"
      },
      "markdown": []
    },
    "Image_Enhancement-2": {
      "lang": "py",
      "codeString": "import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nimg_grayed = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nplt.title(\"Original GrayScale image\")\nplt.imshow(img_grayed, cmap=\"gray\")\nplt.show()\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(10, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\nimg2 = cv.imread(\"./Low Contrast.jpg\")\nimg2_grayed = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n\ndef contrast_stretch(img, l, m, n, a, b, show_plots: bool = True):\n  contrast_stretched_img = []\n  v = l * a\n  w = m * (b - a) + v \n  for row in img:\n    new_row = []\n    for r in row:\n      if 0 < r <= a:\n        new_row.append(int(l * r))\n      elif a < r <= b:\n        new_row.append(int(m * (r - a) + v))\n      else:\n        new_row.append(int(n * (r - b) + w))\n    contrast_stretched_img.append(new_row)\n  \n  contrast_stretched_img = np.array(contrast_stretched_img)\n  if show_plots:\n    matplot_images(img, contrast_stretched_img, titles=[f\"Original Grayscale Image (Min: {img.min()}, Max: {img.max()})\", f\"Contrast Stretched Image (Min: {contrast_stretched_img.min()}, Max: {contrast_stretched_img.max()})\"])\n\ncontrast_stretch(img2_grayed, 0.2, 1.5, 0.6, 5, 80)\n\ncontrast_stretch(img2_grayed, 0.2, 0.5, 0.6, 5, 80)\n\ndef drc_log_tf(img, c: int | float = 10, show_plot:bool = True):\n #\n  log_tf_img = c * np.log(img + 1) \n  log_tf_img = np.array(log_tf_img, dtype = np.uint8)\n  if show_plot:\n    matplot_images(img, log_tf_img, titles=[f\"Original Grayscale Image (Min: {img.min()}, Max: {img.max()})\", f\"DyR Compressed Image (Min: {log_tf_img.min()}, Max: {log_tf_img.max()})\"])\n\ndrc_log_tf(img_grayed)\n\ndef power_law_tf(img, \u03b3 = 0.2, c = 1, show_plot:bool = True):\n #\n  pltf_img = np.array([[(c * (r / 255) ** \u03b3) for r in img[i]] for i in range(img.shape[0])])\n\n #\n  if show_plot:\n    matplot_images(img, pltf_img, titles=[f\"Original Grayscale Image (Min: {(img.min())}, Max: {img.max()})\", f\"Power Transformed Image (Min: {round(pltf_img.min(), 4)}, Max: {round(pltf_img.max(), 4)})\"])\n\npower_law_tf(img_grayed)\n\npower_law_tf(img_grayed, 1)\n\npower_law_tf(img_grayed, 10)",
      "comments": {
        "47": " log_tf_img = [[c  np.log(r  1) for r in row] for row in img]      data type error",
        "56": " power_tf_img = np.array([[int(np.floor(c  (r  \u03b3))) % 255  for r in row] for row in img])",
        "59": " power_tf_img = np.array([[int(np.floor(r  \u03b3))  for r in row] for row in img])"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/1.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/2.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/3.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/4.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/5.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/6.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-2/7.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#ffffff",
        "6.png": "#ffffff",
        "7.png": "#ffffff"
      },
      "markdown": []
    },
    "Image_Enhancement-3": {
      "lang": "py",
      "codeString": "import numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nimgg = imgg[:1080, :1080]\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(12, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ngaussian = np.random.normal(10, 20, (imgg.shape[0], imgg.shape[1]))\nnoisy_imgg = np.array(imgg) + gaussian\nplt.title(\"Image + Gaussian Noise\")\nplt.imshow(noisy_imgg, cmap=\"gray\")\nplt.show()\n\ndef convolute_image(img, mask):\n  mask = np.array(mask)\n  conv_img = [[0 for _ in range(img.shape[1])] for _ in range(img.shape[0])]\n  for x in range(1, img.shape[0] - 1):\n    for y in range(1, img.shape[1] - 1):\n      convoluted = img[x - 1: x + 2, y - 1: y + 2] * mask\n      val = sum(map(sum, convoluted))\n      if val > 0:\n        conv_img[x][y] = val if val <= 255 else 255\n      else:\n        conv_img[x][y] = 0\n  return np.array(conv_img)\n\nmask = [[1/9 for _ in range(3)] for _ in range(3)] #\ndenoised = convolute_image(noisy_imgg, mask)\nmatplot_images(imgg, noisy_imgg, denoised, titles=[\"Original Grayscale Image\", \"Noisy Image\", \"De-noised Image\"])\n\nrandom_indices = []\nsp_noise_img = deepcopy(imgg)\nfor i in range(10000):\n  random_indices.append((np.random.randint(0, len(imgg)), np.random.randint(0, len(imgg[0]))))\nfor indices in random_indices:\n  sp_noise_img[indices[0]][indices[1]] = 255\n\nplt.title(\"Salt-Pepper Noise image\")\nplt.imshow(sp_noise_img, cmap=\"gray\")\nplt.show()\n\ndef median_filtering(img):\n  filtered_img = [[0 for _ in range(img.shape[1])] for _ in range(img.shape[0])]\n  for x in range(1, img.shape[0] - 1):\n    for y in range(1, img.shape[1] - 1):\n      filtered_img[x][y] = sorted([r for row in img[x - 1: x + 2, y - 1: y + 2] for r in row])[4] #\n  \n  return filtered_img\n\nfiltered_img = median_filtering(sp_noise_img)\nmatplot_images(imgg, sp_noise_img, filtered_img, titles=[\"Original Grayscale Image\", \"Salt-Pepper Noise Image\", \"Filtered Image\"])",
      "comments": {
        "41": " a 3 x 3 average filter",
        "60": " choosing the center value after sorting the flattened slice"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-3/1.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-3/2.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-3/3.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-3/4.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-3/5.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#ffffff"
      },
      "markdown": []
    },
    "Image_Enhancement-4": {
      "lang": "py",
      "codeString": "import numpy as np\nimport cv2 as cv\nimport matplotlib.pyplot as plt\n\nimg = cv.imread(\"../Sample Images/Oxalis.jpg\")\nimgg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\nimgg = imgg[:1080, :1080]\nplt.title(\"Original GrayScale image\")\nplt.imshow(imgg, cmap=\"gray\")\nplt.show()\n\ndef matplot_images(*imgs, titles):\n  fig = plt.figure(figsize=(12, 7))\n  columns = len(imgs)\n  for i in range(columns):\n    fig.add_subplot(1, columns, i + 1)\n    plt.imshow(imgs[i], cmap=\"gray\")\n    plt.title(titles[i])\n  plt.show()\n\ndef convolute_image(img, mask):\n  mask = np.array(mask)\n  conv_img = [[0 for _ in range(img.shape[1])] for _ in range(img.shape[0])]\n  for x in range(1, img.shape[0] - 1):\n    for y in range(1, img.shape[1] - 1):\n      convoluted = img[x - 1: x + 2, y - 1: y + 2] * mask\n      val = sum(map(sum, convoluted))\n      if val > 0:\n        conv_img[x][y] = val if val <= 255 else 255\n      else:\n        conv_img[x][y] = 0\n  return np.array(conv_img)\n\nmask = [[8 if j == 1 and i == 1 else -1 for j in range(3)] for i in range(3)] #\nprint(mask)\nhpf_img = convolute_image(imgg, mask)\nmatplot_images(imgg, hpf_img, titles=[\"Original Grayscale Image\", \"Image after High-Pass Filter Convolution\"])\n\nA = 1.1\nX = 9 * A - 1\nmask = [[X if j == 1 and i == 1 else -1 for j in range(3)] for i in range(3)] #\nprint(mask)\nhbf_img = convolute_image(imgg, mask)\nmatplot_images(imgg, hbf_img, titles=[\"Original Grayscale Image\", \"Image after High Boost Filter Convolution\"])",
      "comments": {
        "34": " a 3 x 3 high pass filter",
        "41": " a 3 x 3 high boost filter"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-4/1.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-4/2.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-4/3.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-4/4.png",
        "./OP_ss/Sem_VI-IPCV/Image_Enhancement-4/5.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#111111",
        "3.png": "#ffffff",
        "4.png": "#111111",
        "5.png": "#ffffff"
      },
      "markdown": []
    }
  },
  "Sem_VI-RL": {
    "Exploration_Exploitation": {
      "lang": "py",
      "codeString": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef select_action(Q, bounds, \u03b5):\n  lb, ub = bounds[0], bounds[1]\n  n = np.random.random() #\n  return (random.randint(lb, ub), 0) if n < \u03b5 else (np.argmax(Q), 1) #\n\ndef update_arm_estimation(chosen_arm_no, Q, R, \u03b1 = 0.1):\n  CAN = chosen_arm_no\n  Q[CAN] += \u03b1 * (R[CAN] - Q[CAN])\n\ndef bandit_problem(arms_rewards, \u03b5, noofepochs = 100):\n  bounds = (0, len(arms_rewards) - 1) #\n  arms_est_rewards = [0 for _ in range(len(arms_rewards))] #\n  arm_choice_freq = [0 for _ in range(len(arms_rewards))] #\n  history = []\n\n  for _ in range(noofepochs):\n    arm_chosen, TOC = select_action(arms_est_rewards, bounds, \u03b5) #\n    arm_choice_freq[arm_chosen] += 1\n    history.append([\"Explore\" if TOC == 0 else \"Exploit\", f\"A{arm_chosen}\", arms_est_rewards[arm_chosen], arms_rewards[arm_chosen]])\n    update_arm_estimation(arm_chosen, arms_est_rewards, arms_rewards)\n    \n  return history, arm_choice_freq\n\n #\narm_rewards = [0.2, 0.5]\n\nhist, freq = bandit_problem(arm_rewards, 0.5)\nprint(*hist, sep=\"\\n\")\nfor i in range(len(freq)):\n    print(f\"Arm {i} was chosen {freq[i]} times.\")\n\nA0_returns = [x[2] for x in hist if x[1] == \"A0\"]\nA1_returns = [x[2] for x in hist if x[1] == \"A1\"]\n\nplt.figure(figsize=(15, 7))\nplt.title(\"Arm chosen v/s Expected Return (\u03b5 = 0.5)\")\nplt.plot(A0_returns, marker=\".\")\nplt.plot(A1_returns, marker=\".\")\nplt.legend([\"Arm 0\", \"Arm 1\"])\nplt.show()\n\nhist_p1, freq_p1 = bandit_problem(arm_rewards, 0.1)\nfor i in range(len(freq_p1)):\n    print(f\"Arm {i} was chosen {freq_p1[i]} times. (\u03b5 = 0.1)\")\n\nhist_p01, freq_p01 = bandit_problem(arm_rewards, 0.01)\nfor i in range(len(freq_p01)):\n    print(f\"Arm {i} was chosen {freq_p01[i]} times. (\u03b5 = 0.01)\")\n\nA0_returns_p1 = [x[2] for x in hist_p1 if x[1] == \"A0\"]\nA1_returns_p1 = [x[2] for x in hist_p1 if x[1] == \"A1\"]\n\nA0_returns_p01 = [x[2] for x in hist_p01 if x[1] == \"A0\"]\nA1_returns_p01 = [x[2] for x in hist_p01 if x[1] == \"A1\"]\n\nplt.figure(figsize=(15, 7))\nplt.title(\"Effect of \u03b5 on agent's learning\")\nplt.plot(A1_returns, marker=\".\")\nplt.plot(A0_returns_p1, marker=\"o\")\nplt.plot(A0_returns_p01, marker=\".\")\nplt.legend([\"Arm 1 (\u03b5 = 0.5)\", \"Arm 0 (\u03b5 = 0.1)\", \"Arm 0 (\u03b5 = 0.01)\"])\nplt.show()",
      "comments": {
        "7": " random number from 0 - 1 is returned",
        "8": " based on n, either return randomly 0 or 1 or return index of highest Q",
        "15": " indices of array of arms, for 2-arm, 0 and 1 (used in choosing arms)",
        "16": " Qk -> Reward estimation for each arm",
        "17": " K -> Frequency of arm chosen",
        "21": " TOC -> Type of choice, explore(0) or exploit(1)",
        "28": " real arm rewards"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-RL/Exploration_Exploitation/1.png",
        "./OP_ss/Sem_VI-RL/Exploration_Exploitation/2.png",
        "./OP_ss/Sem_VI-RL/Exploration_Exploitation/3.png",
        "./OP_ss/Sem_VI-RL/Exploration_Exploitation/4.png",
        "./OP_ss/Sem_VI-RL/Exploration_Exploitation/5.png"
      ],
      "bgColors": {
        "1.png": "#111111",
        "2.png": "#ffffff",
        "3.png": "#111111",
        "4.png": "#111111",
        "5.png": "#ffffff"
      },
      "markdown": []
    },
    "Gamblers_Problem": {
      "lang": "py",
      "codeString": "import numpy as np\nfrom copy import deepcopy\nimport matplotlib.pyplot as plt\n\ndef value_iteration_gambler_problem(p_h = 0.4, \u0398 = 1e-10, \u03b3 = 1, max_capital = 100):\n  \n  V = [0 for _ in range(max_capital + 1)]\n  \u03c0 = [0 for _ in range(max_capital)]\n\n  rewards = [0 for _ in range(max_capital)]\n  rewards.append(1)\n\n  def vigp_bets(s, V, r):\n #\n #\n    possible_bets = [i for i in range(1, min(s, max_capital - s) + 1)] #\n    \n #\n    BCEPB = [0 for _ in range(len(possible_bets))]\n\n    for pb in possible_bets:\n      BCEPB[pb - 1] = p_h * (r[s + pb] + \u03b3 * V[s + pb]) + (1 - p_h) * (r[s - pb] + \u03b3 * V[s - pb]) #\n    return BCEPB\n\n #\n  while True:\n    \u03b4 = 0\n    for i in range(1, max_capital):\n      v = V[i]\n      V[i] = max(vigp_bets(i, V, rewards))\n      \u03b4 = max(\u03b4, abs(v - V[i]))\n    if \u03b4 < \u0398:\n      break\n\n #\n  for i in range(1, max_capital):\n    A = vigp_bets(i, V, rewards)\n    \u03c0[i] = np.argmax(A) + 1 #\n\n #\n  plt.figure(figsize=(30, 10))\n  x = range(max_capital)\n  y = V[:max_capital]\n  plt.plot(x, y)\n  plt.xticks([i for i in x])\n  plt.xlabel('Capital')\n  plt.ylabel('Value Estimates')\n  plt.title('Final Policy (action stake) vs State (Capital)')\n  plt.show()\n\n  y = \u03c0\n  plt.figure(figsize=(30, 10))\n  plt.bar(x, y, align = 'center', alpha = 0.5)\n  plt.xticks([i for i in x])\n  plt.yticks([i for i in range(max_capital // 2)])\n  plt.xlabel('Capital')\n  plt.ylabel('Final policy (stake)')\n  plt.title(f\"Capital vs Final Policy (ph = {p_h})\")\n  plt.show()\n\nvalue_iteration_gambler_problem()\n\nvalue_iteration_gambler_problem(0.25)\n\nvalue_iteration_gambler_problem(0.55)",
      "comments": {
        "14": " can bet --> <= what he currently holds in hand...",
        "15": " until the bet makes the gambler win more than max_capital because the V array ranges till max_capital",
        "16": " has 1 - s elements for s 1 to max_capital / 2, then has 1 - (100 - s) elements for s max_capital  1 to max_capital",
        "18": " bcfepb -> bellman calculations for each possible bet",
        "22": " -1 because pb always starts from 1",
        "25": " this is using the singular V array,  similar to stochastic approach in DL",
        "35": " policy formation, no need to have a policy for the max_capital (100)",
        "38": " argmax can return 0 so 1 is needed",
        "40": " displaying results"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-RL/Gamblers_Problem/1.png",
        "./OP_ss/Sem_VI-RL/Gamblers_Problem/2.png",
        "./OP_ss/Sem_VI-RL/Gamblers_Problem/3.png",
        "./OP_ss/Sem_VI-RL/Gamblers_Problem/4.png",
        "./OP_ss/Sem_VI-RL/Gamblers_Problem/5.png",
        "./OP_ss/Sem_VI-RL/Gamblers_Problem/6.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#ffffff",
        "6.png": "#ffffff"
      },
      "markdown": []
    },
    "GridWorld": {
      "lang": "py",
      "codeString": "import numpy as np\nfrom copy import deepcopy\n\ndef all_possible_moves(V, i, j, size = 4):\n  if i == 0 and j == size - 1:\n    return ((V[i][j], \"\u2191\"), (V[i][j], \"\u2192\"), (V[i + 1][j], \"\u2193\"), (V[i][j - 1], \"\u2190\"))\n  \n  elif i == size - 1 and j == 0:\n    return ((V[i][j], \"\u2193\"), (V[i][j], \"\u2190\"), (V[i - 1][j], \"\u2191\"), (V[i][j + 1], \"\u2192\"))\n  \n  elif j == 0:\n    return ((V[i][j], \"\u2190\"),( V[i][j + 1], \"\u2192\"), (V[i - 1][j], \"\u2191\"), (V[i + 1][j], \"\u2193\"))\n  \n  elif j == size - 1:\n    return ((V[i][j], \"\u2192\"), (V[i][j - 1], \"\u2190\"), (V[i - 1][j], \"\u2191\"), (V[i + 1][j], \"\u2193\"))\n  \n  elif i == 0:\n    return ((V[i][j], \"\u2191\"), (V[i][j - 1], \"\u2190\"), (V[i][j + 1], \"\u2192\"), (V[i + 1][j], \"\u2193\"))\n  \n  elif i == size - 1:\n    return ((V[i][j], \"\u2193\"), (V[i][j - 1], \"\u2190\"), (V[i][j + 1], \"\u2192\"), (V[i - 1][j], \"\u2191\"))\n  \n  else:\n    return ((V[i - 1][j], \"\u2191\"), (V[i + 1][j], \"\u2193\"), (V[i][j + 1], \"\u2192\"), (V[i][j - 1], \"\u2190\"))\n\ndef policy_iteration_grid_world_problem(size = 4, \u0398 = 0.0001, r = -1, \u0393 = 1):\n  V = [[0 for _ in range(size)] for _ in range(size)]\n  \u03c0 = [[\"\u2191\u2192\u2193\u2190\" for _ in range(size)] for _ in range(size)]\n  \u03c0[0][0], \u03c0[size - 1][size - 1] = \"\", \"\"\n  epoch = 1\n\n #\n  while True:\n    \u03b4 = 99999\n #\n    eval_iter = 1\n    while \u03b4 > \u0398:\n      \u03b4 = 0\n      V_dash = deepcopy(V)\n      for i in range(size):\n        for j in range(size):\n          if (i, j) not in [(0, 0), (size - 1, size - 1)]:\n            v = V[i][j]\n            moves = [i[0] for i in all_possible_moves(V, i, j, size)]\n            possibility = 1 / len(moves)\n            new_v = sum([possibility * (r + \u0393 * x) for x in moves])\n            V_dash[i][j] = new_v\n            \u03b4 = max(\u03b4, abs(v - V_dash[i][j]))\n      V = deepcopy(V_dash)\n #\n      eval_iter += 1\n\n #\n    policy_stable = True\n    for i in range(size):\n      for j in range(size):\n        if (i, j) not in [(0, 0), (size - 1, size - 1)]:\n          action = \u03c0[i][j]\n          q_sa = list(all_possible_moves(V, i, j, size))\n          q_sa.sort(key=lambda x: x[0], reverse=True)\n          \u03c0[i][j] = q_sa[0][1]\n          if action != \u03c0[i][j]:\n            policy_stable = False\n  \n    if policy_stable:\n      break\n\n    epoch += 1\n    \n  print(\"Final (Optimum) Grid Values:\", *V, sep=\"\\n\")\n  print(\"\\nFinal (Optimal) Policy\", *\u03c0, sep=\"\\n\")\n\npolicy_iteration_grid_world_problem()",
      "comments": {
        "32": " Policy Iteration",
        "35": " Policy Evaluation",
        "50": " print(f\"Grid Values (iteration {eval_iter}):\", V, sep=\"\\n\", end='\\n\\n')",
        "53": " Policy Improvement"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-RL/GridWorld/1.png"
      ],
      "bgColors": {
        "1.png": "#111111"
      },
      "markdown": []
    },
    "UCB_Algorithm": {
      "lang": "py",
      "codeString": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\n\ndef select_action(Q, c, ps, t): #\n  UCB_vals = [Q[i] + c * ((np.log(t) / ps[i]) ** 0.5) for i in range(len(Q))]  \n  At = np.argmax(UCB_vals)        \n  return At, UCB_vals       \n\ndef update_arm_estimation(chosen_arm_no, Q, R, \u03b1 = 0.1):\n  CAN = chosen_arm_no\n  Q[CAN] += \u03b1 * (R[CAN] - Q[CAN])\n\ndef pretty_freq_printer(freq):\n  table = PrettyTable([\"Arm\", *(i for i in range(1, len(freq) + 1))])\n  freq.insert(0, \"\")\n  table.add_row(freq)\n  print(\"Chosen Arm frequencies\".center(50, '-'), table, sep=\"\\n\")\n  freq.pop(0)\n\ndef full_history_separator(hist, freq):\n  sep_hist = [[0 for _ in range(len(hist))] for _ in freq]\n  \n  for rec_i in range(len(hist)):\n    updated_arm = hist[rec_i][0]\n    sep_hist[updated_arm][rec_i] = hist[rec_i][1]\n    for hist_ix in range(len(sep_hist)):\n      if hist_ix != updated_arm:\n        sep_hist[hist_ix][rec_i] = sep_hist[hist_ix][rec_i - 1]\n  for x in sep_hist:\n    x.insert(0, 0)\n  \n  return sep_hist \n\ndef bandit_problem_2(arms_rewards, noofepochs, c = 1):\n  Q, R = [0 for _ in arms_rewards], arms_rewards\n  cfa = [1 for _ in arms_rewards] #\n  full_hist, UCB_hist = [], []\n\n  for i in range(noofepochs):\n    arm_chosen, UCB_vals = select_action(Q, c, cfa, i + 1)\n    UCB_hist.append(UCB_vals)\n    cfa[arm_chosen] += 1\n    update_arm_estimation(arm_chosen, Q, R)\n    full_hist.append([arm_chosen, Q[arm_chosen], R[arm_chosen]])\n\n  return full_hist, [i - 1 for i in cfa], UCB_hist #\n\n #\narms_rewards, noofepochs = [0.7, 0.3, 0.05, 0.69], 100\nfull_hist, freq, ucb_hist = bandit_problem_2(arms_rewards, 100, 1)\nprint(f\"Expected Return: {sum([x * y for x, y in zip(arms_rewards, freq)])}\", end=\"\\n\\n\")\n\npretty_freq_printer(freq)\n\nsep_hist = full_history_separator(full_hist, freq)\n\nplt.figure(figsize=(15, 7))\nplt.title(\"Expected Reward (Q)/arm v/s Epochs\")\n\nfor x in sep_hist:\n  plt.plot(x)\n\nplt.legend([f\"Arm {i + 1}\" for i in range(len(sep_hist))], loc=\"best\")\nplt.show()\n\nsep_ucb_hist = [list() for _ in ucb_hist[0]]\nfor x in ucb_hist:\n  sep_ucb_hist[0].append(x[0])\n  sep_ucb_hist[1].append(x[1])\n  sep_ucb_hist[2].append(x[2])\n  sep_ucb_hist[3].append(x[3])\n\nrange_ = [i for i in range(noofepochs)]\nplt.figure(figsize=(15, 7))\nplt.title(\"UCB values/arm v/s Epochs\")\n\nfor x in sep_ucb_hist:\n  plt.plot(range_, x)\n\nplt.legend([f\"Arm {i + 1}\" for i in range(len(sep_ucb_hist))], loc=\"best\")\nplt.show()",
      "comments": {
        "6": " t -> current iteration, timestep; ps -> prior_selections",
        "38": " chosen frequency of arms, starting with 1 to avoid ZDE",
        "48": " while returning, adjusting the frequencies by 1",
        "50": " 4 arms bandit problem"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VI-RL/UCB_Algorithm/1.png",
        "./OP_ss/Sem_VI-RL/UCB_Algorithm/2.png",
        "./OP_ss/Sem_VI-RL/UCB_Algorithm/3.png"
      ],
      "bgColors": {
        "1.png": "#111111",
        "2.png": "#ffffff",
        "3.png": "#ffffff"
      },
      "markdown": []
    }
  },
  "Sem_VII-ML4": {
    "Apriori_Algorithm": {
      "lang": "py",
      "codeString": "from itertools import combinations, permutations\nfrom prettytable import PrettyTable\nimport math\n\ndef preprocess_csv_lines(csv_lines):\n  data = []\n  for line in csv_lines:\n    line = line.replace(\"\\n\", \"\")\n    items = line.split(\",\")\n    data.append([f\"{item}\" for item in items])\n  return data\n\ndef valid_support_items(data, unique_single_items, item_len = 1, min_support = 2):\n  if item_len == 1:\n    singletons_freq = {}\n    for item in unique_single_items:\n      if (valid_count := sum([1 for basket in data if item in basket])) >= min_support:\n        singletons_freq[item] = valid_count\n    return list(singletons_freq.keys()), singletons_freq  \n  else:\n    unique_itemsets = list(combinations(unique_single_items, item_len))\n    itemsets_freq = {}\n    for itemset in unique_itemsets:\n      if (valid_count := sum([1 for basket in data if all([item in basket for item in itemset])])) >= min_support:\n        itemsets_freq[f\"{itemset}\"] = (valid_count, itemset)\n\n    #\n    return list(set([item for itemset in itemsets_freq.values() for item in itemset[1]])), itemsets_freq\n  \ndef apriori_algorithm(sample_data, min_support, min_confidence):\n  #\n  data = sample_data\n  noofbaskets = len(data)\n  min_support = math.ceil((min_support * len(data)) / 100)\n  min_confidence = round(min_confidence / 100, 4)\n  print(f\"\\033[1m\\033[38;5;227mMinimum Support: {min_support}\\nMinimum Confidence: {min_confidence}\\033[0m\")\n  \n  valid_singleton_items = []\n  for basket in data:\n    for item in basket:\n      if item not in valid_singleton_items:\n        valid_singleton_items.append(item)\n\n  #\n  i = 1\n  support_records = {}\n  while True:\n    valid_singleton_items, supports = valid_support_items(data, valid_singleton_items, noofbaskets, i, min_support)\n    support_records.update({i: supports})\n    i += 1\n    if len(valid_singleton_items) <= i:\n      break\n\n  #\n  all_association_rules = []\n  for i in range(len(valid_singleton_items)):\n    all_association_rules.append((valid_singleton_items[i], tuple([j for j in valid_singleton_items if j != valid_singleton_items[i]])))\n  all_association_rules.extend([i[::-1] for i in all_association_rules])\n\n  confidence_numerator = list(support_records[len(valid_singleton_items)].values())[0][0]\n  all_valid_associations = []\n  print(f\"\\n\\033[1m\\033[38;5;225mAll prospective association rules w/ confidence values:\\033[0m\")\n  for assc_rule in all_association_rules:\n    if type(assc_rule[0]) == str:\n      confidence = confidence_numerator / support_records[1][assc_rule[0]]\n    else:\n      tuple_ = assc_rule[0]\n      tuple_perms = permutations(tuple_, len(tuple_))\n      for tuple__ in tuple_perms:\n        if str(tuple__) in support_records[len(assc_rule)].keys():\n          denominator = support_records[len(assc_rule)][f\"{tuple__}\"][0]\n      confidence = confidence_numerator / denominator\n    print(assc_rule, confidence)\n    if confidence >= min_confidence:\n      all_valid_associations.append((assc_rule, confidence))\n\n  conf_table = PrettyTable(['A', 'B', 'Confidence'], title=\"Valid Confidence Table\")\n  for rule in all_valid_associations:\n    conf_table.add_row([rule[0][0], rule[0][1], rule[1]])\n  print(\"\\n\\033[1m\\033[38;5;221mBest association\\033[0m\")\n\n  print(conf_table)\nsample_data_3 = [[\"Coke\", \"Fries\", \"Nuggets\"], [\"Burger\", \"Coke\", \"Fries\"], [\"Coke\", \"Fries\", \"Nuggets\"], [\"Burger\", \"Fries\", \"Nuggets\"], [\"Burger\", \"Coke\", \"Fries\", \"Nuggets\"]]\n\napriori_algorithm(sample_data_3, 60, 80)",
      "comments": {
        "27": "    # since in the dict the tuple directly are the keys\n",
        "31": "  # Pre-requisites\n",
        "44": "  # Support part\n",
        "54": "  # Confidences part\n"
      },
      "outputSrcs": [
        "OP_ss/Sem_VII-ML4/Apriori_Algorithm/1.png"
      ],
      "bgColors": {
        "1.png": "#181616"
      }
    },
    "Apriori_Association_Rules": {
      "lang": "py",
      "codeString": "from itertools import combinations\nfrom prettytable import PrettyTable\n\ndef preprocess_csv_lines(csv_lines):\n  data = []\n  for line in csv_lines:\n    line = line.replace(\"\\n\", \"\")\n    items = line.split(\",\")\n    data.append([f\"{item}\" for item in items])\n  return data\n\ndef association_rules(data):\n  noofbaskets = len(data)\n  unique = []\n\n  #\n  for basket in data:\n    for item in basket:\n      if item not in unique:\n        unique.append(item)\n  item_count = {item: sum([1 for basket in data if item in basket]) for item in unique}\n    \n  #\n  supports = {item: [f\"{item_count[item]} / {noofbaskets}\", round(item_count[item] / noofbaskets, 3)] for item in unique}\n  supports = {k: v for k, v in sorted(supports.items(), key = lambda x: x[1][1], reverse=True)}  \n  supports_table = PrettyTable(['Item', 'Support'], title=\"Supports Table\")\n  supports_table.add_rows(list(supports.items()))\n  print(supports_table)\n\n  #\n  dual_item_combos = list(combinations(unique, 2))\n  combo_counts = {f\"{combo}\": sum([1 for basket in data if combo[0] in basket and combo[1] in basket]) for combo in dual_item_combos}\n  confidences = {}\n  for combo in dual_item_combos:\n    confidences.update({f\"{combo}\": [f\"{combo_counts[f'{combo}']} / {item_count[combo[0]]}\", round(combo_counts[f\"{combo}\"] / item_count[combo[0]], 3)]})     \n    #\n  \n  confidences = {k: v for k, v in sorted(list(confidences.items()), key = lambda x: x[1][1], reverse=True)}\n\n  confidences_table = PrettyTable(['Item Combo', 'Confidence'], title=\"Confidences Table\")\n  confidences_table.add_rows(list(confidences.items()))\n  print(confidences_table)\n\n  #\n  lifts = {}\n  for combo in dual_item_combos:\n    lifts.update({f\"{combo}\": [f\"{combo_counts[f'{combo}']} / {item_count[combo[0]] * item_count[combo[1]] / noofbaskets}\", combo_counts[f'{combo}'] / (item_count[combo[0]] * item_count[combo[1]] / noofbaskets)]}) #\n\n  lifts = {k: v for k, v in sorted(list(lifts.items()), key = lambda x: x[1][1], reverse=True)}\n\n  lifts_table = PrettyTable(['Item Combo', 'Lifts'], title=\"Lifts Table\")\n  lifts_table.add_rows(list(lifts.items()))\n  print(lifts_table)\n\n  print(f\"Item with the most Support (most popular): \\033[38;5;227m{list(supports.keys())[0]}\\033[0m\")\n  print(f\"Dual Combo with the most confidence score (most popular paired items): \\033[38;5;227m{list(confidences.keys())[0]}\\033[0m\")\n  print(f\"Profitable pairing (increased chance of buying when paired): \\033[38;5;227m{list(lifts.keys())[0]}\\033[0m\")\n\n\nsample_data = [[\"T-shirt\", \"Trousers\", \"Belt\"], [\"T-shirt\", \"Jacket\"], [\"Jacket\", \"Gloves\"], [\"T-shirt\", \"Trousers\", \"Jacket\"],\n              [\"T-shirt\", \"Trousers\", \"Sneakers\", \"Jacket\", \"Belt\"], [\"Trousers\", \"Sneakers\", \"Belt\"], [\"Trousers\", \"Belt\", \"Sneakers\"]]\nsample_data_2 = [[\"Apple\", \"Beer\", \"Rice\", \"Chicken\"], [\"Apple\", \"Beer\", \"Rice\"], [\"Apple\", \"Beer\"], [\"Apple\", \"Pear\"], [\"Milk\", \"Beer\", \"Rice\", \"Chicken\"], [\"Milk\", \"Beer\", \"Rice\"], [\"Milk\", \"Beer\"], [\"Milk\", \"Pear\"]]\n\nassociation_rules(sample_data)",
      "comments": {
        "16": "  # getting the unique items from the baskets\n",
        "23": "  # Support\n",
        "30": "  # Confidences\n",
        "36": "    # confidence(a->b) = support(a, b) / support(a) OR count(a,b) / count(a) (cause support(a, b) = count(a, b)/noofbaskets and support(a) = count(a)/noofbaskets, noofbaskets are cancelled)\n",
        "44": "  #Lifts\n",
        "47": " # denominator would have noofbaskets squared hence have to divide\n"
      },
      "outputSrcs": [
        "OP_ss/Sem_VII-ML4/Apriori_Association_Rules/1.png",
        "OP_ss/Sem_VII-ML4/Apriori_Association_Rules/2.png"
      ],
      "bgColors": {
        "1.png": "#181616",
        "2.png": "#181616"
      }
    },
    "Blooms_Filter": {
      "lang": "py",
      "codeString": "def blooms_filter():\n  insert_elements = [int(x) for x in input(\"Enter numbers to be inserted (space separated): \").split()]\n  \n  hash_functions = input(\"Enter hash functions: (comma separated, using 'x' as the variable, can use () brackets): \")\n  hash_functions = [x.strip() for x in hash_functions.split(\",\")]\n  \n  bloom_filter_size = max([int(x.split('%')[1].strip()) for x in hash_functions])\n  bloom_filter = [0 for _ in range(bloom_filter_size)]\n\n  for num in insert_elements:\n    hash_values = [eval(hash_func, {'x': num}) for hash_func in hash_functions]\n    for val in hash_values:\n      bloom_filter[val] = 1\n  \n  print(\"Current bloom filter: \", bloom_filter)\n\n  check_elements = [int(x) for x in input(\"Enter numbers to be checked (space separated): \").split()]\n  for num in check_elements:\n    hash_values = [eval(hash_func, {'x': num}) for hash_func in hash_functions]\n    for val in hash_values:\n      if bloom_filter[val] == 1:\n        if num in insert_elements:\n          print(f\"{num} is in the stream and is a true positive\")\n        else:\n          print(f\"{num} is NOT in the stream and is a false positive\")\n        break\n    else: \n          print(f\"{num} is NOT in the stream and is true negative\")\n\nblooms_filter()",
      "comments": {},
      "outputSrcs": [
        "OP_ss/Sem_VII-ML4/Blooms_Filter/1.png"
      ],
      "bgColors": {
        "1.png": "#181616"
      }
    },
    "Flajolet_Martin_Algorithm": {
      "lang": "py",
      "codeString": "import numpy as np\nfrom prettytable import PrettyTable\n\n#\ndef to_binary(num: int) -> list[int]:\n  bin_repr = []\n  if(num == 0):\n    return \"\".join(['0'])\n  \n  def mechanism(n):\n    if(n >= 1):\n      mechanism(n // 2)\n      bin_repr.append(str(n % 2))  \n  mechanism(num)\n\n  return \"\".join(bin_repr)\n\ndef flajolet_martin_algorithm(data: list[int], hash_function: str) -> tuple[int, dict]:\n  fm_table = {\"x\": data, \"h(x)\": [], \"Binary\": [], \"r\": []}\n  fm_p_table = PrettyTable([\"x\", \"h(x)\", \"Binary\", \"r\"], title=\"Flajolet-Martin Table\")\n\n  for i in range(len(fm_table[\"x\"])):\n    fm_table[\"h(x)\"].append(eval(hash_function, {\"x\": fm_table[\"x\"][i]}))\n    fm_table[\"Binary\"].append(to_binary(fm_table[\"h(x)\"][i]))\n    try:\n      fm_table[\"r\"].append(fm_table[\"Binary\"][i][::-1].index('1'))        #\n    except ValueError:\n      fm_table[\"r\"].append(0)        #\n\n    fm_p_table.add_row([fm_table[\"x\"][i], fm_table[\"h(x)\"][i], fm_table[\"Binary\"][i], fm_table[\"r\"][i]])\n  R = max(fm_table[\"r\"])\n  return 2 ** R, fm_p_table\n\n\ntest_stream = np.random.randint(0, 25, size=200).tolist()\nhash_function = input(\"Enter a single hash function: (comma separated, using 'x' as the variable, can use () brackets): \")\nresults = flajolet_martin_algorithm(test_stream, hash_function)\nprint(results[1])\nprint(f\"\\033[1m\\033[38;5;224mNumber of Unique elements by Flajolet Martin's Algorithm: {results[0]}\\033[0m\")\nprint(f\"\\033[1m\\033[38;5;227mActual unique elements count: {len(set(test_stream))}\\033[0m\")\n",
      "comments": {
        "4": "# takes in a decimal number and gives out a string of binary representation of that number, using only required bits\n",
        "26": "        # index of the first '1' in the reverse binary representation is the number of zeroes before it, i.e the number of trailing zeroes in the original binary representation\n",
        "28": "        # there isn't any '1', i.e 0's binary representation and r = 0 for 0\n"
      },
      "outputSrcs": [
        "OP_ss/Sem_VII-ML4/Flajolet_Martin_Algorithm/1.png",
        "OP_ss/Sem_VII-ML4/Flajolet_Martin_Algorithm/11.png",
        "OP_ss/Sem_VII-ML4/Flajolet_Martin_Algorithm/2.png"
      ],
      "bgColors": {
        "1.png": "#181616",
        "11.png": "#181616",
        "2.png": "#181616"
      }
    },
    "Map_Reduce": {
      "lang": "py",
      "codeString": "import sys\nimport re\nfrom prettytable import PrettyTable\n\ndef mapper(node):\n  node_key_val = {}\n  for word in node:\n    if word in node_key_val.keys():\n      node_key_val[word] += 1\n    else:\n      node_key_val.update({word: 1})\n  return node_key_val\n\ndef shuffler(mapper_result):\n  shuffler_result = {}\n  \n  for dict_ in mapper_result:\n    for k, v in dict_.items():\n      if k in shuffler_result.keys():\n        shuffler_result[k].append(v)\n      else:\n        shuffler_result.update({k: [v]})\n  \n  return shuffler_result\n\ndef reducer(shuffler_result):\n  final_result = {}\n\n  for k, v in shuffler_result.items():\n    final_result.update({k: sum(v)})\n\n  return final_result\n\ndef map_reduce():\n  mapper_results = []\n  shuffler_result = []\n  final_result = []\n\n  if(len(sys.argv) < 1):\n    return \"File not found...\"\n\n  for file_name in sys.argv[1:]:\n    with open(f\"./{file_name}\") as f:\n      text = f.read()\n    f.close()\n\n    text = re.sub(r'[^\\w\\s]', '', text)\n    words = text.split(\" \")\n    length = len(words)\n\n    print(f\"\\n\\033[1m\\033[38;5;135mNodes formed from the text of {file_name}\\033[0m\\n\")\n    nodes = [words[i: i + length // 3] for i in range(0, length-length // 3 + 1, length // 3)]\n    print(*nodes, sep=\"\\n\\n\", end=\"\\n\\n\")\n\n    for node in nodes:\n      mapper_results.append(mapper(node))\n      \n  shuffler_result = shuffler(mapper_results)\n  final_result = reducer(shuffler_result)\n\n  for i, mr in enumerate(mapper_results):\n    mapper_table = PrettyTable([\"Word\", \"Count\"], title=f\"Mapper {i + 1} Results\")\n    mapper_table.add_rows(mr.items())\n    print(mapper_table)\n\n  shuffler_table = PrettyTable([\"Word\", \"Counts\"], title=\"Shuffler Results\")\n  shuffler_table.add_rows(shuffler_result.items())\n  final_table = PrettyTable([\"Word\", \"Count\"], title=\"Final Results\")\n  final_table.add_rows(final_result.items())\n\n  print(\"\\n\")\n  print(shuffler_table)\n  print(\"\\n\")\n  print(final_table)\n\nmap_reduce()",
      "comments": {},
      "outputSrcs": [
        "OP_ss/Sem_VII-ML4/Map_Reduce/1.png",
        "OP_ss/Sem_VII-ML4/Map_Reduce/2.png",
        "OP_ss/Sem_VII-ML4/Map_Reduce/3.png",
        "OP_ss/Sem_VII-ML4/Map_Reduce/4.png",
        "OP_ss/Sem_VII-ML4/Map_Reduce/5.png"
      ],
      "bgColors": {
        "1.png": "#181616",
        "2.png": "#181616",
        "3.png": "#181616",
        "4.png": "#181616",
        "5.png": "#181616"
      }
    },
    "Map_Reduce_Mat_Multiplication": {
      "lang": "py",
      "codeString": "import re\nfrom prettytable import PrettyTable\n\ndef mapper_result_printer(mapper_result):\n  table = PrettyTable(['i/k', 'value'])\n  for k, v in mapper_result.items():\n    for val in v:\n      table.add_row([k, val])\n  return table\n\ndef map_reduce_matmul(matA, matB):\n  def input_mat_validation(matrix):\n    try:\n      if len(set([len(row) for row in matrix])) != 1:\n        print(f\"{matrix} is an \\033[38;5;196mInvalid Matrix! -> Gaps in column data\\033[0m\")\n        return\n    except TypeError:\n        print(f\"{matrix} is an \\033[38;5;196mInvalid Matrix! -> Rows should be 1D array\\033[0m\")\n        return\n    \n  input_mat_validation(matA)\n  input_mat_validation(matB)\n\n  if len(matA[0]) != len(matB):\n    print(f\"{matA} x {matB} \\033[38;5;196mInvalid! -> no. of columns of 1st matrix must be equal to no. of rows of the 2nd matrix.\\033[0m\")\n    return\n  \n  resultant_size = (len(matA), len(matB[0]))\n  \n  def mapper(matrix, matrix_label, matrix_psn):\n    mapper_result = {}\n    #\n    if matrix_psn == 1:\n      for i in range(len(matrix)):\n        for j in range(len(matrix[0])):\n          if i not in mapper_result.keys():\n            mapper_result.update({i: [(matrix_label, j, matrix[i][j])]})\n          else:\n            mapper_result[i].append((matrix_label, j, matrix[i][j]))\n    else:\n      #\n      for k in range(len(matrix[0])):\n        for j in range(len(matrix)):\n          if k not in mapper_result.keys():\n            mapper_result.update({k: [(matrix_label, j, matrix[j][k])]})\n          else:\n            #\n            mapper_result[k].append((matrix_label, j, matrix[j][k]))\n\n    return mapper_result\n  \n  mapper_result_A = mapper(matA, 'A', 1)\n  mapper_result_B = mapper(matB, 'B', 2)\n  \n  print(\"\\nMapper Result for Matrix A:\")\n  print(mapper_result_printer(mapper_result_A))\n\n  print(\"\\nMapper Result for Matrix B:\")\n  print(mapper_result_printer(mapper_result_B))\n\n  def shuffler(map_res_1, map_res_2):\n    shuffler_result = {}\n    for i in range(len(map_res_1.keys())):\n      for j in range(len(map_res_2.keys())):\n        shuffler_result.update({f\"({i}, {j})\": [(x, y) for x, y in zip(map_res_1[i], map_res_2[j])]})\n\n    return shuffler_result\n  \n  shuffler_result = shuffler(mapper_result_A, mapper_result_B)\n  \n  table = PrettyTable(['i/k', 'values'])\n  for k, v in shuffler_result.items():\n    tuple_1 = str(v[0][0]) + str(v[0][1]) + '\\n'\n    tuple_2 = str(v[1][0]) + str(v[1][1])\n    table.add_row([k, tuple_1 + tuple_2])\n\n  print(\"\\nShuffler Result:\",table,sep=\"\\n\")\n\n  def reducer(shuffler_res):\n    resultant_matrix = [[0 for _ in range(resultant_size[1])] for _ in range(resultant_size[0])]\n    index_pattern = r\"\\((\\d+), (\\d+)\\)\"\n    for indices, grouped in shuffler_res.items():\n      sum = 0\n      for tuple_group in grouped:\n        sum += tuple_group[0][-1] * tuple_group[1][-1]\n\n      match = re.search(index_pattern, indices)\n      i, j = int(match.group(1)), int(match.group(2))\n      resultant_matrix[i][j] = sum\n\n    return resultant_matrix\n    \n  final_answer = reducer(shuffler_result)\n  print(\"\\nFinal Matrix Result:\")\n  print(*final_answer, sep=\"\\n\")\n\nmatA = [[1, 2], [2, 1], [3, 4]]\nmatB = [[1, 2], [1, 3]]\nmap_reduce_matmul(matA, matB)",
      "comments": {
        "32": "    # going row-wise\n",
        "41": "      # going column-wise\n",
        "47": "            # mapper_result is a dict and keys should be unique... to match with how we do it manually, I'm appending and then using a custom printing function for clear understanding\n"
      },
      "outputSrcs": [
        "OP_ss/Sem_VII-ML4/Map_Reduce_Mat_Multiplication/1.png",
        "OP_ss/Sem_VII-ML4/Map_Reduce_Mat_Multiplication/2.png"
      ],
      "bgColors": {
        "1.png": "#181616",
        "2.png": "#181616"
      }
    }
  },
  "Sem_VIII-SNA": {
    "Barabasi-Albert PAM": {
      "lang": "py",
      "codeString": "import networkx as nx\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nfrom random import randint\n\ndef network_viz(G, pos, with_labels=True):\n  node_sizes = [1000 for _ in G.nodes]\n  node_colors = {node: \"#{:06x}\".format(randint(0, 0xFFFFFF)) for node in G.nodes}\n  \n  nx.draw(G, pos, node_color=list(node_colors.values()), node_size=node_sizes, with_labels=with_labels)\n\ndef nx_measures(G):\n  diameter = nx.diameter(G)\n  avgcc = round(nx.average_clustering(G), 4)\n  apl = round(nx.average_shortest_path_length(G), 4)\n\n  table = PrettyTable(['Measurement', 'Value'], title=\"Network Measures\")\n  table.add_row(['Diameter', diameter])\n  table.add_row(['Average Clustering Coefficient', avgcc])\n  table.add_row(['Average Path Length', apl])\n\n  return table, [diameter, avgcc, apl]\n\ndef deg_dist(G, n, m):\n  degree_count = nx.degree_histogram(G)\n  degrees, counts = zip(*enumerate(degree_count))\n\n  plt.bar(degrees, counts, width=1.0, color='#4FBACC')\n  plt.title(f\"Degree Distribution of N={n}; m={m}\")\n  plt.xlabel(\"Degree\")\n  plt.ylabel(\"Frequency\")\n\ndef ba_graph_maker(N=10, m=1, show_table = False):\n  G = nx.barabasi_albert_graph(N, m)\n  pos = nx.circular_layout(G)\n\n  table, measures = nx_measures(G)\n  if show_table:\n    print(table, end=\"\\n\\n\")\n\n  return G, pos, table, f\"N={N}; m={m}\", measures\n\nmeasures = []\nmeasure_tables = []\ntitles = []\ngraphs = []\nNms = [[10, 1], [10, 2], [20, 1], [20, 2]]\ncols = len(Nms)\n\nplt.subplots(2, cols // 2, figsize=(12, 12))\n\nfor i, (n, m) in enumerate(Nms):\n  graph, pos, table, title, measure = ba_graph_maker(n, m)\n  measures.append(measure)\n  titles.append(title)\n  measure_tables.append(table)\n  graphs.append(graph)\n  \n  plt.subplot(2, cols // 2, i + 1)\n  network_viz(graph, pos)\n  plt.title(title)\n\nplt.suptitle(\"BA Preferential Attachment Model Networks w/ varying params.\")\nplt.show()\n\nplt.subplots(2, cols // 2, figsize=(12, 12))\nfor i, graph in enumerate(graphs):\n  plt.subplot(2, cols // 2, i + 1)\n  deg_dist(graph, Nms[i][0], Nms[i][1])\nplt.show()\n\n\nmega_table = PrettyTable(['Graph', 'All Measures'])\nfor i in range(len(measure_tables)):\n  mega_table.add_row([titles[i], measure_tables[i]])\n\nprint(mega_table)\n",
      "comments": {},
      "outputSrcs": [
        "./OP_ss/Sem_VIII-SNA/Barabasi-Albert PAM/1.png",
        "./OP_ss/Sem_VIII-SNA/Barabasi-Albert PAM/2.png",
        "./OP_ss/Sem_VIII-SNA/Barabasi-Albert PAM/3.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#111111"
      },
      "markdown": [
        "With an **increase** in **m** i.e the number of edges to be formed per node, we see an decrease in Diameter and Average Path Length all the while Average Clustering Coefficient increases.",
        "With **increase** in **N**, we can see an increase in Diameter, ACC and APL, understandably due to more nodes to be covered when m is kept constant."
      ]
    },
    "Clique_Percolation": {
      "lang": "py",
      "codeString": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom random import randint\nimport networkx as nx\nfrom prettytable import PrettyTable\nfrom itertools import combinations\n\ndef network_viz(G, title, base_size=750, font_size=18, layout='c'):\n  labels = {i: i for i in G.nodes()}\n  if layout == 'c':\n    pos = nx.circular_layout(G)\n  else:\n    pos = nx.planar_layout(G)\n\n  node_sizes = [base_size * (10 / len(G.nodes) * 1.5) for _ in G.nodes]\n  node_colors = [f\"#{randint(120, 255):02X}{randint(120, 255):02X}{randint(120, 255):02X}\" for _ in G.nodes]\n  \n  plt.figure(figsize=(10, 8))\n  plt.title(title)\n  nx.draw(G, pos, node_color=node_colors, node_size=node_sizes, width=2, edge_color='#171717')\n  nx.draw_networkx_labels(G, pos, labels, font_size=font_size, font_color=\"black\")\n  \n  plt.show()\n\ninput_ = {\n      1: [2, 3, 4],\n      2: [1, 3, 5, 6],\n      3: [1, 2, 4],\n      4: [1, 3],\n      5: [2, 6, 7, 8, 9],\n      6: [2, 5, 7, 8],\n      7: [5, 6, 8, 9, 10],\n      8: [5, 6, 7],\n      9: [5, 7],\n      10: [7]\n    }\n\nG = nx.from_dict_of_lists(input_, create_using=nx.Graph)\nnetwork_viz(G, \"Input Graph\")\n\ndef clique_percolation_cd(adj_li, k = 3):\n  \"\"\" \n    Assuming or taking \"k\" here as the number of nodes that are involved in a clique\n    for e.g, k=3 will start with detecting 1-cliques involving 3 nodes and then merge these cliques to form communities (k-cliques, where k is the maximal distance between nodes involved in the clique)\n  \"\"\"\n\n  one_k_cliques = [] #\n\n #\n  combos = list(combinations(adj_li.keys(), k))\n\n  for combo in combos:\n #\n    noofvalidedges = 0\n    candidate_edges = combinations(combo, 2)\n    for ce in candidate_edges:\n      if ce[0] in adj_li[ce[1]] and ce[1] in adj_li[ce[0]]:\n        noofvalidedges += 1\n    \n #\n    if noofvalidedges == k * (k - 1) // 2:\n      one_k_cliques.append(combo)\n\n #\n  clique_combos = list(combinations(one_k_cliques, 2))\n  communities = {}\n\n  for combo in clique_combos:\n    if len(set(combo[0]).intersection(combo[1])) == k - 1:\n      if combo[0] not in communities:\n        communities[combo[0]] = [combo[1]]\n      else:\n        communities[combo[0]].append(combo[1])\n  network_viz(nx.from_dict_of_lists(communities), \"Community Graph\", 1250, 10, 'p')\n\n #\n  table = PrettyTable(['Clique-Community', 'Nodes involved'])\n  for key, value in communities.items():\n      combined = set(key)\n      for v in value:\n          combined.update(v)\n      table.add_row([[f\"{key}:{value}\"], combined])\n\n  print(table)\nclique_percolation_cd(input_)\n",
      "comments": {
        "47": "means 1-cliques involving k nodes",
        "49": "has all the combinations of k nodes for which we're deciding whether they form a clique or not",
        "53": "valid edges means that only the edges between the nodes for whom we're checking for if they form a clique must be checked, not the other edges with other nodes",
        "60": "a clique (complete subgraph) will always have n(n - 1) / 2 noofedges, where n is the number of vertices",
        "64": "now forming the clique-community graph (the blue one in the materials)",
        "76": "trying to get just the nodes belonging to a community (subset coalescing NOT performed)"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VIII-SNA/Clique_Percolation/1.png",
        "./OP_ss/Sem_VIII-SNA/Clique_Percolation/2.png",
        "./OP_ss/Sem_VIII-SNA/Clique_Percolation/3.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#111111"
      },
      "markdown": [
        "Above demonstration is of 1 iteration of Clique Percolation Community Detection, which uses 3cliques to form communities w/ (3  1 = 2) overlaps criterion.",
        "The \"Nodes involved\" list can be further used to combine (3 + 1 = 4) cliques, this can be continued until only 2 communities (as seen in the graph above) are the only 2 sets remaining."
      ]
    },
    "Random_Graph": {
      "lang": "py",
      "codeString": "import networkx as nx\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nfrom random import randint\n\ndef network_viz(G, pos, plot_title=\"Generated Network\", with_labels=True):\n  node_sizes = [1000 for _ in G.nodes]\n  node_colors = {node: \"#{:06x}\".format(randint(0, 0xFFFFFF)) for node in G.nodes}\n  \n  fig_size = min(10, (len(G.nodes) / 10) * 2) #\n\n  plt.figure(figsize=(fig_size, fig_size))\n  nx.draw(G, pos, node_color=list(node_colors.values()), node_size=node_sizes, with_labels=with_labels)\n  plt.title(plot_title)\n  plt.show()\n\ndef nx_measures(G):\n  diameter = nx.diameter(G)\n  avgcc = nx.average_clustering(G)\n  table = PrettyTable(['Measurement', 'Value'], title=\"Network Measures\")\n  table.add_row(['Diameter', diameter])\n  table.add_row(['Average Clustering Coefficient', round(avgcc, 4)])\n\n  return table\n\ndef deg_dist(G):\n  degree_sequence = sorted([(n,d) for n, d in G.degree()], reverse=True, key=lambda x: x[1])\n  table = PrettyTable(['Node', 'Degree'], title=\"per Node degrees\")\n  table.add_rows(degree_sequence)\n  print(table, end=\"\\n\\n\")\n\n  degree_count = nx.degree_histogram(G)\n  degrees, counts = zip(*enumerate(degree_count))\n\n  plt.bar(degrees, counts, width=1.0, color='#4FBACC')\n  plt.title(\"Degree Distribution\")\n  plt.xlabel(\"Degree\")\n  plt.ylabel(\"Frequency\")\n  plt.show()\n\ndef er_graph_maker(N=20, p=0.2):\n  G = nx.erdos_renyi_graph(N, p, seed=47) #\n  pos = nx.circular_layout(G)\n\n  network_viz(G, pos, f\"ER Random Network, N={N}; p={p}\")\n  print(nx_measures(G), end=\"\\n\\n\")\n  deg_dist(G)\n\ner_graph_maker()\n\nNs = [i for i in range(40, 70, 10)]\nfor N in Ns:\n  er_graph_maker(N, p=0.2)\n\nps = [round(i / 10, 1) for i in range(1, 10, 2)]\nfor p in ps:\n  er_graph_maker(N=20, p=p)\n",
      "comments": {
        "10": "Adjust as needed",
        "42": "had to set a seed for graphs that are fully connected."
      },
      "outputSrcs": [
        "./OP_ss/Sem_VIII-SNA/Random_Graph/1.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/2.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/3.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/4.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/5.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/6.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/7.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/8.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/9.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/10.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/11.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/12.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/13.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/14.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/15.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/16.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/17.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/18.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/19.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/20.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/21.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/22.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/23.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/24.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/25.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/26.png",
        "./OP_ss/Sem_VIII-SNA/Random_Graph/27.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#111111",
        "3.png": "#ffffff",
        "4.png": "#ffffff",
        "5.png": "#111111",
        "6.png": "#ffffff",
        "7.png": "#ffffff",
        "8.png": "#111111",
        "9.png": "#ffffff",
        "10.png": "#ffffff",
        "11.png": "#111111",
        "12.png": "#ffffff",
        "13.png": "#ffffff",
        "14.png": "#111111",
        "15.png": "#ffffff",
        "16.png": "#ffffff",
        "17.png": "#111111",
        "18.png": "#ffffff",
        "19.png": "#ffffff",
        "20.png": "#111111",
        "21.png": "#ffffff",
        "22.png": "#ffffff",
        "23.png": "#111111",
        "24.png": "#ffffff",
        "25.png": "#ffffff",
        "26.png": "#111111",
        "27.png": "#ffffff"
      },
      "markdown": [
        "Parameters<br>N: Number of nodes in the graph<br>p: Probability of edge formation between nodes<br>",
        "When changing (increasing) the number of nodes in a network, while not changing the probability of edges forming between any, we see that the Diameter and the Average Clustering Coefficient (ACC) do not change significantly.",
        "Diameter does seems to slowly decrease, could be interpreted as new nodes providing shorter direct paths than the previous shorter paths.",
        "While, if we change the probability for a constant number of nodes, Diameter of the network decreases and the ACC increases."
      ]
    },
    "Random_Surfer_PageRank": {
      "lang": "py",
      "codeString": "import networkx as nx\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom random import randint\nfrom prettytable import PrettyTable\nfrom math import floor\n\ncorr_alphas = {i: chr(i + 65) for i in range(26)}\n\ndef network_viz(G):\n  labels = {i: chr(i + 65) for i in range(len(G.nodes()))}\n  pos = nx.circular_layout(G)\n  node_sizes = [500 * (10 / len(G.nodes) * 1.5) for _ in G.nodes]\n  node_colors = [f\"#{randint(120, 255):02X}{randint(120, 255):02X}{randint(120, 255):02X}\" for _ in G.nodes]\n  \n  plt.figure(figsize=(6, 6))\n  plt.title(\"Input Graph\")\n  nx.draw(G, pos, node_color=node_colors, node_size=node_sizes, width=2, arrowsize=25, edge_color='#ef0fa2')\n  nx.draw_networkx_labels(G, pos, labels, font_size=18, font_color=\"black\")\n  \n  plt.show()\n\ndef rank_printer(ranks):\n  rank_table = PrettyTable(['Node', 'Rank Score'])\n  for i, x in enumerate(ranks):\n    rank_table.add_row([corr_alphas[i], x])\n\n  print(\"\\nRank Table:\")\n  print(rank_table)\n  print(\"\\nHighest ranking node from the graph: \\033[1m\\033[38;5;227mNode\", corr_alphas[ranks.index(max(ranks))],\"\\033[0m\")\n\ndef lower_round(number, precision):\n    factor = 10 ** precision\n    rounded_number = floor(number * factor) / factor\n    return rounded_number\n\n #\ninput_ = [\n          [0, 1, 1], \n          [0, 0, 1], \n          [1, 0, 0]\n        ]\n\n #\nnp_input = np.array(input_)\n\nG = nx.from_numpy_array(np_input, create_using=nx.DiGraph)\nnetwork_viz(G)\n\ndef random_surfer_pgrk(adj_mx, \u00df = 0.85, noofiters = 3):\n  ranks = [1 for _ in adj_mx]\n\n  for o in range(noofiters):\n    print(\"Iteration:\",o)\n\n    for ri in range(len(ranks)):\n      ranks[ri] = lower_round((1 - \u00df) + \u00df * (sum([ranks[i] / sum(adj_mx[i]) for i in range(len(adj_mx)) if adj_mx[i][ri] == 1])), 5)\n  \n    rank_printer(ranks)\n\nrandom_surfer_pgrk(input_)\n",
      "comments": {
        "37": "Class example matrix for easy cross-verification",
        "44": "! rows are \"from\" and cols are \"to\""
      },
      "outputSrcs": [
        "./OP_ss/Sem_VIII-SNA/Random_Surfer_PageRank/1.png",
        "./OP_ss/Sem_VIII-SNA/Random_Surfer_PageRank/2.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#181616",
        "3.png": "#181616"
      },
      "markdown": []
    },
    "Watts-Strogatz RAM": {
      "lang": "py",
      "codeString": "import networkx as nx\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nfrom random import randint\n\ndef network_viz(G, pos, with_labels=True):\n  node_sizes = [1000 * (10 / len(G.nodes) * 1.5) for _ in G.nodes]\n  node_colors = [f\"#{randint(120, 255):02X}{randint(120, 255):02X}{randint(120, 255):02X}\" for _ in G.nodes]\n  nx.draw(G, pos, node_color=node_colors, node_size=node_sizes, with_labels=with_labels)\n\ndef nx_measures(G):\n  diameter = nx.diameter(G)\n  avgcc = round(nx.average_clustering(G), 4)\n  apl = round(nx.average_shortest_path_length(G), 4)\n\n  table = PrettyTable(['Measurement', 'Value'], title=\"Network Measures\")\n  table.add_row(['Diameter', diameter])\n  table.add_row(['Average Clustering Coefficient', avgcc])\n  table.add_row(['Average Path Length', apl])\n\n  return table, [diameter, avgcc, apl]\n\ndef deg_dist(G, **kwargs):\n  degree_count = nx.degree_histogram(G)\n  degrees, counts = zip(*enumerate(degree_count))\n  plt.bar(degrees, counts, width=1.0, color='#4FBACC')\n\n  dynamic = \"\"\n  for k, v in kwargs.items():\n    dynamic += f\"{k} = {v}; \"\n    \n  plt.title(f\"Degree Distribution of \" + dynamic)\n  plt.xlabel(\"Degree\")\n  plt.ylabel(\"Frequency\")\n\ndef ws_graph_maker(N=10, k=4, p=0.2, show_table = False):\n  G = nx.watts_strogatz_graph(N, k, p)\n  pos = nx.circular_layout(G)\n\n  table, measures = nx_measures(G)\n  if show_table:\n    print(table, end=\"\\n\\n\")\n\n  return G, pos, table, f\"N={N}; k={k}; p={p}\", measures\n\nimport math\n\nmeasures = []\nmeasure_tables = []\ntitles = []\ngraphs = []\nNkps = [[12, 4, 0], [12, 4, 1], [12, 4, 0.5], [20, 4, 0.5], [30, 4, 0.5], [40, 4, 0.5]]\ncols = math.ceil(len(Nkps) / 2)\n\nplt.subplots(2, cols, figsize=(17, 12))\n\nfor i, (n, k, p) in enumerate(Nkps):\n  graph, pos, table, title, measure = ws_graph_maker(n, k, p)\n  measures.append(measure)\n  titles.append(title)\n  measure_tables.append(table)\n  graphs.append(graph)\n  \n  plt.subplot(2, cols, i + 1)\n  network_viz(graph, pos)\n  plt.title(title)\n\nplt.suptitle(\"Watts-Strogatz Ring Lattice Network Models w/ varying params.\")\nplt.show()\n\nplt.subplots(2, cols, figsize=(17, 12))\nfor i, graph in enumerate(graphs):\n  plt.subplot(2, cols, i + 1)\n  deg_dist(graph, N=Nkps[i][0], k=Nkps[i][1], p=Nkps[i][2])\nplt.show()\n\nmega_table = PrettyTable(['Graph', 'All Measures'])\nfor i in range(len(measure_tables)):\n  mega_table.add_row([titles[i], measure_tables[i]])\n\nprint(mega_table)\n\ndef er_graph_maker(N=20, p=0.2, show_table=False):\n  G = nx.erdos_renyi_graph(N, p, seed=47) #\n  pos = nx.circular_layout(G)\n\n  table, measures = nx_measures(G)\n  if show_table:\n    print(table, end=\"\\n\\n\")\n\n  return G, pos, table, f\"N={N}; p={p}\", measures\n\ndef ba_graph_maker(N=10, m=1, m0=3, show_table = False):\n  assert N >= m0\n  G0 = nx.complete_graph(m0) #\n  G = nx.barabasi_albert_graph(N, m, initial_graph=G0) \n  pos = nx.circular_layout(G)\n\n  table, measures = nx_measures(G)\n  if show_table:\n    print(table, end=\"\\n\\n\")\n\n  return G, pos, table, f\"N={N}; m={m}\", measures\n\nN = 20 #\ner_p = 0.45 #\nba_m = 2 #\nws_k, ws_p = 4, 0.45 # degree of every node in the ring network and the probability of rewiring\n\ner_G, er_pos, er_table, er_title, er_measures = er_graph_maker(N, er_p)\nba_G, ba_pos, ba_table, ba_title, ba_measures = ba_graph_maker(N, ba_m)\nws_G, ws_pos, ws_table, ws_title, ws_measures = ws_graph_maker(N, ws_k, ws_p)\n\nplt.subplots(2, 3, figsize=(17, 12))\n\nplt.subplot(2, 3, 1)\nnetwork_viz(er_G, er_pos)\nplt.title(er_title)\nplt.subplot(2, 3, 2)\nnetwork_viz(ba_G, ba_pos)\nplt.title(ba_title)\nplt.subplot(2, 3, 3)\nnetwork_viz(ws_G, ws_pos)\nplt.title(ws_title)\n\nplt.subplot(2, 3, 4)\ndeg_dist(er_G, N=N, p=er_p)\nplt.subplot(2, 3, 5)\ndeg_dist(ba_G, N=N, m=ba_m)\nplt.subplot(2, 3, 6)\ndeg_dist(ws_G, N=N, k=ws_k, p=ws_p)\n\nplt.show()\n\ngiga_table = PrettyTable(['Model', 'Measures'], title='Model performances')\ngiga_table.add_row(['ER Model ' + er_title, er_table])\ngiga_table.add_row(['BA Model ' + ba_title, ba_table])\ngiga_table.add_row(['WS Model ' + ws_title, ws_table])\nprint(giga_table)\n",
      "comments": {
        "84": "had to set a seed for graphs that are fully connected.",
        "95": "initial fully connected graph",
        "105": "keeping the number of nodes to be generated constant across all three graphs",
        "106": "a decently high prob. for ER network's binomial dist. approach",
        "107": "number of edges each new node has to form per iteration in BA PAM graph"
      },
      "outputSrcs": [
        "./OP_ss/Sem_VIII-SNA/Watts-Strogatz RAM/1.png",
        "./OP_ss/Sem_VIII-SNA/Watts-Strogatz RAM/2.png",
        "./OP_ss/Sem_VIII-SNA/Watts-Strogatz RAM/3.png",
        "./OP_ss/Sem_VIII-SNA/Watts-Strogatz RAM/4.png",
        "./OP_ss/Sem_VIII-SNA/Watts-Strogatz RAM/5.png"
      ],
      "bgColors": {
        "1.png": "#ffffff",
        "2.png": "#ffffff",
        "3.png": "#111111",
        "4.png": "#ffffff",
        "5.png": "#111111"
      },
      "markdown": []
    }
  }
}